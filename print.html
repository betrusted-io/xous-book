<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The Xous Operating System</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="ch00-00-introduction.html">Introduction</a></li><li class="chapter-item expanded "><a href="ch01-00-getting-started.html"><strong aria-hidden="true">1.</strong> Getting Started</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch01-02-hello-world.html"><strong aria-hidden="true">1.1.</strong> Hello, World!</a></li><li class="chapter-item expanded "><a href="ch01-04-coding-style.html"><strong aria-hidden="true">1.2.</strong> Coding Style</a></li></ol></li><li class="chapter-item expanded "><a href="ch02-00-server-architecture.html"><strong aria-hidden="true">2.</strong> Server Architecture</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch02-04-synchronization.html"><strong aria-hidden="true">2.1.</strong> Synchronization</a></li></ol></li><li class="chapter-item expanded "><a href="ch03-00-introducing-the-kernel.html"><strong aria-hidden="true">3.</strong> Introducing the Kernel</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch03-01-memory-layout.html"><strong aria-hidden="true">3.1.</strong> Memory Layout</a></li><li class="chapter-item expanded "><a href="ch03-02-hosted-mode.html"><strong aria-hidden="true">3.2.</strong> Hosted Mode</a></li><li class="chapter-item expanded "><a href="ch03-03-process-creation.html"><strong aria-hidden="true">3.3.</strong> Process Creation</a></li><li class="chapter-item expanded "><a href="ch03-04-debugging-programs.html"><strong aria-hidden="true">3.4.</strong> Debugging Programs with GDB</a></li></ol></li><li class="chapter-item expanded "><a href="ch04-00-renode-emulation.html"><strong aria-hidden="true">4.</strong> Renode Emulation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch04-04-writing-cs-peripherals.html"><strong aria-hidden="true">4.1.</strong> Writing C# Peripherals</a></li></ol></li><li class="chapter-item expanded "><a href="ch05-00-system-startup.html"><strong aria-hidden="true">5.</strong> System Startup</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch05-01-arguments.html"><strong aria-hidden="true">5.1.</strong> Arguments Structure</a></li><li class="chapter-item expanded "><a href="ch05-02-loader.html"><strong aria-hidden="true">5.2.</strong> Xous Loader</a></li><li class="chapter-item expanded "><a href="ch05-03-minielf.html"><strong aria-hidden="true">5.3.</strong> MiniELF Format</a></li></ol></li><li class="chapter-item expanded "><a href="ch06-00-build-system-overview.html"><strong aria-hidden="true">6.</strong> Build System</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch06-01-testing-crates.html"><strong aria-hidden="true">6.1.</strong> Testing Crates</a></li><li class="chapter-item expanded "><a href="ch06-02-create-image.html"><strong aria-hidden="true">6.2.</strong> Image Creation</a></li><li class="chapter-item expanded "><a href="ch06-03-target-specification.html"><strong aria-hidden="true">6.3.</strong> Target Specification, UTRA</a></li></ol></li><li class="chapter-item expanded "><a href="ch07-00-messages.html"><strong aria-hidden="true">7.</strong> Messages</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch07-01-xous-names.html"><strong aria-hidden="true">7.1.</strong> Xous Names</a></li><li class="chapter-item expanded "><a href="ch07-02-caller-idioms.html"><strong aria-hidden="true">7.2.</strong> Caller Idioms</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch07-03-nonsynchronizing.html"><strong aria-hidden="true">7.2.1.</strong> Non-synchronizing</a></li><li class="chapter-item expanded "><a href="ch07-04-synchronizing.html"><strong aria-hidden="true">7.2.2.</strong> Synchronous</a></li><li class="chapter-item expanded "><a href="ch07-05-asynchronous.html"><strong aria-hidden="true">7.2.3.</strong> Asynchronous</a></li><li class="chapter-item expanded "><a href="ch07-06-deferred.html"><strong aria-hidden="true">7.2.4.</strong> Deferred Response</a></li><li class="chapter-item expanded "><a href="ch07-07-forwarding.html"><strong aria-hidden="true">7.2.5.</strong> Forwarding</a></li></ol></li><li class="chapter-item expanded "><a href="ch07-08-performance.html"><strong aria-hidden="true">7.3.</strong> Performance</a></li></ol></li><li class="chapter-item expanded "><a href="ch08-00-graphics.html"><strong aria-hidden="true">8.</strong> Graphics Toolkit</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch08-01-modals.html"><strong aria-hidden="true">8.1.</strong> Modals</a></li><li class="chapter-item expanded "><a href="ch08-02-menus.html"><strong aria-hidden="true">8.2.</strong> Menus</a></li></ol></li><li class="chapter-item expanded "><a href="ch09-00-pddb-overview.html"><strong aria-hidden="true">9.</strong> Plausibly Deniable DataBase (PDDB)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch09-01-basis.html"><strong aria-hidden="true">9.1.</strong> Basis Internal Structure</a></li><li class="chapter-item expanded "><a href="ch09-02-rootkeys.html"><strong aria-hidden="true">9.2.</strong> Key Derivation</a></li><li class="chapter-item expanded "><a href="ch09-03-api-native.html"><strong aria-hidden="true">9.3.</strong> Native API</a></li><li class="chapter-item expanded "><a href="ch09-04-api-std.html"><strong aria-hidden="true">9.4.</strong> std API</a></li><li class="chapter-item expanded "><a href="ch09-05-testing.html"><strong aria-hidden="true">9.5.</strong> Testing and CI</a></li><li class="chapter-item expanded "><a href="ch09-06-backups.html"><strong aria-hidden="true">9.6.</strong> Backups</a></li><li class="chapter-item expanded "><a href="ch09-07-discussion.html"><strong aria-hidden="true">9.7.</strong> Security and Deniability</a></li></ol></li><li class="chapter-item expanded "><a href="ch10-00-swap-overview.html"><strong aria-hidden="true">10.</strong> Swap Extensions</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">The Xous Operating System</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        <a href="https://github.com/betrusted-io/xous-book" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#introduction" id="introduction">Introduction</a></h1>
<p>Xous is a microkernel operating system with processes, threads, and
messages. It is designed to have an extremely small kernel that
delegates as much as possible to userspace. This book describes
the operating system kernel as well as the services that support
normal operating system behavior.</p>
<p>As this book is a work in progress, some chapters are placeholders and will appear blank.</p>
<p>The book is written for two audiences: kernel maintainers, and application developers.</p>
<p>Chapters <a href="ch02-00-server-architecture.html">2 (Server Architecture)</a>, <a href="ch03-00-introducing-the-kernel.html">3 (Introducing the Kernel)</a>, and <a href="ch05-00-system-startup.html">5 (System Startup)</a> are primarily for kernel maintainers and system programmers.</p>
<p>Chapters <a href="ch01-00-getting-started.html">1 (Getting Started)</a>, <a href="ch04-00-renode-emulation.html">4 (Renode Emulation)</a>, <a href="ch06-00-build-system-overview.html">6 (Build System Overview)</a>, <a href="ch07-00-messages.html">7 (Messages)</a> and <a href="ch08-00-graphics.html">8 (Graphics)</a> are more appropriate for application developers.</p>
<p>Chapter <a href="ch09-00-pddb-overview.html">9 (PDDB)</a> covers the Plausibly Deniable DataBase, and has sub-sections for both kernel and application developers.</p>
<hr />
<h2><a class="header" href="#architecture" id="architecture">Architecture</a></h2>
<p><strong>Xous</strong> is a collection of small, single purpose <strong>Servers</strong> which respond to <strong>Messages</strong>. The Xous <strong>Kernel</strong> delivers Messages to Servers, allocates processing time to Servers, and transfers memory ownership from one Server to another. Every Xous Server contains a central loop that receives a Message, matches the Message <strong>Opcode</strong>, and runs the corresponding rust code. When the operation is completed, the Server waits to receive the next Message at the top of the loop, and processing capacity is released to other Servers. Every service available in Xous is implemented as a Server. Every user application in Xous is implemented as a Server.</p>
<p>Architecturally, Xous is most similar to <a href="https://www.qnx.com/developers/docs/6.4.1/neutrino/getting_started/s1_msg.html">QNX</a>, another microkernel message-passing OS.</p>
<h3><a class="header" href="#servers" id="servers">Servers</a></h3>
<p>There are only a few &quot;well known&quot; Servers which are always available to receive Messages, and run the requested Opcode:</p>
<ul>
<li>The <code>xous-name-server</code> maintains a list of all registered Servers by name, and guards a randomised 128-bit <strong>Server ID</strong> for each of the Servers. The xous-name-server arbitrates the flow of Messages between Servers.</li>
<li>The <code>ticktimer-server</code> provides time and time-out related services.</li>
<li>The <code>xous-log-server </code> provides logging services.</li>
<li>The <code>timeserverpublic</code> provides real-time (wall-clock time) services. It is only accessed via <code>std::time</code> bindings.</li>
</ul>
<p>The remaining servers are not &quot;well known&quot; - meaning that the <code>xous-name-server</code> must be consulted to obtain a Connection ID in order to send the Server a Message. Such Servers include <code>aes</code> <code>com</code> <code>dns</code> <code>gam</code> <code>jtag</code> <code>keyboard</code> <code>llio</code> <code>modals</code> <code>net</code> <code>pddb</code> <code>trng</code>.</p>
<h3><a class="header" href="#messages-aka-ipc" id="messages-aka-ipc">Messages, aka IPC</a></h3>
<p>Every <strong>Message</strong> contains a <strong>Connection ID</strong> and an <strong>Opcode</strong>. The Connection ID is a &quot;delivery address&quot; for the recipient Server, and the Opcode specifies a particular operation provided by the recipient Server. There are two flavours of messages in Xous:</p>
<ul>
<li><strong>Scalar messages</strong> are very simple and very fast. Scalar messages can transmit only 4 u32 sized arguments.</li>
<li><strong>Memory messages</strong> can contain larger structures, but they are slower. They &quot;transmit&quot; page-sized (4096-byte) memory chunks.</li>
</ul>
<p>Rust <code>struct</code>s need to be serialized into bytes before they can be passed using Memory Messages. Xous provides convenience bindings for <code>rkyv</code>, so any <code>struct</code> fully-annotated with <code>#[derive(rkyv::Archive, rkyv::Serialize, rkyv::Deserialize)]</code> can be serialized into a buffer by the sender and deserialized by the recipient.</p>
<p>The most simple Server communication involves a <strong>non-synchronizing</strong> &quot;fire and forget&quot; style of Messaging. The Sender sends a Message and continues processing immediately. The Recipient will receive the Message when it arrives, and process the Opcode accordingly. End of story. The ownership of the Message memory passes from the Sender to the Recipient and is Dropped by the Recipient. While there will be a delay before the Message is received - the sequence is assured. In the code, these are referred to as either <code>Scalar</code> Scalar Messages or <code>Send</code> Memory Messages.</p>
<p>Alternatively, A Server can send a <strong>synchronous</strong> Message, and wait (block) until the Recipient completes the operation and responds. In this arrangement, the Message memory is merely lent to the Recipient (read-only or read-write) and returned to the Sender on completion. While the sender Server &quot;blocks&quot;, its processing quanta is not wasted, but also &quot;lent&quot; to the Recipient Server to complete the request promptly. In the code, these are referred to as either <code>BlockingScalar</code> Scalar Messages, or <code>Borrow</code> or <code>MutableBorrow</code> Memory Messages. <code>Borrow</code> messages are read-only, <code>MutableBorrow</code> are read-write, with semantics enforced by the Rust borrow checker.</p>
<p><strong>asynchronous</strong> Message flow is also possible. The Sender will send a non-synchronous Message, which the kernel will amend with a &quot;return token&quot;. The Recipient Server will complete the operation, and then send a non-synchronous Message in reply to this return token.</p>
<p>A Server may also send a synchronous Message and wait for a <strong>deferred-response</strong>. This setup is needed when the recipient Server cannot formulate a reply within a single pass of the event loop. Rather, the recipient Server must &quot;park&quot; the request and continue to process subsequent Messages until the original request can be satisfied. The request is &quot;parked&quot; by either saving the <code>msg.sender</code> field (for Scalar messages) or keeping a reference to the <code>MessageEnvelope</code> (for Memory messages). Memory Messages automatically return-on-Drop, relying on the Rust borrow checker and reference counting system to enforce implicit return semantics.</p>
<h2><a class="header" href="#acknowledgement" id="acknowledgement">Acknowledgement</a></h2>
<p>This project is funded through the NGI0 PET Fund, a fund established by NLnet
with financial support from the European Commission's Next Generation Internet
programme, under the aegis of DG Communications Networks, Content and Technology
under grant agreement No 825310.</p>
<table>
    <tr>
        <td align="center" width="50%"><img src="https://nlnet.nl/logo/banner.svg" alt="NLnet foundation logo" style="width:90%"></td>
        <td align="center"><img src="https://nlnet.nl/image/logos/NGI0_tag.svg" alt="NGI0 logo" style="width:90%"></td>
    </tr>
</table><h1><a class="header" href="#getting-started" id="getting-started">Getting Started</a></h1>
<p>The <a href="https://github.com/betrusted-io/betrusted-wiki/wiki">wiki</a> is going to be the most up-to-date source of information for getting started, as it is still a topic in flux.</p>
<p>Below are some excerpts from the Wiki, but some links may be out of date.</p>
<h2><a class="header" href="#update-your-device" id="update-your-device">Update Your Device</a></h2>
<ul>
<li><a href="https://github.com/betrusted-io/betrusted-wiki/wiki/Updating-Your-Device">Updating</a> your device.</li>
<li>Videos: <a href="https://vimeo.com/676414220/a590a017c3">Install a debug cable</a>; <a href="https://vimeo.com/676415520/51f9df8439">Assemble a Limited Edition</a></li>
<li><a href="https://ci.betrusted.io/latest-ci/">Bleeding-edge binaries</a> can be found at the CI server. Use at your own risk.</li>
<li><a href="https://ci.betrusted.io/releases/">Releases</a>: please check the corresponding README within each subdir for notes.</li>
</ul>
<h2><a class="header" href="#setting-up-security" id="setting-up-security">Setting up Security</a></h2>
<ul>
<li><a href="https://github.com/betrusted-io/betrusted-wiki/wiki/Inspecting-Your-Mainboard#trusted-domain-point-by-point">Inspecting your mainboard</a></li>
<li><a href="https://github.com/betrusted-io/betrusted-wiki/wiki/Initializing-Root-Keys">Initialize Root Keys</a> on &quot;factory new&quot; devices, by selecting the item from the main menu.</li>
<li>(Optional) <a href="https://github.com/betrusted-io/betrusted-wiki/wiki/FAQ:-FPGA-AES-Encryption-Key-(eFuse-BBRAM)#how-do-i-externally-provision-my-device">Burn Battery-Backed RAM keys</a> Note: do not use this if you plan to store long-term secrets on the device.</li>
</ul>
<h2><a class="header" href="#jargon" id="jargon">Jargon</a></h2>
<ul>
<li><a href="https://github.com/betrusted-io/betrusted-wiki/wiki/Jargon">Jargon</a>: Confused by terms like SoC and EC? You're not alone.</li>
</ul>
<h2><a class="header" href="#other-issues" id="other-issues">Other Issues</a></h2>
<h3><a class="header" href="#pre-boot--security" id="pre-boot--security">Pre-Boot &amp; Security</a></h3>
<ul>
<li><a href="https://github.com/betrusted-io/betrusted-wiki/wiki/How-Does-Precursor-Get-to-the-Reset-Vector%3F">What happens before boot?</a> fills in the details of everything that happens before the first instruction gets run.</li>
<li>&quot;<a href="https://github.com/betrusted-io/betrusted-wiki/wiki/Secure-Boot-and-KEYROM-Layout">Secure Boot</a>&quot; and key ROM layout</li>
<li><a href="https://github.com/betrusted-io/betrusted-wiki/wiki/FAQ:-FPGA-AES-Encryption-Key-(eFuse-BBRAM)">eFuse/BBRAM FPGA key</a> FAQ</li>
</ul>
<h3><a class="header" href="#between-the-software-and-hardware-hardware-abstractions" id="between-the-software-and-hardware-hardware-abstractions">Between the Software and Hardware: Hardware Abstractions</a></h3>
<ul>
<li><a href="https://github.com/betrusted-io/xous-core/tree/main/svd2utra">UTRA</a> Hardware register access abstraction for Xous</li>
<li><a href="https://github.com/betrusted-io/xous-core/wiki/Peripheral-Access-Conventions">Peripheral access conventions</a> Goals for hardware register abstractions</li>
<li><a href="https://github.com/betrusted-io/betrusted-wiki/wiki/Embedded-Controller-(EC)-COM-Protocol">COM</a> Protocol between the embedded controller (EC) and the main SoC</li>
</ul>
<h3><a class="header" href="#hardware-documentation" id="hardware-documentation">Hardware Documentation</a></h3>
<ul>
<li><a href="https://ci.betrusted.io/betrusted-soc/doc/index.html">SoC register set</a> / generated from <a href="https://github.com/betrusted-io/betrusted-soc/blob/main/betrusted_soc.py">SoC Litex Design Source</a></li>
<li><a href="https://github.com/betrusted-io/betrusted-soc#readme">SoC block diagram</a> is embedded in the README for the SoC</li>
<li><a href="https://ci.betrusted.io/betrusted-ec/doc/">EC register set</a> / generated from <a href="https://github.com/betrusted-io/betrusted-ec/blob/main/betrusted_ec.py">EC Litex Design Source</a></li>
<li><a href="https://github.com/betrusted-io/betrusted-hardware">Hardware design files</a> PDFs of schematics are in the &quot;mainboard-*&quot; directories</li>
</ul>
<h3><a class="header" href="#trng-chronicles" id="trng-chronicles">TRNG Chronicles</a></h3>
<ul>
<li><a href="https://betrusted.io/avalanche-noise">Physics and electrical design</a> of the external Avalanche generator</li>
<li>Notes on <a href="https://github.com/betrusted-io/betrusted-wiki/wiki/TRNG-characterization">Characterization</a> and debugging of raw sources</li>
<li><a href="https://github.com/betrusted-io/betrusted-wiki/wiki/TRNG-Online-Health-Monitors">On-line health monitoring</a></li>
<li><a href="https://github.com/betrusted-io/betrusted-wiki/wiki/TRNG-Data-Conditioning">Post-Generation Conditioning</a> with ChaCha</li>
</ul>
<h3><a class="header" href="#audit-trail" id="audit-trail">Audit Trail</a></h3>
<ul>
<li><a href="https://github.com/betrusted-io/crate-scraper">crate-scraper</a> is the beginning of a tool that helps with audit trails. It saves all the source code derived from <code>crates.io</code> to build Xous, and collates all the <code>build.rs</code> files into a <a href="https://github.com/betrusted-io/crate-scraper/blob/main/builds.rs">single mega-file</a> for faster manual inspection.</li>
</ul>
<h3><a class="header" href="#meta-issues" id="meta-issues">Meta-Issues</a></h3>
<ul>
<li><a href="https://github.com/betrusted-io/xous-core/tree/main/imports">imports</a> How imported repositories that are not yet stand-alone crates are managed</li>
<li><a href="https://github.com/betrusted-io/xous-core/tree/main/emulation">Emulation</a></li>
<li><a href="https://github.com/betrusted-io/xous-core/tree/main/tools">Tools</a> Helper tools to build bootable images</li>
<li><a href="https://github.com/betrusted-io/betrusted-wiki/wiki/Going-from-ODT-to-Github-Wiki">Converting Wiki Pages</a> from ODT to Markdown</li>
</ul>
<h1><a class="header" href="#hello-world" id="hello-world">Hello, World!</a></h1>
<ul>
<li>You will need the latest stable Rust. For now, Xous is tightly coupled to the latest stable Rust toolchain.</li>
<li>One should be able to run <code>cargo xtask run</code> after cloning <a href="https://github.com/betrusted-io/xous-core">xous-core</a>, and it will pop up a &quot;host-mode&quot; emulated version of Precursor.
<ul>
<li>You should be prompted to install the <code>xous</code> target the very first time you run <code>cargo</code>.
<ul>
<li>If you have updated <code>rust</code> or have tinkered with <code>std</code> on your system, you can re-install the <code>xous</code> target with <code>cargo xtask install-toolkit --force</code>, and then run <code>rm -r target</code> to force remove stale build files.</li>
</ul>
</li>
<li>You may also need to install some additional libraries, such as <code>libxkbdcommon-dev</code>.</li>
<li>:warning: hosted mode is literally Xous running on your local host, which means it supports more features than Xous on native hardware:
<ul>
<li>We do not have <code>tokio</code> support planned anytime soon.</li>
<li>We do not have <code>File</code> support in Xous; instead, we have the <code>pddb</code>.</li>
<li><code>Net</code> support in actively in development and we hope to have fairly robust support for <code>libstd</code> <code>Net</code> but, note that <code>socket2</code> crate (which is not part of Rust <code>libstd</code>) does <em>not</em> recognize Xous as a supported host.</li>
</ul>
</li>
<li>It is recommended to try compiling your configuration for a real hardware target or Renode early on to confirm compatibility, before doing extensive development in hosted mode.</li>
</ul>
</li>
<li>Make your own app:
<ul>
<li>Please refer to the <a href="https://github.com/betrusted-io/xous-core/blob/main/apps/README.md">manifest.json</a> documentation for integration notes</li>
<li><a href="https://github.com/betrusted-io/xous-core/blob/main/apps/repl/README.md"><code>repl</code> app demo</a> is the starting point for users who want to interact with their device by typing commands. This demo leverages more of the Xous UX built-in frameworks.</li>
<li><a href="https://github.com/betrusted-io/xous-core/blob/main/apps/ball/README.md"><code>ball</code> app demo</a> is the starting point for users who prefer to run close to the bare iron, getting only key events and a framebuffer for crafting games and bespoke apps.</li>
</ul>
</li>
</ul>
<h1><a class="header" href="#coding-style" id="coding-style">Coding Style</a></h1>
<h2><a class="header" href="#lint" id="lint">Lint</a></h2>
<p>Any code in <code>main</code> should be free of <code>rustc</code> lint.</p>
<h2><a class="header" href="#formatting" id="formatting">Formatting</a></h2>
<p>Generally, most stable APIs and crates should be formatted with the Rust formatter.
However, there are some idioms in Xous code that format quite poorly with the default
Rust formatter options.</p>
<p>We are waiting on the stabilization of more <code>rustfmt</code> features to define a custom
<code>rustfmt.toml</code> to address this before making formatting mandatory. It's been a few
years waiting for this, though, so we might just bite the bullet and run <code>rustfmt</code>
with <code>+nightly</code> and the features we need in <code>rustfmt.toml</code>, so that
we can have a uniform style.</p>
<p>Trailing whitespaces are frowned upon.</p>
<h2><a class="header" href="#exception-handling" id="exception-handling">Exception Handling</a></h2>
<h3><a class="header" href="#background" id="background">Background</a></h3>
<p>A mistake was made early on in defining the Xous API where all errors were
propagated, even for operations that are supposed to be infalliable or there
is no sensible way to handle an error if it were to arise.</p>
<p>The subtlety is that some errors in Rust are more like <code>assert</code> statements.
For example, a function that unpacks a message into a struct could fail. If such
a failure is encountered, then you'd like to see a panic showing that exact line
of code so you can fix the bug. There isn't a sensible alternative code path at run-time,
because the root cause was likely a type mismatch error.</p>
<p>In most of the original code base, that error would be propagated up the call
stack as an <code>InternalError</code>, until you get back to your main loop, at which point
the main loop just throws up its hands and reports a panic but at a line of code
several call frames away from the offending statement. Normally this problem
can be fixed by reading the stack trace from a panic-unwind, but Xous does not have
mature panic-unwind support and also the device's screen real estate is limited
so a deep call stack cannot be displayed entirely on the screen.</p>
<h3><a class="header" href="#recommendation" id="recommendation">Recommendation</a></h3>
<p>We are in the process of refactoring code from going to a &quot;propagate all errors&quot;
rule to a &quot;panic on infalliable failures&quot; rule. Infallible operations include
most syscalls (except ones that are explicitly fallible) and helper methods meant
to transform <em>inter-process</em> messages and buffers into types (note that this does
not include methods that receive, for example, arbitrary messages over network).</p>
<p>A simple <code>.unwrap()</code> is probably sufficient to check the results of most infalliable operations,
because the panic handler will print a panic on that line</p>
<p><code>unwrap()</code> may even be preferable to a <code>.expect(&quot;helpful error message&quot;)</code> in most
cases, because &quot;helpful error message&quot; takes memory to store, increases the
binary size, and in most cases the line of code where the panic happened is the most
informative part of the error message.</p>
<p>Any error that happen in fallible operations (timeouts, OOMs, disconnects, etc.)
should be handled and/or passed up the stack.</p>
<h1><a class="header" href="#server-architecture" id="server-architecture">Server Architecture</a></h1>
<p>This chapter is written for kernel maintainers.</p>
<p>Application programmers should see <a href="ch07-02-caller-idioms.html">caller idioms</a> and <a href="ch07-00-messages.html">messages</a> for details on how to use servers.</p>
<h2><a class="header" href="#what-is-the-difference-between-a-thread-and-a-server" id="what-is-the-difference-between-a-thread-and-a-server">What is the difference between a Thread and a Server?</a></h2>
<p>A Server is a messaging construct, whereas threads refer to execution flow. You can have a thread without a Server, and you can have multiple Servers referenced in a thread.</p>
<p>Threads in Xous are conventional: just a PC + stack that runs in a given process space. A single process can have up to 32 threads, and each thread will run until their time slice is up; or they yield their time slice by either explicitly yielding, or blocking on something (such as a blocking message).</p>
<p>Blocking messages dovetails into the concept of servers: in Xous, server is basically just a 128-bit ID number that servers as a mailbox for incoming messages. There is a limit of 128 servers in Xous across all processes and threads. Within that limit, one can allocate all the servers they want for a given thread, although it's not terribly useful to do that.</p>
<p>Messages specify a 128-bit server ID as a recipient; and, the typical idiom (although it doesn't have to be this way) is for a thread to wake up, initialize, allocate a server ID, and then wait for a message to arrive in its inbox.</p>
<p>If no message arrives, the thread consumes zero time.</p>
<p>Once a message arrives, the thread will be unblocked to handle the message when its quantum comes up. The thread may receive a quantum through the normal round-robin pre-emptive scheduler, but it could also receive a quantum in the case that a blocking message is sent from another thread. What happens then is the sender yields the remainder of its time to the receiving server, so that the message may be handled immediately.</p>
<p>As a counter-example, a &quot;valid&quot; but <em>not recommended</em> way to communicate between threads in Xous is to do something like:</p>
<pre><code class="language-rust noplayground ignore">let sem = Arc::new(AtomicBool::new(false));
thread::spawn(
    let sem = sem.clone();
    move || {
        loop {
            if sem.load(Ordering::SeqCst) {
                // do something useful here

                // do it just once
                sem.store(false, Ordering::SeqCst);
            } else {
                // we could be nice and yield our quantum to another thread
                xous::yield_slice();
                // but even if you forget to yield, eventually, the pre-emptive
                // scheduler will stop polling and allow another thread to run.
            }
        }
    }
);

// Later in the parent thread, use this to trigger the child thread:
sem.store(true, Ordering::SeqCst);
</code></pre>
<p>The &quot;bad example&quot; above starts a thread that just polls the <code>sem</code> variable until it is <code>true</code> before a one-shot execution of the thing it's supposed to do.</p>
<p>The problem with this construction is that it will constantly run the CPU and always take a quantum of time to poll <code>sem</code>. This is very inefficient; it actually burns more battery, and has a material impact on user experience to do it this way.</p>
<p>A more &quot;Xous&quot; way to do this would be:</p>
<pre><code class="language-rust noplayground ignore">let sid = xous::create_server().unwrap();
let conn = xous::connect(sid).unwrap();
thread::spawn(
    // sid automatically clones here
    move || {
        loop {
            let msg = xous::receive_message(sid).unwrap();
            // typically one would decode an opcode from the message body, so you can dispatch more than one function.
            let _opcode: Option&lt;ActionOp&gt; = FromPrimitive::from_usize(msg.body.id());
            // but in this case, we have exactly one thing, so:

            // do something useful here

            // indicate that we got our thing done
            xous::return_scalar(msg.sender, retval).unwrap();
        }
    }
);

// Later in the parent thread, use this to trigger the child thread:
xous::send_message(conn,
    Message::new_blocking_scalar(0 /* this is the opcode field */,
    0, 0, 0, 0) // up to 4 &quot;scalar&quot; arguments can be sent as well
).unwrap();
</code></pre>
<p>The above <code>send_message()</code> would yield the remaining quantum of time for the parent thread, and dispatch into the child thread. The child would receive the message, do &quot;something useful&quot; and return a value to the caller. Assuming there was still time left in the quantum, this <code>return_scalar</code> would return execution back to the parent thread!</p>
<p>If the message was not blocking, the parent thread would continue executing until its quantum is completed, and then the child thread would handle the message only then. Assuming the child  thread can handle the response very quickly, it would yield the remainder of its quantum once it completed doing &quot;something useful&quot; and it returned to the top of its loop where it calls <code>receive_message()</code>, and found its input queue to be empty.</p>
<p>Thus, Xous is carefully coded such that everything blocks if it's not being used, using the idiom above. Crates like <code>crossbeam</code> are implemented using <code>condvar</code> which intenally uses servers and messages to ensure that blocking waits are efficient.</p>
<p>So, in general, if the CPU load bar is pegged to 100% and nothing is &quot;going on&quot; (perhaps just a spin-wait), it's considered a bug.</p>
<h1><a class="header" href="#synchronization-primitives" id="synchronization-primitives">Synchronization Primitives</a></h1>
<p>Synchronization primitives are provided via the Ticktimer Server. This includes mutexes, process sleeping, and condvars.</p>
<h2><a class="header" href="#thread-sleeping" id="thread-sleeping">Thread Sleeping</a></h2>
<p>Thread sleeping is a primitive that is implemented by the ticktimer
server.</p>
<p>This takes advantage of the fact that a sender will suspend a thread
until a <code>BlockingScalar</code> message is responded to.</p>
<p>In order to suspend a thread, simply send a <code>BlockingScalar</code> message
to the ticktimer server with an <code>id</code> of <code>1</code> and an <code>arg1</code> indicating
the number of milliseconds to sleep.</p>
<p>If you need  to sleep for more than 49 days, simply send multiple messages.</p>
<h2><a class="header" href="#mutex" id="mutex">Mutex</a></h2>
<p>Mutexes allow for multiple threads to safely access the same data.
Xous Mutexes have two paths: A fast path, and a slow path. Non-contended
Mutexes traverse the fast path and will not need a context switch.
Contended Mutexes will automatically fall back to the slow path.</p>
<p>The core of a Mutex is a single <code>AtomicUsize</code>. This value is 0 when
the Mutex is unlocked, and nonzero when it is locked.</p>
<h3><a class="header" href="#mutex-locking" id="mutex-locking">Mutex: Locking</a></h3>
<p>Locking a Mutex involves a simple <code>try_lock()</code> operation. In this
operation, atomic instructions are used to replace the value <code>0</code>
with the value <code>1</code>, failing if this is the case.</p>
<pre><code class="language-rust noplayground ignore">pub unsafe fn try_lock(&amp;self) -&gt; bool {
    self.locked.compare_exchange(0, 1, SeqCst, SeqCst).is_ok()
}
</code></pre>
<p>If the Mutex is locked, then the current thread will call <code>yield_slice()</code>
which hands execution to another thread in the current process in the hope
that the other thread will release its mutex.</p>
<p>This currently occurs three times.</p>
<p>If the lock still cannot be locked, then it is &quot;poisoned&quot;. Instead of
swapping <code>0</code> for <code>1</code>, the thread does an atomic Add of <code>1</code> to the current
value. If the resulting value is <code>1</code> then the lock was successfully
obtained and execution may continue as normal.</p>
<p>However, if the value is not <code>1</code> then the process falls back to the Slow Path. This involves sending a <code>BlockingScalar</code> to the ticktimer
server with an <code>id</code> of <code>6</code> and <code>arg1</code> set to the address of the Mutex.</p>
<h3><a class="header" href="#mutex-unlocking" id="mutex-unlocking">Mutex: Unlocking</a></h3>
<p>Unlocking a Mutex on the Fast Path simply involves subtracting <code>1</code> from
the Mutex. If the previous value was <code>1</code> then there were no other
threads waiting on the Mutex.</p>
<p>Otherwise, send a <code>BlockingScalar</code> to the ticktimer server with
an <code>id</code> of <code>7</code> and <code>arg1</code> set to the address of the Mutex.</p>
<h2><a class="header" href="#condvar" id="condvar">Condvar</a></h2>
<p>Condvar is Rust's name for &quot;conditional variables&quot;. Broadly speaking,
they are instances where one thread takes an area of memory and says
&quot;Wake me up sometime in the future.&quot; A different thread can then say
&quot;Wake up one other thread that's waiting on this object.&quot; Or it
can say &quot;Wake up all other threads that are waiting on this object.&quot;</p>
<h3><a class="header" href="#condvar-waiting-for-a-condition" id="condvar-waiting-for-a-condition">Condvar: Waiting for a Condition</a></h3>
<p>To suspend a thread until a condition occurs, or until a timeout hits,
allocate an area of memory for the condvar. Then send a <code>BlockingScalar</code>
message to the ticktimer server with an <code>id</code> of <code>8</code>. Set <code>arg1</code> to the
address of the condvar.</p>
<p>In order to add a timeout, set <code>arg2</code> to the number of milliseconds to
wait for. Times longer than 49 days are not supported, so multiple
calls will be required. If no timeout is required, pass <code>0</code> for <code>arg2</code>.</p>
<h3><a class="header" href="#condvar-signaling-wakeups" id="condvar-signaling-wakeups">Condvar: Signaling Wakeups</a></h3>
<p>To wake up another thread, send a <code>BlockingScalar</code> message to the ticktimer
server with an <code>id</code> of <code>9</code>, and set <code>arg1</code> to the address of the condvar.
<code>arg2</code> should contain the number of blocked threads to wake up.
In order to wake only one thread, pass <code>1</code>.</p>
<h1><a class="header" href="#introducing-the-kernel" id="introducing-the-kernel">Introducing the Kernel</a></h1>
<p>Xous is a microkernel design that tries to keep as little as possible inside the main kernel. Instead, programs can start &quot;Servers&quot; that process can connect to in order to accomplish a task.</p>
<p>Processes are isolated, and therefore an MMU is strongly recommended. One process can have multiple threads, and processes cannot interact with one another except by passing Messages.</p>
<p>A Message is a piece of data that can be sent to a Server. Messages contain one <code>usize</code> ID field that may be used to identify an opcode, and may additionally contain some memory or some <code>usize</code> scalars.</p>
<p>Additionally, a Message may be either blocking, in which case it will wait for the Server to respond, or non-blocking, where they will return immediately.</p>
<p>&quot;Drivers&quot; are really just Servers. For example, to print a string to the console, send a <code>StandardOutput</code> (1) opcode to the server &quot;xous-log-server &quot; with a <code>&amp;[u8]</code> attached to some memory. The process will block until the server is finished printing.</p>
<p>The entire Xous operating system is built from these small servers, making it easy to work on one component at a time.</p>
<h2><a class="header" href="#memory-and-mapping" id="memory-and-mapping">Memory and mapping</a></h2>
<p>Memory is obtained by issuing a <code>MapMemory</code> syscall. This call can optionally provide a physical address to map. If no memory is specified, a random physical page is provided. The process has no way of knowing the physical address of the page.</p>
<p>If the caller allocates memory from the primary region, it will be zeroed. If it allocates memory from an ancillary region such as a registor or a framebuffer, then that memory will not be initialized.</p>
<p>Processes can use this to allocate memory-mapped regions in order to create drivers.</p>
<h2><a class="header" href="#interrupts" id="interrupts">Interrupts</a></h2>
<p>Processes can allocate interrupts by calling the <code>ClaimInterrupt</code> call. If an interrupt has not been used, then that process will become the new owner of that interrupt. This syscall requires you to specify an address of a function to call, and you may optionally provide an argument to pass to the function handler.</p>
<p>There is no way to disable interrupts normally, except by handling an interrupt. That is, interrupts are disabled inside of your interrupt handler, and will be re-enabled after your interrupt handler returns.</p>
<p>There are a very limited set of functions that may be called during an interrupt handler. You may send nonblocking Messages and allocate memory, for example. However you may not Yield or send blocking Messages.</p>
<p>A common pattern for &quot;disabling interrupts&quot; is to come up with an interrupt that does nothing but trigger on-demand and handling the requisite code in that function. This is used by the suspend/resume server, for example, in order to ensure nothing else is running when the system is powering down.</p>
<h2><a class="header" href="#supported-platforms-risc-v-32-and-hosted" id="supported-platforms-risc-v-32-and-hosted">Supported Platforms: RISC-V 32 and Hosted</a></h2>
<p>Xous currently supports two platforms: RISC-V 32 and Hosted mode.</p>
<p>RISC-V 32 is the hardware that ships in Betrusted and Precursor, and is what is available in the Renode emulator.</p>
<p>An additional platform is <code>Hosted</code> mode, which targets your desktop machine. This can be used to debug builds using desktop-class debuggers such as <code>rr</code> or even just <code>gdb</code>. You can also use profilers in order to discover where code performance can be improved.</p>
<p><code>Hosted</code> mode is discussed in <a href="ch03-02-hosted-mode.html">more detail later</a></p>
<h1><a class="header" href="#memory-management-in-xous" id="memory-management-in-xous">Memory Management in Xous</a></h1>
<p>Memory is allocated with the <code>MapMemory</code> syscall. This call accepts four arguments:</p>
<ul>
<li>physical: <code>Option&lt;NonZeroUsize&gt;</code>: The physical address you would like to allocate. Specify <code>None</code> if you don't need a particular address.</li>
<li>virtual: <code>Option&lt;NonZeroUsize&gt;</code>: The virtual address you would like to allocate. Specify <code>None</code> if you don't need a particular virtual address.</li>
<li>size: <code>NonZeroUsize</code>: The size of the region to allocate. This must be page-aligned.</li>
<li>flags: <code>MemoryFlags</code>: A list of platform-specific flags to apply to this region.</li>
</ul>
<p>The memory will return a <code>MemoryRange</code> that encompasses the given region.</p>
<p>You can free memory with <code>UnmapMemory</code>, though be very careful not to free memory that is currently in use. <code>UnmapMemory</code> simply takes the <code>MemoryRange</code> returned by <code>MapMemory</code>.</p>
<h2><a class="header" href="#physical-addresses" id="physical-addresses">Physical Addresses</a></h2>
<p>A program rarely needs to access physical addresses, and in most operating systems it's not the kind of thing you can actually <em>do</em>. However, Xous is designed to be embedded, so it's entirely legal to request a physical address.</p>
<p>The trick is that you can only request physical addresses that actually exist. For example, you cannot request a physical address for a mirrored region of a peripheral because that is not a valid address.</p>
<p><strong>If you request a physical address from main RAM, the memory will be zeroed when you receive it</strong>. Peripherals and ares that are not in main RAM will not be zeroed. It is for this reason that system services are recommended to claim all peripherals before running user programs.</p>
<h2><a class="header" href="#virtual-addresses" id="virtual-addresses">Virtual Addresses</a></h2>
<p>All Xous programs run with virtual memory enabled. Attempting to perform an illegal operation will result in an exception. If you have an exception handler installed, illegal memory accesses will run this exception handler which may fix up the exception.</p>
<h3><a class="header" href="#demand-paging" id="demand-paging">Demand Paging</a></h3>
<p>When you allocate memory using <code>MapMemory(None, None, ..., ...)</code>, you will be handed memory from the <code>DEFAULT_BASE</code>. This memory will not be backed by a real page, and will only be allocated by the kernel once you access the page. This allows threads to allocate large stacks without running out of memory immediately.</p>
<p>Pages that are mapped-but-unallocated are visible in a process' page table view. As an example, consider the following excerpt from a page table view:</p>
<pre><code class="language-text">    38 60026000 -&gt; 400a3000 (flags: VALID | R | W | USER | A | D)
    41 60029000 -&gt; 40108000 (flags: VALID | R | W | A | D)
    42 6002a000 -&gt; 40109000 (flags: VALID | R | W | A | D)
    43 6002b000 -&gt; 00000000 (flags: R | W)
    44 6002c000 -&gt; 00000000 (flags: R | W)
</code></pre>
<p>Addresses 0x60026000 (#38), 0x60029000 (#41), and 0x6002a000 (#42) are all allocated. The rest of the pages are valid-but-unallocated.</p>
<p>Address 0x60026000 (#38) is mapped to the process and has a valid physical address. Reads and writes to this page are backed by physical address 0x400a3000.</p>
<p>Addresses 0x60029000 (#41) and 0x6002a000 (#42) are still owned by the kernel, likely because they were being cleared.</p>
<p>Addresses 0x6002b000 (#43) and 0x6003c000 (#44) are on-demand allocated. They have no physical backing, and attempting to access them will result in a kernel fault where they will be allocated. When the page is allocated, it will be given the flags <code>R | W</code> in addition to default kernel flags.</p>
<h3><a class="header" href="#the-heap" id="the-heap">The Heap</a></h3>
<p>When we talk about &quot;The Heap&quot; we mean data that is managed by functions such as <code>malloc</code>. Xous has a pair of syscalls that behave vaguely like the Unix <code>brk</code> command.</p>
<p><code>IncreaseHeap(usize, MemoryFlags)</code> will increase a program's heap by the given amount. This returns the new heap as a <code>MemoryRange</code>.</p>
<p>To decrease the heap by a given amount, call <code>DecreaseHeap(usize)</code>.</p>
<p>Note that you must adjust the heap in units of <code>PAGE_SIZE</code>.</p>
<p>You can avoid using these syscalls by manually allocating regions using <code>MapMemory</code>, however they are a convenient abstraction with their own memory range.</p>
<p><code>liballoc</code> as bundled by Xous uses these syscalls as a backing for memory.</p>
<h3><a class="header" href="#virtual-memory-regions" id="virtual-memory-regions">Virtual Memory Regions</a></h3>
<p>There are different memory regions in virtual address space:</p>
<table><thead><tr><th>Address</th><th>Name</th><th>Variable</th><th>Description</th></tr></thead><tbody>
<tr><td>0x00010000</td><td>text</td><td>-</td><td>Start of <code>.text</code> with the default riscv linker script (<code>riscv64-unknown-elf-ld -verbose</code>)</td></tr>
<tr><td>0x20000000</td><td>heap</td><td>DEFAULT_HEAP_BASE</td><td>Start of the heap section returned by <code>IncreaseHeap</code></td></tr>
<tr><td>0x40000000</td><td>message</td><td>DEFAULT_MESSAGE_BASE</td><td>Base address where <code>MemoryMessage</code> messages are mapped inside of a server</td></tr>
<tr><td>0x60000000</td><td>default</td><td>DEFAULT_BASE</td><td>Default region when calling `MapMemory(..., None, ..., ...) -- most threads have their stack here</td></tr>
<tr><td>0x7fffffff</td><td>stack</td><td>-</td><td>The default stack for the first thread - grows downwards</td></tr>
<tr><td>0xff000000</td><td>kernel</td><td>USER_AREA_END</td><td>The end of user area and the start of kernel area</td></tr>
<tr><td>0xff400000</td><td>pgtable</td><td>PAGE_TABLE_OFFSET</td><td>A process' page table is located at this offset, accessible only to the kernel</td></tr>
<tr><td>0xff800000</td><td>pgroot</td><td>PAGE_TABLE_ROOT_OFFSET</td><td>The root page table is located at this offset, accessible only to the kernel</td></tr>
</tbody></table>
<p>In addition, there are special addresses that indicate the end of a function. The kernel will set these as the return address for various situations, and they are documented here for completeness:</p>
<table><thead><tr><th>Address</th><th>Name</th><th>Variable</th><th>Description</th></tr></thead><tbody>
<tr><td>0xff802000</td><td>retisr</td><td>RETURN_FROM_ISR</td><td>Indicates the return from an interrupt service routine</td></tr>
<tr><td>0xff803000</td><td>exitthr</td><td>EXIT_THREAD</td><td>Indicates a thread should exit</td></tr>
<tr><td>0xff804000</td><td>retex</td><td>RETURN_FROM_EXCEPTION_HANDLER</td><td>Indicates the return from an exception handler</td></tr>
</tbody></table>
<h1><a class="header" href="#hosted-mode" id="hosted-mode">Hosted Mode</a></h1>
<p>Hosted mode may be built by running <code>cargo xtask run</code>. This causes Xous to be compiled using your native architecture rather than building for <code>riscv32imac-unknown-xous-elf</code>. Your native architecture is probably 64-bits, and has a lot more memory than Betrusted does. Xous also runs in userspace, which means a lot of things end up being very different in this mode.</p>
<p>The API is designed to abstract away these differences so that programs may run seamlessly on both Hosted and Native (RISC-V 32) mode.</p>
<h2><a class="header" href="#the-kernel-as-a-process" id="the-kernel-as-a-process">The Kernel as a Process</a></h2>
<p>When you build processes using <code>cargo xtask run</code>, the kernel is compiled as an ordinary, native program. This program can be run by simply running <code>./target/release/kernel</code>. If you run this by itself after running <code>cargo xtask run</code>, you'll see the following output:</p>
<pre><code class="language-sh">$ ./target/release/kernel
KERNEL: Xous server listening on 127.0.0.1:1238
KERNEL: Starting initial processes:
  PID  |  Command
-------+------------------
</code></pre>
<p>The kernel simply acts as a router, passing messages between processes. This poses some challenges because processes need to be able to connect to one another, and the kernel needs to be able to match a network connection to a given process. Additionally, there needs to be a list of initial processes to start.</p>
<h2><a class="header" href="#initial-processes" id="initial-processes">Initial Processes</a></h2>
<p>In order to get a list of initial processes, they are simply all passed on the command line. For example, we can run the kernel with a log server and see the following output:</p>
<pre><code class="language-sh">$ ./target/release/kernel ./target/release/log-server
KERNEL: Xous server listening on 127.0.0.1:21183
KERNEL: Starting initial processes:
  PID  |  Command
-------+------------------
   2   |  ./target/release/log-server
LOG: my PID is 2
LOG: Creating the reader thread
LOG: Running the output
LOG: Xous Logging Server starting up...
LOG: Server listening on address SID([1937076088, 1735355437, 1919251245, 544367990])
LOG: my PID is 2
LOG: Counter tick: 0
</code></pre>
<p>From this output, we can see that the kernel has started the log server for us. Multiple initial processes may be specified:</p>
<pre><code class="language-sh">$ ./target/release/kernel ./target/release/log-server ./target/release/xous-names
KERNEL: Xous server listening on 127.0.0.1:3561
KERNEL: Starting initial processes:
  PID  |  Command
-------+------------------
   2   |  ./target/release/log-server
   3   |  ./target/release/xous-names
LOG: my PID is 2
LOG: Creating the reader thread
LOG: Running the output
LOG: Xous Logging Server starting up...
LOG: Server listening on address SID([1937076088, 1735355437, 1919251245, 544367990])
LOG: my PID is 2
LOG: Counter tick: 0
INFO:xous_names: my PID is 3 (services/xous-names/src/main.rs:360)
INFO:xous_names: started (services/xous-names/src/main.rs:375)
</code></pre>
<h2><a class="header" href="#launching-a-process" id="launching-a-process">Launching a Process</a></h2>
<p>Processes are launched in the kernel by setting a series of environment variables and then spawning a new process. The following environment variables are currently used:</p>
<table><thead><tr><th>Variable</th><th>Description</th></tr></thead><tbody>
<tr><td>XOUS_SERVER</td><td>The IP and TCP port of the kernel</td></tr>
<tr><td>XOUS_PID</td><td>The unique process ID of this kernel, assigned by the Xous kernel</td></tr>
<tr><td>XOUS_PROCESS_NAME</td><td>The process name, currently taken from the executable name</td></tr>
<tr><td>XOUS_PROCESS_KEY</td><td>An 8-byte hex-encoded key that uniquely identifies this process</td></tr>
</tbody></table>
<p>A thread is created for this process to handle it and to route messages within the kernel. The <code>XOUS_PROCESS_KEY</code> is effectively a single-use token that is unique per process and is used to match a process within the kernel.</p>
<p>When the process launches it should establish a connection to the kernel by connecting to <code>XOUS_SERVER</code> and sending <code>XOUS_PROCESS_KEY</code>. This will authenticate the process with the kernel ane enable it to send and receive messages.</p>
<p>The initial handshake has the following layout:</p>
<table><thead><tr><th>Offset (Bytes)</th><th>Size</th><th>Meaning</th></tr></thead><tbody>
<tr><td>0</td><td>1</td><td>Process ID of connecting process</td></tr>
<tr><td>1</td><td>8</td><td>8-byte process key</td></tr>
</tbody></table>
<h2><a class="header" href="#sending-and-receiving-syscalls" id="sending-and-receiving-syscalls">Sending and Receiving Syscalls</a></h2>
<p>In Hosted mode, syscalls are sent via a network connection. Because pointers are unsafe to send, <code>usize</code> is defined on Hosted mode as being 32-bits. Additionally, most syscalls will return <code>NotImplemented</code>, for example it does not make sense to create syscalls such as <code>MapMemory</code>.</p>
<p>Messages function normally in Hosted mode, however they are more expensive than on real hardware. Because messages get sent via the network, the entire contents of a Memory message must be sent across the wire.</p>
<p>Eight 32-bit values are sent, and these may be followed by any data in case there is a Memory message.</p>
<table><thead><tr><th>Offset (Bytes)</th><th>Usage (Calling)</th></tr></thead><tbody>
<tr><td>0</td><td>Source thread ID</td></tr>
<tr><td>4</td><td>Syscall Number</td></tr>
<tr><td>8</td><td>Arg 1</td></tr>
<tr><td>12</td><td>Arg 2</td></tr>
<tr><td>16</td><td>Arg 3</td></tr>
<tr><td>20</td><td>Arg 4</td></tr>
<tr><td>24</td><td>Arg 5</td></tr>
<tr><td>28</td><td>Arg 6</td></tr>
<tr><td>32</td><td>Arg 7</td></tr>
<tr><td>36</td><td>Contents of any buffer pointed to by args</td></tr>
</tbody></table>
<p>The process should expect a return, and should block until it gets a response. When it gets a response, a memory buffer may be required that is the same size as the buffer that was sent. The contents of this buffer will be appended to the network packet in the same manner as the calling buffer. If the message is a Borrow, then this data will be the same as the data that was sent. If it is a MutableBorrow, then the server may manipulate this data before it returns.</p>
<table><thead><tr><th>Offset (Bytes)</th><th>Usage (Return)</th></tr></thead><tbody>
<tr><td>0</td><td>Target thread ID</td></tr>
<tr><td>4</td><td>Return type tag</td></tr>
<tr><td>8</td><td>Arg 1</td></tr>
<tr><td>12</td><td>Arg 2</td></tr>
<tr><td>16</td><td>Arg 3</td></tr>
<tr><td>20</td><td>Arg 4</td></tr>
<tr><td>24</td><td>Arg 5</td></tr>
<tr><td>28</td><td>Arg 6</td></tr>
<tr><td>32</td><td>Arg 7</td></tr>
<tr><td>36</td><td>Contents of any returned buffer</td></tr>
</tbody></table>
<h2><a class="header" href="#threading" id="threading">Threading</a></h2>
<p>All Xous syscalls go to the kernel, however certain syscalls are simply stubs. One example of this is threading, where the kernel has no way of actually launching a thread.</p>
<p>The application is responsible for creating new threads, and may do so either by &quot;sending&quot; a <code>CreateThread</code> call to the kernel or by creating a native thread using <code>std::Thread::spawn()</code>.</p>
<p>When launching a thread with <code>CreateThread</code>, the kernel will allocate a new &quot;Xous TID&quot; and return that to the application. The application will then launch its new thread and set the local <code>THREAD_ID</code> variable to this ID. This ID will be used as part of the header when sending syscalls to the kernel, and will be used to delegate responses to their waiting threads.</p>
<p>If an application calls <code>std::Thread::spawn()</code> then it will not have a <code>THREAD_ID</code> set. When the thread attempts to send a syscall, hosted mode will notice that <code>THREAD_ID</code> is None. When this occurs, Hosted mode will create a &quot;fake&quot; thread ID (starting at TID 65536) and call <code>SysCall::CreateThread(ThreadInit {})</code> to register this new ID. Then all subsequent calls will use this fake thread ID.</p>
<h1><a class="header" href="#process-creation" id="process-creation">Process Creation</a></h1>
<p>Creating processes is a fundamental requirement of modern operating systems above a certain size. Xous supports process creation, although it does not prescribe an executable format nor does it even have a built-in loader.</p>
<p>Process creation arguments vary depending on the platform being targeted, making this one of the less portable aspects of Xous. All platforms support the <code>CreateProcess</code> syscall, however the arguments to this syscall vary widely.</p>
<h2><a class="header" href="#creating-processes-in-hosted-mode" id="creating-processes-in-hosted-mode">Creating Processes in Hosted Mode</a></h2>
<p>In Hosted mode, the <code>ProcessArgs</code> struct contains a full command line to be passed directly to the shell. This is actually used by the kernel during its init routine when it spawns each child process of PID 1.</p>
<p>Internally, the parent process is responsible for launching the process as part of the <code>create_process_post()</code> that gets called after the successful return of the <code>CreateProcess</code> syscall. As part of this, the hook sets various environment variables for the child process such as its 16-byte key stored in the <code>XOUS_PROCESS_KEY</code> variable, as well as the PID stored in the <code>XOUS_PID</code> variable.</p>
<h2><a class="header" href="#creating-processes-in-test-mode" id="creating-processes-in-test-mode">Creating Processes in Test Mode</a></h2>
<p>Test mode is a special case. Tests don't want to depend on files in the filesystem, particularly as multiple tests are running at the same time. To work around this, processes are created as threads. This is a special case intended to support heavily-parallel machines that can run all thread tests simultaneously, and is not normally used.</p>
<h2><a class="header" href="#creating-processes-on-native-hardware-eg-risc-v" id="creating-processes-on-native-hardware-eg-risc-v">Creating Processes on Native Hardware (e.g. RISC-V)</a></h2>
<p>Process creation on real hardware requires a minimum of six pieces of information. These are all defined in the <code>ProcessInit</code> struct, which gets passed directly to the kernel:</p>
<pre><code class="language-rust noplayground ignore">pub struct ProcessInit {
    // 0,1 -- Stack Base, Stack Size
    pub stack: crate::MemoryRange,
    // 2,3 -- Text Start, Text Size
    pub text: crate::MemoryRange,
    // 4 -- Text destination address
    pub text_destination: crate::MemoryAddress,
    // 5 -- Entrypoint (must be within .text)
    pub start: crate::MemoryAddress,
}
</code></pre>
<p>The <code>stack</code> defaults to 128 kB growing downwards from <code>0x8000_0000</code>.</p>
<p><code>text</code> refers to a region of memory <strong>INSIDE YOUR PROGRAM</strong> that will be detached and moved to the child process. This memory will form the initialization routine for the child process, and should contain no <code>.bss</code> or <code>.data</code> sections, unless it also contains code to allocate and set up those sections.</p>
<p><code>text_destination</code> describes the offset where <code>text</code> will be copied. This address is determined by the link address of your initialization program. </p>
<p>The <code>start</code> is the address where the program counter will start. This is the address of your program's entrypoint. It must reside within the allocated text section, beginning at <code>text_destination</code>.</p>
<h3><a class="header" href="#native-hardware-entrypoint" id="native-hardware-entrypoint">Native Hardware Entrypoint</a></h3>
<p>The entrypoint for native hardware takes four arguments. When combined, these four arguments form a Server ID that can be used for sending additional data from the parent process to the child. An example loader program might look like the following:</p>
<pre><code class="language-rust noplayground ignore">pub extern &quot;C&quot; fn init(a1: u32, a2: u32, a3: u32, a4: u32) -&gt; ! {
    let server = xous::SID::from_u32(a1, a2, a3, a4);
    while let Ok(xous::Result::Message(envelope)) =
        xous::rsyscall(xous::SysCall::ReceiveMessage(server))
    {
        match envelope.id().into() {
            StartupCommand::WriteMemory =&gt; write_memory(envelope.body.memory_message()),
            StartupCommand::FinishStartup =&gt; finish_startup(server, envelope),
            StartupCommand::PingResponse =&gt; ping_response(envelope),

            _ =&gt; panic!(&quot;unsupported opcode&quot;),
        }
    }
    panic!(&quot;parent exited&quot;);
}
</code></pre>
<p>This compiles down to a very efficient program that can be used to load a larger program into the new address space. Memory is written using the <code>WriteMemory</code> opcode to load new pages into the nascent process, and <code>FinishStartup</code> is used to shut down the server and jump to the new process entrypoint.</p>
<h3><a class="header" href="#limitations-of-created-processes" id="limitations-of-created-processes">Limitations of Created Processes</a></h3>
<p><strong>NOTE:</strong> The following is subject to fixes in the kernel, and do not currently apply. This information is presented here in order to explain oddities observed when these features are implemented.</p>
<p>Newly-created processes cannot create servers with a predefined Server ID. They can only create randomized servers.</p>
<p>Processes created using <code>CreateProcess</code> are not ever scheduled to run. Parent processes must donate their quantum to child processes in order for them to run. This is done with a special syscall.</p>
<p>When a parent process exits, all child processes will also exit. This is because those processes will not be scheduled anymore, so there's no point in letting them continue to run.</p>
<h1><a class="header" href="#debugging-with-gdb" id="debugging-with-gdb">Debugging with GDB</a></h1>
<p>The kernel supports enabling the <code>gdb-stub</code> feature which will provide a gdb-compatible server on the 3rd serial port. This server can be used to debug processes that are running, and when a process crashes the kernel will automatically halt the process for debugging.</p>
<p>When using the debugger, many features are supported:</p>
<ul>
<li>Listing processes on the system</li>
<li>Attaching to a given process</li>
<li>Listing threads</li>
<li>Examining and updating memory</li>
<li>Examining and updating registers</li>
<li>Single-stepping (non-XIP processes)</li>
<li>Inserting breakpoints (non-XIP processes)</li>
</ul>
<p>The following features are NOT SUPPORTED:</p>
<ul>
<li>Watchpoints</li>
<li>Inserting breakpoints in XIP processes</li>
<li>Single-stepping XIP processes</li>
</ul>
<h2><a class="header" href="#building-a-gdb-compatible-image" id="building-a-gdb-compatible-image">Building a GDB-Compatible Image</a></h2>
<p>For the toolchain, Xous has harmonized around the <a href="https://github.com/xpack-dev-tools/riscv-none-elf-gcc-xpack/releases">xpack</a> gcc distribution, but other GCC distributions version of GDB (even those that target RV64) should work.</p>
<p>You probably want to set <code>debug = true</code> inside <code>Cargo.toml</code>. This will add debug symbols to the resulting ELF binaries which greatly enhance the debugging experience. You may also want to reduce the optimization level and turn off <code>strip</code> if it is set.</p>
<p>When running <code>xtask</code> to create images, the target processes you want to debug should <em>not</em> be XIP. XIP images run out of FLASH, which makes the code immutable and thus impossible for our debugger implementation to insert a breakpoint (our breakpoints are <em>not</em> hardware backed). The easiest way to do this is to use the <code>app-image</code> generator (instead of <code>app-image-xip</code>). However, if you've turned your optimizations to <code>0</code> and included debug symbols, it's possible this isn't an option because you'll run out of memory. In this case, you will need to modify <code>app-image-xip</code> to check for the target process name and toggle the flag on just that process to run out of RAM.</p>
<p>You will also need to pass <code>--gdb-stub</code> as an argument to <code>xtask</code>.</p>
<p>For example:</p>
<pre><code class="language-text">cargo xtask app-image --gdb-stub mtxchat --feature efuse --feature tls
</code></pre>
<p>Then, flash the resulting image to the target device as normal.</p>
<h2><a class="header" href="#attaching-to-the-debugger-renode" id="attaching-to-the-debugger-renode">Attaching to the debugger (Renode)</a></h2>
<p>If you're using Renode, then you can connect gdb to <code>localhost:3456</code>:</p>
<pre><code class="language-text">riscv-none-elf-gdb -ex 'tar ext :3456'
</code></pre>
<p>On Renode, port <code>3333</code> also exists, but it is useful mainly for debugging machine mode, i.e., when the hardware is in the loader or inside the kernel only.</p>
<ul>
<li><code>3333</code> is useful for when Xous itself has crashed, or when you're debugging the bootloader and Xous isn't even running. It's a stop-the-world debugger. Like &quot;God Mode&quot; on the Vex, where you really can do anything. Debugging there has no effect on the emulated world, so it's like stopping time and looking at things. This port also has no concept of processes or threads, so what process you're in is arbitrary every time you pause the debugger.</li>
<li><code>3456</code> is identical to what is presented on the hardware serial port (see next section). It's invasive, since processes will keep running when you attach but their timing will be skewed. It does, however, let you attach to a given process and get actual translated memory pages. With 3333 you kind of just hope that you don't have to deal with any MMU pages in a process, which is a nonissue as long as you're just debugging the kernel or bootloader.</li>
</ul>
<h2><a class="header" href="#attaching-to-the-debugger-hardware" id="attaching-to-the-debugger-hardware">Attaching to the debugger (Hardware)</a></h2>
<p>On real hardware, you will first need to re-mux the serial port so that gdb is visible on serial. Then you can connect gdb to the target serial port.</p>
<p>For example, if you have a hardware Precursor device connected to a Raspberry Pi 3B+ with a debug HAT running Raspbian &quot;Buster&quot;, you would first run this command in <code>shellchat</code> on the hardware device itself:</p>
<pre><code class="language-text">console app
</code></pre>
<p>This switches the internal serial port mux in the Precursor to the GDB port.</p>
<p>Then, on the Raspberry pi command line, you would run this:</p>
<pre><code class="language-text">riscv-none-elf-gdb -ex 'tar ext /dev/ttyS0'
</code></pre>
<h2><a class="header" href="#debugging-a-process" id="debugging-a-process">Debugging a process</a></h2>
<p>Within the gdb server, you can switch which file you're debugging. For example, to debug the ticktimer, run:</p>
<pre><code class="language-text">(gdb) file target/riscv32imac-unknown-xous-elf/release/xous-ticktimer
</code></pre>
<p>After setting the ELF file you will need to attach to the process. Use <code>mon pr</code> or <code>monitor process</code> to list available processes. Then, use <code>attach</code> to attach to a process:</p>
<pre><code class="language-text">(gdb) mon pr
Available processes:
   1   kernel
   2   xous-ticktimer
   3   xous-log
   4   xous-names
   5   xous-susres
   6   libstd-test
(gdb) att 2
Attaching to process 2
[New Thread 2.2]
[New Thread 2.3]
0xff802000 in ?? ()
(gdb)
</code></pre>
<p>You can switch processes by sending <code>att</code> to a different PID.</p>
<h2><a class="header" href="#debugging-a-thread" id="debugging-a-thread">Debugging a thread</a></h2>
<p>To list threads, use <code>info thr</code>:</p>
<pre><code class="language-text">(gdb) info thr
  Id   Target Id         Frame
* 1    Thread 2.255      0xff802000 in ?? ()
  2    Thread 2.2        xous::definitions::Result::from_args (src=...) at src/definitions.rs:474
  3    Thread 2.3        xous::definitions::Result::from_args (src=...) at src/definitions.rs:474
(gdb)
</code></pre>
<p>To switch threads, use <code>thr [n]</code>:</p>
<pre><code class="language-text">(gdb) thr 2
[Switching to thread 2 (Thread 2.2)]
#0  xous::definitions::Result::from_args (src=...) at src/definitions.rs:474
474             match src[0] {
(gdb)
</code></pre>
<p><strong>Important Note</strong>: GDB thread numbers are different from Xous thread numbers! GDB Always starts with <code>1</code>, but Xous may have any number of threads running. GDB pays attention to the first column, and you are most likely interested in the second column.</p>
<h1><a class="header" href="#renode-emulation" id="renode-emulation">Renode Emulation</a></h1>
<p><a href="https://renode.io/">Renode</a> is a multi-device emulator written in C#. It is designed to assist in testing and development of software, and is also useful in developing new hardware blocks.</p>
<p>The emulator is available for Windows, Mac, and Linux. It is designed to simulate whole systems of devices, meaning it can easily capture the interactions between devices on a network or bus. It allows you to pause the system and inspect memory, single-step, and watch various sections of the bus.</p>
<p>There is extensive end-user documentation available at <a href="https://renode.readthedocs.io/en/latest/">Read the Docs</a>, which is highly recommended. The remainder of this chapter will cover recommendations on how to use Renode with Xous.</p>
<h2><a class="header" href="#quickstart-using-the-renode-emulator" id="quickstart-using-the-renode-emulator">Quickstart using the Renode emulator</a></h2>
<p>Xous uses <a href="https://renode.io/">Renode</a> as the preferred emulator, because it is easy to extend the hardware peripherals without recompiling the entire emulator.</p>
<p><a href="https://renode.io/#downloads">Download Renode</a> and ensure it is in your path.</p>
<p>Then, build Xous:</p>
<pre><code class="language-sh">cargo xtask renode-image
</code></pre>
<p>This will compile everything in <code>release</code> mode for RISC-V, compile the tools required to package it all up, then create an image file.</p>
<p>Finally, run Renode and specify the <code>xous-release.resc</code> REnode SCript:</p>
<pre><code class="language-sh">renode emulation/xous-release.resc
</code></pre>
<p>Renode will start emulation automatically, and will run the same set of programs as in &quot;Hosted mode&quot;.</p>
<h3><a class="header" href="#network-support" id="network-support">Network support</a></h3>
<p>If you are seeking to emulate a Xous build with apps requiring network support, then there is some additional setup.</p>
<p>Renode accepts the Ethernet frames that the EC sends to the simulated WF200, and then dumps them onto a network TAP interface called <code>renodetap</code>.</p>
<p>It is probably best to prepare the TAP interface and associated configuration before the emulation:</p>
<ul>
<li><strong>linux distro with Network Manager:</strong> <code>nmcli c add con-name renodetun type tun ifname renodetun mode tap ipv4.method shared ipv6.method ignore</code></li>
<li><strong>OpenSuSE Aeon:</strong> also requires installation of dnsmasq <code>transactional-update pkg install dnsmasq</code></li>
</ul>
<p>Start the emulation with:</p>
<pre><code class="language-sh">renode emulation/xous-release-tap.resc
</code></pre>
<p>Once the emulation is up and running then connect to one of the WiFi APs <code>Renode1</code> ... <code>Renode9</code> (any password will work)</p>
<h1><a class="header" href="#writing-renode-c-peripherals" id="writing-renode-c-peripherals">Writing Renode C# Peripherals</a></h1>
<p>Renode is written in C#, which means it has access to the entire base of C#. One feature of C# is the <code>CSharpCodeProvider</code> object which provides the <code>CompileAssemblyFromSource(CompilerParameters, string[])</code> function. This means that Renode has a runtime C# compiler built in.</p>
<p>You can <code>include</code> C# files in the Renode console or in your startup script to dynamically add new peripherals to your environment. Xous uses this extensively in Betrusted since the hardware peripherals are still under development and therefore change regularly. Updating a hardware module in Renode simply involves modifying the <code>.cs</code> file and restarting Renode. There is no additional compile step.</p>
<h2><a class="header" href="#setting-up-an-ide----visual-studio-code" id="setting-up-an-ide----visual-studio-code">Setting up an IDE -- Visual Studio Code</a></h2>
<p>It is highly recommended to use a full IDE. The Renode API can change, and it can take time to restart Renode to recompile your C# files. An IDE will provide you with tab-completion and will immediately tell you if there is a code error.</p>
<p>The core of Renode is written in a full IDE such as Visual Studio or Monodevelop. These IDEs expect a full Project file that defines a single target output -- for example an executable or a linked library. With our usage of C# there is no single target since Renode will dynamically load the source files. To work around this, we create a stub project file that tricks the IDE into loading our assembly files and providing autocomplete. We never actually <em>use</em> this project file, but it's used behind the scenes automatically.</p>
<p>Broadly speaking, there are three steps to setting up an IDE:</p>
<ol>
<li>Download Visual Studio Code</li>
<li>Copy the reference project file</li>
<li>Modify the reference project file</li>
<li>Install the C# extension.</li>
</ol>
<p>To begin with download <a href="https://code.visualstudio.com/">Visual Studio Code</a>. It is available for Windows, Linux, and Mac.</p>
<p>Next, copy <code>emulation/peripherals.csproj.template</code> to <code>emulation/peripherals.csproj</code>. This is a C# Project file that is understood by Visual Studio and Visual Studio Code. The file name <code>peripherals.csproj</code> is in the <code>.gitignore</code> file, so don't worry about accidentally checking it in.</p>
<p>Edit <code>peripherals.csproj</code> and modify <code>RenodePath</code> to point to your Renode installation where the <code>.dll</code> files are located. On Linux this is likely <code>/opt/renode/bin</code>. On Windows this may be in <code>C:\Program Files\</code>.</p>
<p>Finally, install the <a href="https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.csharp">C# for Visual Studio Code</a> extension. This extension will activate, parse your <code>.csproj</code>, and start providing autocomplete and compile suggestions.</p>
<h2><a class="header" href="#creating-a-new-peripheral" id="creating-a-new-peripheral">Creating a new Peripheral</a></h2>
<p>To create a new peripheral, simply copy an existing peripheral to a new filename under <code>emulation/peripherals/</code>, making sure the filename ends in <code>.cs</code>.</p>
<p>Many examples exist in the <code>emulation/peripherals/</code> directory, and you can find many more examples <a href="https://github.com/renode/renode-infrastructure/tree/master/src/Emulator/Peripherals/Peripherals">built into Renode</a>.</p>
<p>A simple example could be a device that provides random numbers:</p>
<pre><code class="language-cs">using Antmicro.Renode.Core;
using Antmicro.Renode.Core.Structure.Registers;
using Antmicro.Renode.Logging;

namespace Antmicro.Renode.Peripherals.Miscellaneous
{
    public class ExampleRNGServer : BasicDoubleWordPeripheral, IKnownSize
    {
        public long Size { get { return 0x100; } }
        public GPIO IRQ { get; private set; }
        private readonly PseudorandomNumberGenerator rng = EmulationManager.Instance.CurrentEmulation.RandomGenerator;
        private bool enabled = true;

        private enum Registers
        {
            CONTROL = 0x0,
            DATA = 0x4,
            STATUS = 0x8,
            AV_CONFIG = 0xc,
            RO_CONFIG = 0x10,

            READY = 0xc4,
            EV_STATUS = 0xc8,
            EV_PENDING = 0xcc,
            EV_ENABLE = 0xd0,
            URANDOM = 0xdc,
            URANDOM_VALID = 0xe0,
            TEST = 0xf8,
        }

        public ExampleRNGServer(Machine machine) : base(machine)
        {
            this.IRQ = new GPIO();
            DefineRegisters();
        }


        private void DefineRegisters()
        {

            Registers.URANDOM.Define(this)
                .WithValueField(0, 32, FieldMode.Read, valueProviderCallback: _ =&gt;
                {
                    if (!enabled)
                        return 0;
                    return (uint)rng.Next();
                }, name: &quot;URANDOM&quot;);
            Registers.DATA.Define(this)
                .WithValueField(0, 16, FieldMode.Read, valueProviderCallback: _ =&gt;
                {
                    if (!enabled)
                        return 0;
                    return (uint)rng.Next();
                }, name: &quot;DATA&quot;)
                .WithValueField(16, 16, FieldMode.Read, valueProviderCallback: _ =&gt;
                {
                    return 0xf00f;
                }, name: &quot;SIGNATURE&quot;);
            Registers.URANDOM_VALID.Define(this)
                .WithFlag(0, FieldMode.Read, valueProviderCallback: _ =&gt; { return true; }, name: &quot;URANDOM_VALID&quot;)
                .WithFlag(1, FieldMode.Read, valueProviderCallback: _ =&gt; { return enabled; }, name: &quot;ENABLE&quot;);

            Registers.CONTROL.Define(this)
                .WithFlag(0, FieldMode.Write, writeCallback: (_, val) =&gt; { enabled = val; }, name: &quot;ENABLE&quot;);
        }
    }
}
</code></pre>
<p>There's a lot to take in there, particularly if you've never dealt with C# before. Let's go over the module line-by-line.</p>
<pre><code class="language-cs">using Antmicro.Renode.Core;
using Antmicro.Renode.Core.Structure.Registers;
using Antmicro.Renode.Logging;
</code></pre>
<p>The first three lines import various packages to the current namespace. You'll most likely use these in all of your projects. Any valid C# namespace may be used, including core <code>.Net</code> libraries. This can be useful if you need networking, cryptography, or other exotic libraries. There are many useful logging functions as well. You'll notice that the final line is darker than the other two. This is because this package is currently unused -- we don't perform any logging currently. You can safely remove this final line, however it's useful to leave Logging as an import because it allows for autocompletion of Logging functions.</p>
<pre><code class="language-cs">namespace Antmicro.Renode.Peripherals.Miscellaneous {
</code></pre>
<p>Next, we define the namespace for this module. The module MUST be under a <code>namespace Antmicro.Renode.Peripherals.xxx</code> namespace. In this case, it is under <code>Antmicro.Renode.Peripherals.Miscellaneous</code>. This namespacing provides a handy structure to various peripherals.</p>
<pre><code class="language-cs">public class ExampleRNGServer : BasicDoubleWordPeripheral, IKnownSize {
</code></pre>
<p>Finally, we begin to define our class. This class is named <code>ExampleRNGServer</code>, and it inherits <code>BasicDoubleWordPeripheral</code> and <code>IKnownSize</code>.</p>
<p>The <code>BasicDoubleWordPeripheral</code> class provides several convenience functions that makes it easy to create a memory-mapped device. It means we don't need to manage accessors, and we can simply worry about the register values themselves.</p>
<p>Peripherals need to have a known size, so we inform C# that our client has a known size. The <code>I</code> stands for Interface. To find out which functions we must implement to conform to <code>IKnownSize</code>, hold Ctrl and click on <code>IKnownSize</code>. It will take you to the definition of <code>IKnownSize</code>, located inside <code>Emulator.dll</code>. You will note that the only thing we need to implement is <code>log Size { get; }</code>, which means we only need to create an accessor for the property <code>Size</code>.</p>
<pre><code class="language-cs">public long Size { get { return 0x100; } }
public GPIO IRQ { get; private set; }
private readonly PseudorandomNumberGenerator rng = EmulationManager.Instance.CurrentEmulation.RandomGenerator;
private bool enabled = true;
</code></pre>
<p>Here we define our local properties and variables. We can see the <code>Size</code> property defined here. Our peripheral goes up to <code>0xf8</code>, so we return that as a constant. This is used by Renode to ensure peripherals don't overlap, and to know which peripheral to invoke when memory is accessed.</p>
<p>There is an IRQ here as well, which is a <code>GPIO</code>. The way Renode handles interrupts is by reusing GPIO pins. We can trigger an interrupt by setting this GPIO, and the system will invoke an interrupt context on the CPU.</p>
<p>Finally there is a local variable that is part of this object and not visible outside of our class.</p>
<pre><code class="language-cs">private enum Registers
{
    CONTROL = 0x0,
    DATA = 0x4,
    STATUS = 0x8,
    AV_CONFIG = 0xc,
    RO_CONFIG = 0x10,

    READY = 0xc4,
    EV_STATUS = 0xc8,
    EV_PENDING = 0xcc,
    EV_ENABLE = 0xd0,
    URANDOM = 0xdc,
    URANDOM_VALID = 0xe0,
    TEST = 0xf8,
}
</code></pre>
<p>We define an enum called <code>Registers</code>. This is simply a mapping of register names to register numbers. It is not a particularly special enum, however correct naming of the enum values will make it easier to define the register set later on. It is standard practice to define all possible registers in this enum, even if you do not implement them right away.</p>
<pre><code class="language-cs">public ExampleRNGServer(Machine machine) : base(machine)
{
    this.IRQ = new GPIO();
    DefineRegisters();
}
</code></pre>
<p>This is the constructor for our device. It takes a single argument of type <code>Machine</code>. Because we inherit from <code>BasicDoubleWordPeripheral</code>, we will need to call the constructor for the base class. To figure out what the constructor looks like, hold Ctrl and click on <code>BasicDoubleWordPeripheral</code>. We can see that the constructor for that class simply takes one argument that's a <code>Machine</code>. Therefore, the first line of our constructor should invoke the base constructor directly. Which is what we do here.</p>
<p>We create a new GPIO and assign it to the IRQ. Renode will access our <code>IRQ</code> property if it wants to watch for interrupts. If our peripheral has no interrupts we can omit the <code>IRQ</code> property.</p>
<pre><code class="language-cs">private void DefineRegisters() {
</code></pre>
<p>Finally, we invoke the <code>DefineRegisters()</code> function. It is the most complicated function in this class, however it's where most of the work is done. Let's look at each register definition in order.</p>
<pre><code class="language-cs">Registers.URANDOM.Define(this)
    .WithValueField(0, 32, FieldMode.Read, valueProviderCallback: _ =&gt;
    {
        if (!enabled)
            return 0;
        return (uint)rng.Next();
    }, name: &quot;URANDOM&quot;);
</code></pre>
<p>The <code>Define(this)</code> function comes from <code>BasicDoubleWordPeripheralExtensions</code>, which is one of the classes provided to us as a subclass of <code>BasicDoubleWordPeripheral</code>. It allows us to define a register on an enum type.</p>
<p>The <code>WithValueField()</code> function defines a value for a register across a range of values. In this case, we define a value beginning at bit 0 that is 32-bits wide. We define this register as a <code>FieldMode.Read</code> register, meaning writes will be ignored. When a device accesses this register, the <code>valueProviderCallback</code> function will be called.</p>
<p>What follows is a C# closure. The first argument is the register itself, which we ignore since we are not interested in it. Therefore, the variable is named <code>_</code>. If the block is disabled, we return 0, otherwise we return a <code>uint</code> from the class RNG provider.</p>
<p>Finally, we name the register <code>URANDOM</code>.</p>
<pre><code class="language-cs">Registers.DATA.Define(this)
    .WithValueField(0, 16, FieldMode.Read, valueProviderCallback: _ =&gt;
    {
        if (!enabled)
            return 0;
        return (uint)rng.Next();
    }, name: &quot;DATA&quot;)
    .WithValueField(16, 16, FieldMode.Read, valueProviderCallback: _ =&gt;
    {
        return 0xf00f;
    }, name: &quot;SIGNATURE&quot;);
</code></pre>
<p>This register contains two value fields. The first is at offset 0, and is 16-bits wide. The second is at offset 16, and is also 16-bits wide.</p>
<p>The <code>valueProviderCallback</code> function is called for each field, which avoids the need for any manual bit shifting.</p>
<p>If the peripheral is not enabled, then the <code>DATA</code> field returns 0. If it is enabled, then it returns a 16-bit random value.</p>
<p>Because of the way this register is defined, the top 16 bits will always be <code>0xf00f</code>. Therefore, the register's value will be either <code>0xf00f0000</code> or <code>0xf00fRAND</code>.</p>
<pre><code class="language-cs">Registers.URANDOM_VALID.Define(this)
    .WithFlag(0, FieldMode.Read, valueProviderCallback: _ =&gt; { return true; }, name: &quot;URANDOM_VALID&quot;)
    .WithFlag(1, FieldMode.Read, valueProviderCallback: _ =&gt; { return enabled; }, name: &quot;ENABLE&quot;);
</code></pre>
<p>This register defines two flags. The first flag is at bit 0, and the second flag is at bit 1. Flags are always one-bit boolean values, which is why the <code>valueProviderCallback</code> returns <code>true</code> instead of a <code>uint</code> like we've seen in the past. Similarly to <code>WithValueField()</code>, a <code>WithFlag</code> value will call the <code>valueProviderCallback</code> for each flag, avoiding the need to do complex shifting.</p>
<pre><code class="language-cs">Registers.CONTROL.Define(this)
    .WithFlag(4, FieldMode.Write, writeCallback: (_, val) =&gt; { enabled = val; }, name: &quot;ENABLE&quot;);
</code></pre>
<p>Finally we define the <code>CONTROL</code> register. Our implementation simply has an <code>ENABLE</code> bit at offset 4. This is the first time we've seen a <code>writeCallback</code>. This closure takes two arguments: the register itself and the written value. </p>
<h2><a class="header" href="#using-the-new-peripheral" id="using-the-new-peripheral">Using the new peripheral</a></h2>
<p>To use the new peripheral, save it in a <code>.cs</code> file, then include it in Renode. For example, if it was called <code>examplerngserver.cs</code>, you would include it in Renode by running:</p>
<pre><code class="language-text">(renode) i @examplerngserver.cs
</code></pre>
<p>You can then use the <code>Miscellaneous.ExampleRNGServer</code> peripheral in any platform definition. For example, to create a new peripheral at offset <code>0x40048000</code> in the current machine, use the <code>LoadPlatformDescriptionFromString</code> command:</p>
<pre><code class="language-text">(renode) machine LoadPlatformDescriptionFromString 'rng: Miscellaneous.ExampleRNGServer @ sysbus 0x40048000'
</code></pre>
<p>Now, any accesses to <code>0x40048000</code> will be directed to your new peripheral.</p>
<h1><a class="header" href="#xous-operating-system-startup" id="xous-operating-system-startup">Xous Operating System Startup</a></h1>
<p>The Xous operating system is set up by the loader, which is responsible for unpacking data into RAM and setting up processes. It is covered in the <a href="ch05-02-loader.html">Xous Loader</a> section.</p>
<p>The loader reads a binary stream of data located in a tagged format that is discussed in the <a href="ch05-01-arguments.html">Arguments Structure</a> section. This arguments structure defines features such as the memory layout, system configuration, and initial process data.</p>
<p>Programs are loaded in flattened formats called <code>MiniELF</code>, which is documented in the <a href="ch05-03-minielf.html">MiniELF Format</a> section.</p>
<p>You may also find the following links of interest:</p>
<ul>
<li><a href="https://github.com/betrusted-io/betrusted-wiki/wiki/How-Does-Precursor-Get-to-the-Reset-Vector%3F">What happens before boot?</a> fills in the details of everything that happens before the first instruction gets run.</li>
<li>&quot;<a href="https://github.com/betrusted-io/betrusted-wiki/wiki/Secure-Boot-and-KEYROM-Layout">Secure Boot</a>&quot; and key ROM layout</li>
</ul>
<h1><a class="header" href="#system-arguments" id="system-arguments">System Arguments</a></h1>
<p>The loader and kernel use a tagged format for defining system arguments. This tagged structure is designed to be small, and only describes data. The structure does not include any executable data. Instead, it contains references to this data that may be located immediately after the structure on a storage medium.</p>
<p>The tagged structure defines a prefix that is tagged by an 8-byte structure:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Tag {
    /// Ascii-printable name, not null-terminated, in little endian format.
    tag: u32,

    /// CRC16 of the data section, using CCITT polynomial.
    crc16: u16,

    /// Size of the data section, in 4-byte words.
    size: u16,
}
<span class="boring">}
</span></code></pre></pre>
<p>Tags are stored sequentially on disk, meaning a reader can skip over tags that it does not recognize. Furthermore, it can use a combination of <code>crc16</code> and <code>size</code> to determine that it has found a valid section.</p>
<p>The <code>size</code> field is in units of 4-bytes. Therefore, a <code>Tag</code> that contains only four bytes of data (for a total of 12-bytes on disk including the <code>Tag</code>) would have a <code>size</code> value of <code>1</code>.</p>
<h2><a class="header" href="#xarg-tag----xous-arguments-meta-tag" id="xarg-tag----xous-arguments-meta-tag"><code>XArg</code> tag -- Xous Arguments Meta-Tag</a></h2>
<p>The only ordering requirement for tags is that the first tag should be an <code>XArg</code> tag. This tag indicates the size of the entire structure as well as critical information such as the size of RAM.</p>
<p>Future revisions may add to this tag, however the size will never shrink.</p>
<table><thead><tr><th>Offset</th><th>Size</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>4</td><td>Arg Size</td><td>The size of the entire args structure, including all headers, but excluding any trailing data (such as executables)</td></tr>
<tr><td>4</td><td>4</td><td>Version</td><td>Version of the XArg structure.  Currently <code>1</code>.</td></tr>
<tr><td>8</td><td>4</td><td>RAM Start</td><td>The origin of system RAM, in bytes</td></tr>
<tr><td>12</td><td>4</td><td>RAM Size</td><td>The size of system RAM, in bytes</td></tr>
<tr><td>16</td><td>4</td><td>RAM Name</td><td>A printable name for system RAM</td></tr>
</tbody></table>
<h3><a class="header" href="#xkrn-tag----xous-kernel-description" id="xkrn-tag----xous-kernel-description"><code>XKrn</code> tag -- Xous Kernel Description</a></h3>
<p>This describes the kernel image.  There must be exactly one <code>XKrn</code> tag in an arguments structure.
This image will get mapped into every process within the final 4 megabytes, and therefore the text and data
offsets must be in the range <code>0xffc0_0000</code> - <code>0xfff0_0000</code>.</p>
<table><thead><tr><th>Offset</th><th>Size</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>4</td><td>LOAD_OFFSET</td><td>Physical address (or offset) where the kernel is stored</td></tr>
<tr><td>4</td><td>4</td><td>TEXT_OFFSET</td><td>Virtual memory address where the kernel expects the program image to live.  This should be <code>0xffd00000</code>.</td></tr>
<tr><td>8</td><td>4</td><td>TEXT_SIZE</td><td>Size of the text section.  This indicates how many bytes to copy from the boot image.</td></tr>
<tr><td>12</td><td>4</td><td>DATA_OFFSET</td><td>Virtual memory address where the kernel expects the .data/.bss section to be.  This should be above <code>0xffd00000</code> and below  <code>0xffe00000</code></td></tr>
<tr><td>16</td><td>4</td><td>DATA_SIZE</td><td>Size of the .data section</td></tr>
<tr><td>20</td><td>4</td><td>BSS_SIZE</td><td>The size of the .bss section, which immediately follows .data</td></tr>
<tr><td>24</td><td>4</td><td>ENTRYPOINT</td><td>Virtual address of the <code>_start()</code> function</td></tr>
</tbody></table>
<p>The kernel will run in Supervisor mode, and have its own private stack. The address of the stack will be generated by the loader.</p>
<h3><a class="header" href="#inie-and-inif-tag----initial-elf-programs" id="inie-and-inif-tag----initial-elf-programs"><code>IniE</code> and <code>IniF</code> tag -- Initial ELF Programs</a></h3>
<p>The <code>IniE</code> and <code>IniF</code> tags describe how to load initial processes. There is one <code>IniE</code> or <code>IniF</code> for each initial program. There must be at least one <code>IniE</code> tag. <code>IniF</code> tagged processes are laid out in FLASH such that the sub-page offsets match 1:1 with their target virtual memory mapping. Thus, <code>IniF</code>-tagged processes are always memory-mapped from FLASH for XIP (execute in place) operation, where as <code>IniE</code> processes must be copied from disk into RAM and executed from the copy in RAM.</p>
<p>In other words, <code>IniE</code> processes consume more RAM because the static code base must be copied to RAM before execution. <code>IniF</code> processes consume less RAM, but not all processes can be <code>IniF</code>. In particular, the kernel and the FLASH management processes must be RAM based, because during FLASH write operations, the FLASH is unavailable for code execution reads.</p>
<p>This tag has the following values:</p>
<table><thead><tr><th>Offset</th><th>Size</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>4</td><td>LOAD_OFFSET</td><td>Position in RAM relative to the start of the arguments  block where this program is stored, or an absolute value if <code>ABSOLUTE</code>  is <code>1</code>.</td></tr>
<tr><td>4</td><td>4</td><td>ENTRYPOINT</td><td>Virtual memory address of the <code>_start()</code> function</td></tr>
</tbody></table>
<p>Following this is a list of <em>section definitions</em>. Section definitions must be sequential in RAM -- that is, it is not permitted for <code>SECTIONn_OFFSET</code> to decrease.</p>
<table><thead><tr><th>Offset</th><th>Size</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>n*3+8</td><td>8</td><td>SECTIONn_OFFSET</td><td>Virtual memory address of memory section <em>n</em></td></tr>
<tr><td>n*3+12</td><td>3</td><td>SECTIONn_SIZE</td><td>Size of memory section <em>n</em></td></tr>
<tr><td>n*3+15</td><td>1</td><td>SECTIONn_FLAGS</td><td>Flags describing memory section <em>n</em></td></tr>
</tbody></table>
<p>The fields <code>size</code>, <code>flags</code>, and <code>offset</code> together occupy 64 bits (8 bytes). The
<code>OFFSET</code> is a full 32-bit address.  The <code>SIZE</code> field is in units of
bytes, however as it is only 24 bits, meaning the largest section size
is <code>2^24</code> bytes. If these are printed as <code>u32</code> and read on the screen, the format
looks like this:</p>
<pre><code class="language-text">0xJJJJ_JJJJ 0xKK_LLLLLL
</code></pre>
<p>Where:</p>
<ul>
<li><code>J</code> is the 32-bit offset</li>
<li><code>K</code> is the 8-bit flag field</li>
<li><code>L</code> is the 24-bit size field</li>
</ul>
<h4><a class="header" href="#inie-and-inif-flags" id="inie-and-inif-flags"><code>IniE</code> and <code>IniF</code> Flags</a></h4>
<p>The <code>FLAGS</code> field contains the following four bits.  Any region may be
marked NOCOPY, however RISC-V does not allow regions to be marked
&quot;Write-only&quot;:</p>
<table><thead><tr><th>Bit</th><th>Binary</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>0b000001</td><td>NOCOPY</td><td>No data should be copied -- useful for <code>.bss</code></td></tr>
<tr><td>1</td><td>0b000010</td><td>WRITABLE</td><td>Region will be allocated with the &quot;W&quot; bit</td></tr>
<tr><td>2</td><td>0b000100</td><td>READABLE</td><td>Region will be allocated with the &quot;R&quot; bit</td></tr>
<tr><td>3</td><td>0b001000</td><td>EXECUTABLE</td><td>Region will be allocated with the &quot;X&quot; bit</td></tr>
<tr><td>4</td><td>0b010000</td><td>EH_FLAG</td><td>Region is an EH_FLAG region</td></tr>
<tr><td>5</td><td>0b100000</td><td>EH_FLAG_HDR</td><td>Region is an EH_FLAG_HEADER region</td></tr>
</tbody></table>
<p>These correspond 1:1 to the flag definitions used in the MiniELF format.</p>
<p>Programs <strong>cannot</strong> access the final four megabytes, as this memory
is reserved for the kernel. It is an error if any section enters this memory region.</p>
<h3><a class="header" href="#pnam-tag----program-names" id="pnam-tag----program-names"><code>PNam</code> Tag -- Program Names</a></h3>
<p><code>PNam</code> maps process IDs to process names. If multiple <code>PNam</code> tags exist
within a block, the first one that is encountered should take precedence.
This tag is a series of entries that take the following format:</p>
<table><thead><tr><th>Size (bytes)</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>4</td><td>PID</td><td>ID of the process that this name describes</td></tr>
<tr><td>4</td><td>Length</td><td>The length of the data that follows</td></tr>
<tr><td>varies</td><td>Data</td><td>The UTF-8 name string</td></tr>
</tbody></table>
<h3><a class="header" href="#bflg-tag----boot-flags" id="bflg-tag----boot-flags"><code>Bflg</code> Tag -- Boot Flags</a></h3>
<p>This configures various bootloader flags.  It consists of a single word
of data with various flags that have the following meaning:</p>
<ul>
<li>0x00000001 <code>NO_COPY</code>  -- Skip copying data to RAM.</li>
<li>0x00000002 <code>ABSOLUTE</code> -- All program addresses are absolute.
Otherwise, they're relative to the start of the config block.</li>
<li>0x00000004 <code>DEBUG</code>    -- Allow the kernel to access memory inside user
programs, which allows a debugger to run in the kernel.</li>
</ul>
<h3><a class="header" href="#mrex-tag----additional-memory-regions" id="mrex-tag----additional-memory-regions"><code>MREx</code> Tag -- Additional Memory Regions</a></h3>
<p>This tag defines additional memory regions beyond main system memory. This region omits main system memory, which is defined in the <code>XArg</code> tag.
The format for this tag consists of a single word defining how many additional sections there are, followed by actual section entries:</p>
<table><thead><tr><th>Offset</th><th>Size</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>4</td><td>Count</td><td>The number of additional memory entries</td></tr>
</tbody></table>
<p>Each additional memory entry is 3 words of 4-bytes each:</p>
<table><thead><tr><th>Offset</th><th>Size</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>n*3 + 4</td><td>4</td><td>Start</td><td>The start offset of this additional region</td></tr>
<tr><td>n*3 + 8</td><td>4</td><td>Length</td><td>The length of this additional region</td></tr>
<tr><td>n*3 + 12</td><td>4</td><td>Name</td><td>A 4-character name of this region that should be printable -- useful for debugging</td></tr>
</tbody></table>
<p>Additional memory regions should be non-overlapping. Creating overlapping memory regions will simply waste memory, as the loader will allocate multiple regions to track the memory yet will only allow it to be shared once.</p>
<h1><a class="header" href="#xous-loader" id="xous-loader">Xous Loader</a></h1>
<p>The Xous loader is located in the <a href="https://github.com/betrusted-io/xous-core/tree/main/loader">loader/</a> directory. This program runs in Machine mode, and makes the following assumptions:</p>
<ol>
<li>There is an Argument structure located somewhere in memory and register <code>$a0</code> points to it</li>
<li>The system has 16 MB of RAM and it is located at address <code>0x40000000</code></li>
</ol>
<p>Point #2 is flexible, and the loader has the ability to read the memory configuration out of the Argument structure, if one can accept trusting these parameters before the Argument structure is checked. However, in the current implementation, these values are hard-coded into the loader binary so that they are derived from an already verified, trusted location (see Loader Signature Checking below for why this is the case).</p>
<p>After passing the signature check, the loader runs the main loader sequence. The loader runs in two stages. The first stage is responsible for determining how much memory is required for each initial process as well as the kernel, and loading them into memory. The second stage sets up the platform-specific page tables.</p>
<h2><a class="header" href="#signature-checking-the-kernel" id="signature-checking-the-kernel">Signature Checking the Kernel</a></h2>
<p>We do not discuss precisely how we come to trust the loader itself: this responsibility falls onto a bootloader that is assumed to be burned into the ROM of the SoC running Xous. Please refer to <a href="https://github.com/betrusted-io/betrusted-wiki/wiki/How-Does-Precursor-Get-to-the-Reset-Vector%3F">this page</a> for an example of one implementation for getting to the reset vector. It turns out in Precursor that the process to check the loader is identical to that of checking the kernel.</p>
<p>Loader conditions #1 and #2, as outlined above, are set up by the bootloader. The following context is helpful to appreciate why we hard-code the RAM address and offset instead of reading it out of the loader Arguments:</p>
<ul>
<li>The Arguments to the loader describe the location and size of Kernel objects, in addition to encoding the amount and location of RAM</li>
<li>The loader and its Arguments are located in FLASH, so that it may be updated</li>
<li>It is expensive and hard to update the loader's digital signature recorded in the SoC, as it is often burned to a bank of OTP fuses</li>
<li>We assume that Kernel updates are routine, but loader updates are infrequent</li>
</ul>
<p>Because the Arguments are tightly coupled to the Kernel image, we cannot check them at the same time that the loader binary. Therefore, we must treat the Arguments as untrusted at the entry point of the loader, and ask the loader to verify the Arguments. However, the loader needs to know its location and extent of RAM to run any Argument checking. Thus this presents a circular dependency: how are we to know where our memory is, when the structure that describes our memory is designed to be changed frequently? The method chosen to break this circular dependency is to hard-code the location and amount of RAM in the loader binary itself, thus allowing the Arguments that describe the kernel to be malleable with a signature check stored in FLASH.</p>
<p>Signatures for both the loader and the kernel share a common structure. They consist of two sections: the detached signature, and the signed data itself. The detached signature has the following format in memory:</p>
<table><thead><tr><th>Offset</th><th>Size</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>4</td><td>Version</td><td>Version number of the signature record. Currently <code>1</code></td></tr>
<tr><td>4</td><td>4</td><td>Length</td><td>Length of the signed region (should be exactly +4 over the Length field in the signed region)</td></tr>
<tr><td>8</td><td>64</td><td>Signature</td><td>64-byte Ed25519 signature of the signed region</td></tr>
<tr><td>12</td><td>pad</td><td>Padding</td><td>0-pad up to 4096 bytes</td></tr>
</tbody></table>
<p>The signed region has the following format:</p>
<table><thead><tr><th>Offset</th><th>Size</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>len(payload)</td><td>Payload</td><td>The signed payload (loader or kernel)</td></tr>
<tr><td>len(payload)</td><td>4</td><td>Version</td><td>A repeat of the version number of the signature record</td></tr>
<tr><td>len(payload)+4</td><td>4</td><td>Length</td><td>len(payload) + 4 = length of all the data up to this point</td></tr>
</tbody></table>
<p>Exactly every byte in the signed region, including the Version and Length, are signed. By including the Version and Length field in the signed region, we can mitigate downgrade and length extension attacks.</p>
<p>Signatures are computed using the <a href="https://github.com/dalek-cryptography/ed25519-dalek">Dalek Cryptography Ed25519</a> crate.</p>
<p>The public key used to check the signature can come from one of three sources:</p>
<ol>
<li>A self-generated key. This is the &quot;most trusted&quot; source. Ultimately, every device should self-sign its code.</li>
<li>A third-party key. We do not handle the thorny issue of who provides the third party key, or how we come about to trust it.</li>
<li>A developer key. This is a &quot;well known&quot; key which anyone can use to sign an image.</li>
</ol>
<p>The loader will attempt to verify the kernel image, in sequence, with each of the three keys. If it fails to find any image that matches, it prints an error message to the display and powers the system down after a short delay.</p>
<p>If the image is signed with anything but the self-generated key, a visible marker (a set of fine dashed lines over the status bar) is turned on, so that users are aware that there could be a potential trust issue with the boot images. This can be rectified by re-computing a self-signature on the images, and rebooting.</p>
<p>Upon the conclusion of the signature check, the loader also does a quick check of the stack usage, to ensure that nothing ran out of bounds. This is important because the Kernel assumes that no memory pages are modified across a suspend/resume, except for the (currently) two pages of RAM allocated to the loader's stack.</p>
<h2><a class="header" href="#loading-the-os" id="loading-the-os">Loading the OS</a></h2>
<p>Once the image has been signature checked, the loader must set up the Xous kernel. Xous has a very regular structure, where everything is a process, including the kernel. What makes the kernel special is that it is process ID <code>1</code>, and its code is also mapped into the high 4 MiB of every other processes' memory space, allowing processes to run kernel code without having to swap out the <code>satp</code> (that is, the page table base).</p>
<p>The loader's responsibility is to go from a machine that has essentially a zero-ized RAM space and a bunch of archives in FLASH, to one where physical pages of memory are mapped into the correct virtual address spaces for every process.</p>
<p>This is done in several stages:</p>
<ol>
<li>Reading the configuration</li>
<li><code>Stage 1</code> - copying processes to their final runtime locations, and keeping track of all the copies</li>
<li><code>Stage 2</code> - creating a page table that reflects the copies done in <code>Stage 1</code></li>
<li>Jumping to the kernel</li>
</ol>
<h3><a class="header" href="#reading-initial-configuration" id="reading-initial-configuration">Reading Initial Configuration</a></h3>
<p>The loader needs to know basic information about the Arguments structure before it can begin. This includes information about the memory layout, extra memory regions, kernel offset, and the number of initial programs.</p>
<p>The loader performs one pass through the Arguments structure to ensure that it contains the required fields before continuing.</p>
<h3><a class="header" href="#loader-stage-1-copying-and-aligning-data" id="loader-stage-1-copying-and-aligning-data">Loader Stage 1: Copying and Aligning Data</a></h3>
<p>Stage 1 copies and aligns all of the processes, such that the sub-page offsets for the code matches the expectations that the linker set up. It also copies any data requires write access, even if is already correctly aligned. The core routine is <code>copy_processes()</code>.</p>
<p>In the case that the offsets for the memory image on FLASH line up with the virtual memory offsets, nothing needs to be done for the text, read-only data, and exception handler sections. In the case that they do not line up, a copy must be made in RAM of these sections to ensure correct alignment.</p>
<p>Virtual sections marked as <code>NOCOPY</code> must be allocated and zero-ized, and sections marked with write access must always the copied.</p>
<p>The loader reserves the top two pages for its own working stack space, and adds a configurable <code>GUARD_MEMORY_BYTES</code> buffer to determine the beginning of process space. Note that one page of the &quot;guard&quot; area is used to store a &quot;clean supend marker&quot;, which is used by the loader to check if the current power-on cycle is due to a resume, or a cold boot.</p>
<p>Currently, the total works out to an offset of 16kiB reserved from top of RAM before processes are copied. These RAM pages are &quot;lost forever&quot; and not available to the Xous kernel for any purpose. This physical offset represents the start of the loader's workspace for setting up Xous.</p>
<h4><a class="header" href="#process-copying" id="process-copying">Process Copying</a></h4>
<p>The loader consumes RAM, page-by-page, starting from the highest available physical offset, working its way down.</p>
<p>The loader iterates through the list of user process images (<code>IniE</code>/<code>IniF</code>), and copies data into physical pages of RAM based on the following set of rules:</p>
<ol>
<li>If a new page is required, decrement the &quot;top of RAM&quot; pointer by a page and zeroize the page</li>
<li>&quot;If necessary&quot;, copy (or allocate) the section from FLASH to RAM, taking care to align the target data so that it matches the expected virtual address offset</li>
<li>Zeroize any unallocated data in the page</li>
</ol>
<p>The &quot;if necessary&quot; rules are as follows:</p>
<ol>
<li>If it is an <code>IniE</code>, always copy or allocate the sections. Sections marked as <code>NOCOPY</code> are simply allocated in virtual memory and zeroized.</li>
<li>If it is an <code>IniF</code>, only copy sections marked as writeable; allocate any <code>NOCOPY</code> areas.</li>
</ol>
<p>At the conclusion of process copying, the &quot;top of RAM&quot; pointer is now at the bottom of all the physical pages allocated for the user processes.</p>
<p>At this point, the kernel is copied into RAM, and the top of RAM pointer is decremented accordingly. The algorithm is very similar to the above except there are fewer sections to deal with in the kernel.</p>
<p>Finally, the &quot;top of RAM&quot; is located at the lowest address in RAM that has been allocated for the initial process state of Xous.</p>
<h3><a class="header" href="#loader-stage-2-setting-page-tables" id="loader-stage-2-setting-page-tables">Loader Stage 2: Setting Page Tables</a></h3>
<p>Now that memory has been copied, the second stage is responsible for re-parsing the loader file and setting up the system-specific page tables. To recap, memory is laid out as follows:</p>
<ul>
<li>Top of RAM</li>
<li>Loader stack (2 pages currently)</li>
<li>Guard area (2 pages; one page used for &quot;clean suspend marker&quot;)</li>
<li>PID2</li>
<li>PID3</li>
<li>...</li>
<li>Kernel</li>
<li>Pointer to next free memory</li>
</ul>
<p>However, the page tables have not been set up.</p>
<p>Stage 2 iterates through the arguments in the same order as &quot;Stage 1&quot;, except this time we know where the &quot;bottom&quot; of total physical memory is, so we know where to start allocating pages of the page table.</p>
<p>Thus, Stage 2 walks the Arguments structure again, in the exact same order as Stage 1. For each process, it allocates the root page table (noting the SATP location), sets up the various memory sections with their requested permissions, allocates a default stack, and marks all memory as loaded by the correct process in the <code>runtime page tracker</code>, discussed in the next subsection. This is done using a series of <code>alloc</code> routines that simply decrement the &quot;top of RAM&quot; pointer and hand back pages to be stuck into page table entries.</p>
<p>Note that &quot;allocating stack&quot; simply refers to the process of reserving some page table entries for would-be stack; the actual physical memory for stack isn't allocated until runtime, when a page fault happens in stack and the kernel grabs a physical page of RAM and slots it into the stack area on demand.</p>
<p>After this is done, the loader maps all of the loader-specific sections into the kernel's memory space. In particular, the following are all mapped directly into the kernel's memory space:</p>
<ul>
<li>Arguments structure</li>
<li>Initial process list</li>
<li>Runtime page tracker</li>
</ul>
<h4><a class="header" href="#runtime-page-tracker" id="runtime-page-tracker">Runtime Page Tracker</a></h4>
<p>The <em>Runtime Page Tracker</em> is a slice of <code>PID</code>, where each entry corresponds to a page of physical RAM or I/O, starting from the lowest RAM available to the highest RAM, and then any memory-mapped I/O space. Because the loader doesn't have a &quot;heap&quot; per se to allocate anything, the runtime page tracker is conjured from a chunk of RAM subtracted from the &quot;top of free RAM&quot; pointer, and then constructed using <code>slice::from_raw_parts_mut()</code>. This slice is then passed directly onto the kernel so it has a zero-copy method for tracking RAM allocations.</p>
<p>Thus, the <em>Runtime Page Tracker</em> is a whitelist where each valid page in the system can be assigned to exactly one process. Memory that does not have an entry in the <em>Runtime Page Tracker</em> cannot be allocated. This helps prevent memory aliasing attacks in the case that a hardware module does not fully decode all the address bits, because RAM that isn't explicitly described in the SVD description of the SoC can't be allocated.</p>
<p>Thus, the image creation program must be passed a full SVD description of the SoC register model to create this whitelist. It shows up as the &quot;Additional Regions&quot; item in the Xous Arguments output as displayed by the image creation program.</p>
<p>Each page in main memory as well as each page in memory-mapped IO will get one byte of data in the <em>Runtime Page Tracker</em>. This byte indicates the process ID that the memory is assigned to. Process ID <code>0</code> is invalid, and indicates the page is free.</p>
<p>Whenever a page is allocated in the loader, it is marked in this region as belonging to the kernel -- i.e. PID 1. This region is passed to the kernel which will continue to use it to keep track of page allocations.</p>
<h4><a class="header" href="#process-allocation" id="process-allocation">Process Allocation</a></h4>
<p>The loader allocates a set of initial processes, and it must pass this list of processes to the kernel. Fundamentally a process is just three things:</p>
<ol>
<li>A memory space</li>
<li>An entrypoint</li>
<li>A stack</li>
</ol>
<p>As such, the loader needs to allocate a table with these three pieces of information that is large enough to fit all of the initial processes. Therefore, in a manner similar to the <em>Runtime Page Tracker</em>, it allocates a slice of memory that contains an <code>InitialProcess</code> <code>struct</code> that is big enough to cover all of the initial processes.</p>
<p>This structure is zeroed out, and is filled in by the Stage 2 loader.</p>
<h3><a class="header" href="#preparing-to-boot" id="preparing-to-boot">Preparing to Boot</a></h3>
<p>At this point, RAM looks something like this:</p>
<ul>
<li>Top of RAM</li>
<li>Loader stack (2 pages currently)</li>
<li>Guard area (2 pages; one page used for &quot;clean suspend marker&quot;)</li>
<li>PID2</li>
<li>PID3</li>
<li>...</li>
<li>Kernel</li>
<li>Runtime page tracker</li>
<li>Initial process table, holding pointers to root page table locations</li>
<li>Page table entries for PID2</li>
<li>Page table entries for PID3</li>
<li>...</li>
<li>Page table entries for the kernel</li>
</ul>
<p>The kernel is now ready for the pivot into virtual memory, so we perform the following final steps.</p>
<h4><a class="header" href="#argument-copying" id="argument-copying">Argument Copying</a></h4>
<p>The Arguments structure may be in RAM, but it may be located in some other area that will become inaccessible when the system is running. If configured, the Arguments structure is copied into RAM.</p>
<h4><a class="header" href="#setting-page-ownership" id="setting-page-ownership">Setting page ownership</a></h4>
<p>Mark all loader pages as being owned by <code>PID 1</code>. This ensures they cannot be reallocated later on and overwritten by a rogue process.</p>
<h2><a class="header" href="#jumping-to-the-kernel" id="jumping-to-the-kernel">Jumping to the Kernel</a></h2>
<p>The loader runs in Machine mode, which means the MMU is disabled. As soon as the loader jumps to the kernel, the CPU enters Supervisor mode with the MMU enabled and never again returns to Machine mode.</p>
<p>The loader stashes these settings in a structure called <code>backup_args</code>. This structure is currently placed at the end of loader stack, however in the future it may be allocated alongside structures such as the runtime page tracker.</p>
<p>Execution continues in <code>start_kernel</code>, which is currently located in <code>asm.S</code> (but is slated to migrate into a <code>.rs</code> file now that assembly is part of stable Rust).</p>
<p>In order to allow interrupts and exceptions to be handled by the kernel, which runs in Supervisor mode, the loader sets <code>mideleg</code> to <code>0xffffffff</code> in order to delegate all interrupts to Supervisor mode, and it sets <code>medeleg</code> to <code>0xffffffff</code> in order to delegate all CPU exceptions to the kernel.</p>
<p>The loader then does the handover by setting <code>mepc</code> (the exception return program counter - contains the virtual address of the instruction that
nominally triggered the exception) to the <code>entrypoint</code> of the kernel, and issuing a <code>reti</code> (Return from Interrupt) opcode.</p>
<p>Thus one can effectively think of this entire &quot;boot process&quot; as just one big machine mode exception that started at the reset vector, and now, we can return from this exception and resume in Supervisor (kernel) code.</p>
<h2><a class="header" href="#resuming-from-suspend" id="resuming-from-suspend">Resuming from Suspend</a></h2>
<p>The operating system supports resuming from a cold poweroff. In order to get into this state, a program in the operating system wrote some values into RAM, then issued a command to power of the CPU in the middle of an interrupt handler.</p>
<p>A system is considered to be suspended when RAM contains a valid group of murmur3-signed hashes located at the 3rd page from the end of memory. If these hashes match, then the system is considered to be in suspend.</p>
<p>The loader then skips all remaining setup, because setup was previously performed and the system is in a live state. Indeed, if the loader tried to set up the data section of processes again, it would overwrite any volatile data in RAM.</p>
<p>In order to resume, the loader triggers a <code>STATE_RESUME</code> interrupt. This interrupt is not handled yet, since interrupts are not enabled. Instead, this interrupt will stay triggered until the kernel unmasks them, at which point the kernel will resume execution in the <code>susres</code> server and process the resume.</p>
<p>It then calls the kernel with arguments similar to a full boot. It reads values from the <em>backup_args</em> array located at the bottom of stack.</p>
<p>There is one change, however. Instead of beginning inside the kernel <em>main</em> function, the kernel begins executing immediately at the previous process. This causes the kernel to skip its initialization, and the kernel will resume where it left off once the preemption timer resumes.</p>
<h1><a class="header" href="#minielf-file-format" id="minielf-file-format">MiniELF File Format</a></h1>
<p>The loader uses a miniature version of the ELF file format.</p>
<p>ELF files support multiple sections. These sections have various flags, and may contain executable code, data, nothing, or debug information.</p>
<p>Traditional embedded programming relies on linker scripts to copy executable code into a format that can be programmed. Because Xous utilises an MMU, we can use ELF files natively.</p>
<p>A problem with the ELF format is that it contains a lot of overhead. The miniaturised version used here reduces the file size considerably while making it easier for the program to be loaded.</p>
<h2><a class="header" href="#program-header" id="program-header">Program Header</a></h2>
<p>The program header contains just two pieces of information: The <em>load_offset</em>, and the <em>entrypoint</em>.</p>
<p>The <em>load_offset</em> is the offset, relative to the start of the Arguments structure, where various sections are stored. That is, if a section indicates that it is loading from address <code>0x100</code>, then the actual physical address can be calculated as:</p>
<ul>
<li><code>0x100</code> * offset_of(arguments_list) + minielf.load_offset</li>
</ul>
<p>The <em>entrypoint</em> is simply the value of the program counter when the program is first started.</p>
<h2><a class="header" href="#section-headers" id="section-headers">Section Headers</a></h2>
<p>Following the Program Header is one or more Section Headers. The ELF format supports multiple section types, and does not have a fixed data/text/bss split, instead preferring a series of flags and values. The Xous image creation process opens the ELF file for each initial program and scans its section list. It skips any section that isn't required for running -- for example, symbol names, compile-time information, and debug information.</p>
<p>If a section is required for running and has no data -- for example if it's a <code>.bss</code> section -- then it sets the <code>NOCOPY</code> flag. Otherwise, data will get copied.</p>
<p>It then sets the <code>EXECUTE</code> and/or <code>WRITE</code> flags according to the ELF header.</p>
<p>Finally, it creates a new section entry in the Arguments structure with the specified flags, offset, and size. The offset used here is relative to the start of the output image on disk. Therefore, the very first section to be written will have an offset of <code>0</code>.</p>
<h2><a class="header" href="#elf-flags" id="elf-flags">ELF Flags</a></h2>
<p>ELF supports multiple flags. For example, it is possible to mark a section as <code>Executable</code>, <code>Read-Only</code>, or <code>Read-Write</code>. Unfortunately these flags don't work well in practice, and issues can arise from various permissions problems.</p>
<p>Xous supports a subset of these flags, as documented in the <a href="ch05-01-arguments.html#inie-and-inif-flags">flags section</a> of the <code>IniE</code> and <code>IniF</code> tags.</p>
<h2><a class="header" href="#page-aligned-minielf" id="page-aligned-minielf">Page-Aligned MiniELF</a></h2>
<p>Programs that are meant to be run out of FLASH directly and not copied to RAM are laid out in the MiniELF archive format such that the sub-page address offsets (that is, the lower 12 bits) correspond 1:1 with the virtual memory mappings. This allows the FLASH copy of the MiniELF to be simply mapped into the correct location in virtual memory for the target process, instead of being copied into RAM. <code>IniF</code>-tagged sections comply to this discipline.</p>
<p>The penalty for page-aligned MiniELF is minor; primarily, a few bytes of padding have to be inserted here and there as the files are generated to ensure that the alignment requirements are met. The main overhead is the cognitive load of peeking into the next iteration of a Rust iterator to determine what the alignment of the <em>next</em> section should be so that you can finalize the padding of the <em>current</em> section.</p>
<p>However, the <code>IniE</code> format is retained as-is for historical reasons.</p>
<h1><a class="header" href="#xous-build-system-overview" id="xous-build-system-overview">Xous Build System Overview</a></h1>
<p>The Xous build system uses the <code>xtask</code> concept to perform complex tasks without needing an external build system.</p>
<p>The <code>xtask</code> concept is simply an alias under <code>.cargo/config</code> that turns <code>cargo xtask</code> into <code>cargo run --package xtask --</code>.</p>
<p>Therefore, all complex operations from building the kernel to constructing an output image are handled by <code>xtask/src/main.rs</code>, which is compiled and run as a normal Rust program.</p>
<h2><a class="header" href="#building-images" id="building-images">Building Images</a></h2>
<p>Generally, users will want to use <code>cargo xtask app-image [app 1] [app ..]</code> to build a Xous image that contains the desired list of applications. The applications are the names of crates contained in the &quot;apps/&quot; directory. Tesulting FLASH images will be called <a href="ch05-02-loader.html"><code>loader.bin</code></a> and <code>xous.img</code> in the <code>target/riscv32imac-unknown-xous-elf/release</code> directory.</p>
<p>There are also convenience commands to build emulation images, such as <code>cargo xtask run</code> (for hosted mode, where Xous runs directly on your native OS) and <code>cargo xtask renode-image</code> (for a Renode image, where a cycle accurate simulation can be run inside the Renode emulator). See Chapter 4 for more information about Renode.</p>
<h3><a class="header" href="#build-command-syntax-details" id="build-command-syntax-details">Build Command Syntax Details</a></h3>
<p>The general format of an <code>xtask</code> command is as follows:</p>
<pre><code class="language-text">cargo xtask [verb] [cratespecs ..]
    [--feature [feature name]]
    [--lkey [loader key]] [--kkey [kernel key]]
    [--app [cratespec]]
    [--service [cratespec]]
    [--no-timestamp]
</code></pre>
<p>After <code>xtask</code>, a <code>verb</code> will select one of several pre-configured sets of packages and build targets. Immediately after <code>verb</code>, one can specifay a list of 0 or more items that are interpreted as <code>cratespecs</code>.</p>
<p>The binary images merged into a FLASH image is usually built from local source, but it can actually come from many locations. Thus each <code>cratespec</code> has the following syntax:</p>
<ul>
<li><code>name</code>: crate 'name' to be built from local source</li>
<li><code>name@version</code>: crate 'name' to be fetched from crates.io at the specified version</li>
<li><code>name#URL</code>: pre-built binary crate of 'name', to be downloadeded from a server at 'URL' after the <code>#</code> separator</li>
<li><code>path-to-binary</code>: file path to a prebuilt binary image on local machine. Files in '.' must be specified as <code>./file</code> to avoid confusion with local source</li>
</ul>
<p>The exact meaning of a <code>cratespec</code> depends on the context of the verb. Generally, fully-configured builds interpret the <code>cratespec</code> as an <code>app</code>, and debug builds interpcet <code>cratepsec</code> as a <code>service</code>.</p>
<p>Both an <code>app</code> and a <code>service</code> are Xous binaries that are copied into the final disk image; however, there is an additional step that gets run in the build system for an <code>app</code> that looks up its description in <code>apps/manifest.json</code> and attempts to configure the launch menu for the app prior to running the build.</p>
<p>Additional crates can be merged in with explicit app/service treatment by preceeding the crate name with either an <code>--app</code> flag or <code>---service</code> flag.</p>
<h4><a class="header" href="#example-building-a-precursor-user-image" id="example-building-a-precursor-user-image">Example: Building a Precursor User Image</a></h4>
<p>If one were building a user image for Precursor hardware, one could use the following command to build a base system that contains no apps.</p>
<p><code>cargo xtask app-image</code></p>
<p><code>app-image</code> automatically selects a <a href="ch06-03-target-specification.html"><code>utralib</code></a> hardware target, and populates a set of base services that would be bundled into a user image. Thus this command would create an image with no apps and just the default <code>shellchat</code> management interface.</p>
<p>One could add the <code>vault</code> app and the <code>ball</code> demo app by specifying them as positional arguments like this:</p>
<p><code>cargo xtask vault ball</code></p>
<p>It is also perfectly fine to specify them using explicit flags like this:</p>
<p><code>cargo xtask --app vault --app ball</code></p>
<h4><a class="header" href="#example-system-bringup-builds" id="example-system-bringup-builds">Example: System Bringup Builds</a></h4>
<p>When doing system bringup, it's often helpful to build just the tiniest subset of Xous, and then merge the service of interest into the disk image. Let's say you are building a tiny service that is located in a separate source tree. Let's say the service is called <code>test-server</code> and your workspace is set up like this:</p>
<pre><code class="language-text">|
|-- xous-core/
|-- test-server/
</code></pre>
<p>Inside <code>test-server</code>, you would have a <code>src/main.rs</code> that looks like this:</p>
<pre><code class="language-rust noplayground ignore">use xous_api_log_server as log_server;
use std::{thread, time};

fn main() -&gt; ! {
    log_server::init_wait().unwrap();
    log::set_max_level(log::LevelFilter::Info);
    log::info!(&quot;my PID is {}&quot;, xous::process::id());

    let timeout = time::Duration::from_millis(1000);
    let mut count = 0;
    loop {
        log::info!(&quot;test loop {}&quot;, count);
        count += 1;
        thread::sleep(timeout);
    }
}
</code></pre>
<p>And a <code>Cargo.toml</code> that looks like this:</p>
<pre><code class="language-toml">[package]
name = &quot;test-server&quot;
version = &quot;0.1.0&quot;
edition = &quot;2021&quot;

[dependencies]
xous = &quot;0.9.9&quot;
log = &quot;0.4.14&quot;
xous-api-log-server = {version = &quot;0.1.2&quot;, package = &quot;xous-api-log-server&quot;}

</code></pre>
<p>Inside <code>test-server</code>, run this command to build the program:</p>
<p><code>cargo build --target riscv32imac-unknown-xous-elf --release</code></p>
<p>The command would create a Xous executable in <code>target/riscv32imac-unknown-elf/release/test-server</code>.</p>
<p>Then, in the <code>xous-core</code> source tree, you can run this command to create a runnable Xous disk image:</p>
<p><code>cargo xtask tiny ../test-server/target/riscv32imac-unknown-elf/release/test-server</code></p>
<p>The <code>tiny</code> verb selects the smallest subset of servers one can have to run the most basic OS functions, and it interprets the path to <code>test-server</code> as a <code>cratespec</code> which is injected into the <code>xous.img</code> file as another service. The Loader will automatically load <code>test-server</code> and run it concurrently with all the other Xous services in the <code>tiny</code> target.</p>
<p>You could also use the <code>libstd-test</code> verb and create the same image, but for a Renode target.</p>
<p>The advantage of this process is that you can iterate rapidly on <code>test-server</code> without triggering rebuilds of Xous, since the <code>test-server</code> program is entirely out of tree and specified as a binary file path <code>cratespec</code> to <code>xtask</code>. This is particularly useful during very early hardware bring-up of a new peripheral.</p>
<p>Note that the <code>tiny</code> and <code>libstd-test</code> targets contain a minimal subset of Xous, and not all <code>libstd</code> functions will work; for example, the <code>Net</code> and <code>File</code> functions would fail because the test image does not contain networking or PDDB services. Generally, for development that relies on higher-level APIs such as networking and filesystem, it's easier to just build the full user image, because beyond a certain point of complexity all the services become inter-dependent upon each other and there is less value in isolating their dependencies.</p>
<p>Binary <code>cratespec</code>s are also useful for handling license-incompatible crates. Xous is MIT-or-Apache licensed; thus, one cannot introduce a GPL crate into its source tree. However, one can create an executable from a GPL program, that is then copied into a Xous disk image using binary path <code>cratespec</code>s.</p>
<h2><a class="header" href="#the-internal-flow-of-the-build-system" id="the-internal-flow-of-the-build-system">The Internal Flow of the Build System</a></h2>
<p>For those curious as to what the builder does on the inside, here is the general flow of most build operations.</p>
<h3><a class="header" href="#step-0-build-the-build-system" id="step-0-build-the-build-system">Step 0: Build the Build System</a></h3>
<p>When you type <code>cargo xtask</code>, the build system will compile <code>xtask/src/main.rs</code>. This happens automatically.</p>
<h3><a class="header" href="#step-1-build-the-kernel" id="step-1-build-the-kernel">Step 1: Build the Kernel</a></h3>
<p>The build system runs <code>cargo build --package kernel --release --target riscv32imac-unknown-xous-elf</code> in the <code>kernel/</code> directory.</p>
<h3><a class="header" href="#step-2-build-the-initial-programs" id="step-2-build-the-initial-programs">Step 2: Build the Initial Programs</a></h3>
<p>The build system runs <code>cargo build --target riscv32imac-unknown-xous-elf</code> with every initial program appended as a <code>--package</code> argument.</p>
<h3><a class="header" href="#step-3-build-the-loader" id="step-3-build-the-loader">Step 3: Build the Loader</a></h3>
<p>The build system runs <code>cargo build --target riscv32imac-unknown-xous-elf --package loader</code> in the <code>loader/</code> directory.</p>
<h3><a class="header" href="#step-4-package-it-all-up" id="step-4-package-it-all-up">Step 4: Package it all Up</a></h3>
<p>The build system runs <code>cargo run --package tools --bin create-image --</code> followed by arguments to create the image.</p>
<h1><a class="header" href="#testing-crates" id="testing-crates">Testing Crates</a></h1>
<p>Cargo contains a built-in test runner. You can annotate functions with <code>#[test]</code> to indicate functions that should only be run in test mode:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn exploration() {
    assert_eq!(2 + 2, 4);
}
<span class="boring">}
</span></code></pre></pre>
<p>When you run <code>cargo test</code>, the build system will wrap each of these functions in a test harness and run them all in sequence. Importantly, these tests are all run in the same process, because the test harness is just an ordinary program with multiple &quot;main&quot; functions linked in.</p>
<h2><a class="header" href="#testing-crates-on-xous" id="testing-crates-on-xous">Testing Crates on Xous</a></h2>
<p>The <code>cargo test</code> subcommand accepts a <code>--target</code> flag, as well as the <code>--no-run</code> flag to prevent actually running the code. All we have to do is compile tests for our target, then run that executable on real hardware or in Renode:</p>
<pre><code class="language-sh">$ cargo test --target=riscv32imac-unknown-xous-elf --no-run
    Finished test [unoptimized + debuginfo] target(s) in 0.07s
  Executable unittests src/lib.rs (target/riscv32imac-unknown-xous-elf/debug/deps/gdbstub-7542e01db3053fd1)
$
</code></pre>
<p>By running this, the build system has created an ELF executable that we can load onto real hardware. The easiest way to incorporate it into real hardware is to use the <code>libstd-test</code> target as part of core:</p>
<pre><code class="language-sh">$ cd ../xous-core/
$ cargo xtask libstd-test ../gdbstub/target/riscv32imac-unknown-xous-elf/debug/deps/gdbstub-7542e01db3053fd1
$
</code></pre>
<p>You can then run the resulting image in Renode or on real hardware</p>
<p><img src="images/cargo-test-renode.jpg" alt="Renode running Test" /></p>
<h1><a class="header" href="#xous-image-creation" id="xous-image-creation">Xous Image Creation</a></h1>
<p>Xous image creation is primarily performed by the <code>create-image</code> program. This program bundles memory definitions, the kernel, and initial programs together and generates an image on-disk suitable for passing to the loader.</p>
<p>You can run this program manually to see how it works:</p>
<pre><code class="language-sh">$ cargo run -p tools --bin create-image -- --help
    Finished dev [unoptimized + debuginfo] target(s) in 0.19s
     Running `target/debug/create-image --help`
Xous Image Creator 0.1.0
Sean Cross &lt;sean@xobs.io&gt;
Create a boot image for Xous

USAGE:
    create-image [FLAGS] [OPTIONS] &lt;OUTPUT&gt; --csv &lt;CSR_CSV&gt; --kernel &lt;KERNEL_ELF&gt; --ram &lt;OFFSET:SIZE&gt; --svd &lt;SOC_SVD&gt;

FLAGS:
    -d, --debug      Reduce kernel-userspace security and enable debugging programs
    -h, --help       Prints help information
    -V, --version    Prints version information

OPTIONS:
    -c, --csv &lt;CSR_CSV&gt;          csr.csv file from litex
    -i, --init &lt;init&gt;...         Initial program to load
    -k, --kernel &lt;KERNEL_ELF&gt;    Kernel ELF image to bundle into the image
    -r, --ram &lt;OFFSET:SIZE&gt;      RAM offset and size, in the form of [offset]:[size]
    -s, --svd &lt;SOC_SVD&gt;          soc.csv file from litex

ARGS:
    &lt;OUTPUT&gt;    Output file to store tag and init information
$
</code></pre>
<p>This program generates an <a href="ch05-01-arguments.html">Arguments structure</a> based on the specified commands, and copies data from the given ELF files into an area immediately following this structure. In this manner, a complete, position-independent loadable system is generated in a single binary image.</p>
<p>This program also does rudimentary sanity checking. For example, it will ensure the kernel is loaded at a sane offset -- namely above address <code>0xff000000</code>. It will also ensure the memory regions don't overlap.</p>
<p>As a special case, it will trim the CSR section down from the reported size. In essence, while the configuration region is defined as 256 MB wide, this large region is never used in practice. In order to reduce the amount of memory required to store this data, as well as in order to remove memory aliasing attacks, the CSR region is trimmed down from the reported value to only encompass ranges that are valid.</p>
<h2><a class="header" href="#the-kernel-and-initial-programs" id="the-kernel-and-initial-programs">The Kernel and Initial Programs</a></h2>
<p>The kernel, as well as each initial program, are all packaged together in the same <code>args.bin</code> file. In order to do this, <code>create-image</code> operates in a two-pass fashion.</p>
<p>To begin with, all tags are created and lumped together. This is done first by calling <code>finalize()</code> on each tag, followed by writing them all out to disk. The <code>finalize()</code> call allows tags to update internal fields, but does not allow tags to change their size at all.</p>
<p>The <code>finalize()</code> argument takes a single argument, which describes how many additional bytes have been added to the args structure. This function may do nothing, in which case it returns zero. It may also request that additional data be added to the output, in which case it should return a nonzero value.</p>
<p>After all tags have been written, the <code>last_data()</code> function is called for each tag. This allows the tag to append data to the end of the structure.</p>
<p>An example of tags that do this include the kernel and the initial programs. They return the size of their payload in the <code>finalize()</code> call. They also use this call to update the tag data prior to writing it out.</p>
<p>They also write the actual contents of the tag during the <code>last_data()</code> call.</p>
<h1><a class="header" href="#target-specification-and-hardware-registers-with-utra" id="target-specification-and-hardware-registers-with-utra">Target Specification and Hardware Registers with UTRA</a></h1>
<p>Xous isolates target-specific code, such as the location and fields of hardware registers, inside the Unambiguous Thin Register Astraction (UTRA).</p>
<p>The UTRA is contained in the <code>utralib</code> crate, and its contents are generated from <a href="https://www.keil.com/pack/doc/CMSIS/SVD/html/svd_Format_pg.html">SVD files</a> using <a href="https://crates.io/crates/svd2utra"><code>svd2utra</code></a>. SVD itself is an XML format commonly used by hardware vendors for the interchange of SoC registers, and is a native output format of SoC building tools such as LiteX. SVD files are also readily available for many commercial MCUs.</p>
<h2><a class="header" href="#specifying-targets" id="specifying-targets">Specifying Targets</a></h2>
<p>Services that talk to hardware will typically have one or more <code>implementation</code> modules that encapsulate the target-specific back ends. These are gated with <code>#[cfg(feature=&quot;X&quot;)]</code> directives, where &quot;X&quot; is the specific build target.</p>
<p>This means that a specific build target is selected by passing a <code>--feature</code> flag during compilation, e.g. <code>--feature precursor</code>, <code>--feature hosted</code>, or <code>--feature renode</code>.</p>
<h2><a class="header" href="#about-the-utra" id="about-the-utra">About the UTRA</a></h2>
<p>UTRA is a register abstraction for accessing hardware resources. It tries to be:</p>
<ul>
<li>Unambiguous -- the access rules should be concise and unambiguous to a systems programmer with a C background</li>
<li>Thin -- it should hide constants, but not bury them so they become difficult to verify</li>
</ul>
<p>Here is an example of an ambiguous style of register access, from a
PAC generated using <a href="https://crates.io/crates/svd2rust">svd2rust</a>:</p>
<pre><code class="language-rust noplayground ignore">    // this seems clear -- as long as all the bit fields are specified
    // (they actually aren't, so some non-obvious things are happening)
    p.POWER.power.write(|w|
       w.discharge().bit(true)
        .soc_on().bit(false)
        .kbddrive().bit(true)
        .kbdscan().bits(3)
      );

    // what should this do?
    // 1. just set the discharge bit to true and everything else to zero?
    // 2. read the register first, change only the discharge bit to true, leaving the rest unchanged?
    p.POWER.power.write(|w|
       w.discharge().bit(true)
      );

    // answer: it does (1). You need to use the `modify()` function to have (2) happen.

</code></pre>
<p>While the closure-chaining is clever syntax, it's also ambiguous.
First, does the chaining imply an order of writes happening in
sequence, or do they all happen at once? The answer depends on Rust's
optimizer, which is very good and one can expect the behavior to be
the latter, but it is still write-ordering behavior that depends upon
the outcome of an optimizer and not a linguistic guarantee. Second,
the term <code>write</code> itself is ambiguous when it comes to bitfields: do we
write just the bitfield, or do we write the entire register, assuming
the rest of the contents are zero? These types of ambiguity make it
hard to audit code, especially for experts in systems programming
who are not also experts in Rust.</p>
<p>The primary trade-off for achieving unambiguity and thinness is less
type checking and type hardening, because we are not fully taking
advantage of the advanced syntax features of Rust.</p>
<p>That being said, a certain degree of deliberate malleability in the
register abstraction is desired to assist with security-oriented
audits: for a security audit, it is often just as important to ask
what the undefined bits do, as it is to check the settings of the
defined bits. Malleabilty allows an auditor to quickly create targeted
tests that exercise undefined bits. Existing Rust-based access crates
create strict types that eliminate the class of errors where constants
defined for one register are used in an incorrect type of register,
but they also make it very hard to modify in an ad-hoc manner.</p>
<h2><a class="header" href="#utra-api-details" id="utra-api-details">UTRA API Details</a></h2>
<p>This crate is designed to serve as an alternative to <code>svd2rust</code>. It generates
a crate which consists of:</p>
<ol>
<li>A library which is used to perform register accesses</li>
<li>A &quot;header file&quot; (library) that is auto-generated from a given <code>soc.svd</code> file</li>
</ol>
<p>The library provides the a function template for <code>CSR</code> that provides the following
methods:</p>
<ul>
<li><code>.r(reg: Register) -&gt; T</code> - Read. Reads the entire contents of a CSR</li>
<li><code>.rf(field: Field) -&gt; T</code> - Read Field. Read a CSR and return only the masked and shifted value of a sub-field</li>
<li><code>.wo(reg: Register, value:T)</code> - Write only. Write <code>value</code> into a register, replacing its entire contents</li>
<li><code>.wfo(field: Field, value:T)</code> - Write field only. Write <code>value</code> into a field of a register, zeroizing all the other fields and replacing its entire contents</li>
<li><code>.rmwf(field: Field, value:T)</code> - Read-modify-write a register. Replace just the contents of <code>field</code> while leaving the other fields intact. The current implementation makes no guarantees about atomicity.</li>
</ul>
<p><code>Register</code> and <code>Field</code> are generated by the library; <code>Field</code> refers to
the <code>Register</code> to which it belongs, and thus it is not necessary to
specify it explicitly. Furthermore, the base address of the <code>CSR</code> is
bound when the object is created, which allows the crate to work both
with physical and virtual addresses by replacing the base address with
the desired value depending upon the active addressing mode.</p>
<p>In addition to the <code>CSR</code> function template, convenience constants for
the CSR base, as well as any memory bases and interrupts, are also
generated by this crate.</p>
<p>This set of API calls supports the most common set of use cases, which
is reading, writing, and updating single fields of a register, or
entire registers all at once.</p>
<p>The API does not natively support setting two fields
simultaneously. This is because there can be nuances to this that
depend upon the hardware implementation, such as bit fields that are
self-resetting, registers that self-clear on read, or registers that
have other automatic and implicit side effects.</p>
<p>Users that require multiple bit fields to be set simultaneously must
explicitly read the CSR value, bind it to a temporary variable, mask
out the fields they want to replace, and combine in the values before
writing it back to the CSR.</p>
<p>To aid with this, the following helper functions are also available:</p>
<ul>
<li><code>zf(field:Field, value:T) -&gt; T</code> - Zeroize field. Take bits corresponding to <code>field</code> and set it to zero in <code>value</code>, leaving other bits unchanged</li>
<li><code>ms(field:Field, value:T) -&gt; T</code> - Mask and shift. Take value, mask it to the field width, and then shift to its final position.</li>
</ul>
<p>The idea here is that the <code>.r(register)</code> method is used to read the
entire register; then successive <code>.zf(field, value)</code> calls are made to
clear the fields prior to setting. Field values are OR'd with the
result of <code>.ms(field, value)</code> to create the final composite register
value.  Finally, <code>.wo(value)</code> is used to overwrite the entire
register with the final composite register value.</p>
<p>The <code>.ms(field,value)</code> can also be used to synthesize initial register
values that need to be committed all at once to a hardware register,
before a <code>.wo(value)</code> call.</p>
<h2><a class="header" href="#example-usage" id="example-usage">Example Usage</a></h2>
<p>Let's assume you've used svd2utra.py to create a <code>utra</code> crate in the
same directory as svd2utra.py, and you've added this to your <code>Cargo.toml</code> file.
Now, inside your <code>lib.rs</code> file, you might have something like this:</p>
<pre><code class="language-rust noplayground ignore">use utra

fn test_fn() {
        // Audio tests

        // The audio block is a pointer to *mut 32.
        let mut audio = CSR::new(HW_AUDIO_BASE as *mut u32);

        // Read the entire contents of the RX_CTL register
        audio.r(utra::audio::RX_CTL);

        // Or read just one field
        audio.rf(utra::audio::RX_CTL_ENABLE);

        // Do a read-modify-write of the specified field
        audio.rmwf(utra::audio::RX_CTL_RESET, 1);

	// Do a multi-field operation where all fields are updated in a single write.
	// First read the field into a temp variable.
        let mut stat = audio.r(utra::audio::RX_STAT);
	// in read replica, zero EMPTY and RDCOUNT
	stat = audio.zf(utra::audio::RX_STAT_EMPTY, stat);
	stat = audio.zf(utra::audio::RX_STAT_RDCOUNT, stat);
	// in read replica, now set RDCOUNT to 0x123
	stat |= audio.ms(utra::audio::RX_STAT_RDCOUNT, 0x123);
	// commit read replica to register, updating both EMPTY and RDCOUNT in a single write
	audio.wo(utra::audio::RX_STAT, stat);

        // UART tests

        // Create the UART register as a pointer to *mut u8
        let mut uart = CSR::new(HW_UART_BASE as *mut u8);

        // Write the RXTX field of the RXTX register
        uart.wfo(utra::uart::RXTX_RXTX, b'a');

        // Or you can write the whole UART register
        uart.wo(utra::uart::RXTX, b'a');
        assert_ne!(uart.rf(pac::uart::TXFULL_TXFULL), 1);

        // Anomalies

        // This compiles but requires a cast since `audio` is a pointer to
        // u32, whereas `uart` is a pointer to u8.
        audio.wfo(utra::uart::RXTX_RXTX, b'a' as _);

        // This also compiles, despite the fact that the register offset is
        // mismatched and nonsensical
        audio.wfo(utra::uart::TXFULL_TXFULL, 1);
}

</code></pre>
<h1><a class="header" href="#messages-and-message-passing" id="messages-and-message-passing">Messages and Message Passing</a></h1>
<p>Messages form the basis of interprocess communication on Xous. A process exists in isolation and can only communicate to the outside world by sending messages. The limited API provided by the kernel means that almost all interactions are provided by userspace Servers, which must be communicated with using Messages.</p>
<p><img src="images/messaging-arch.png" alt="overview of message passing" /></p>
<h2><a class="header" href="#connecting-to-and-disconnecting-from-servers" id="connecting-to-and-disconnecting-from-servers">Connecting to and Disconnecting from Servers</a></h2>
<p>To connect to a server you must supply it an <code>Server ID</code>. A <code>Server ID</code> is a 16-byte value of some sort that is shared in a universal namespace. If you know a Server's <code>Server ID</code> then you can connect to that Server.</p>
<p>There are a few well-known <code>Server ID</code>s. These include bare minimum IDs that are required by any process to do anything useful. They are:</p>
<ul>
<li><em>b&quot;xous-log-server &quot;</em>: Output log messages to the console, as well as basic <code>println!()</code> support</li>
<li><em>b&quot;ticktimer-server&quot;</em>: Used for <code>sleep()</code> as well as time-based Mutexes</li>
<li><em>b&quot;xous-name-server&quot;</em>: A central nameserver that is used for connecting to all other servers</li>
</ul>
<p>To connect to a Server, call <code>xous::connect()</code>. For example, to connect to the <code>ticktimer-server</code>, call:</p>
<pre><code class="language-cs">let connection_id = xous::connect(xous::SID::from_bytes(b&quot;ticktimer-server&quot;).unwrap())?;
</code></pre>
<p>This will provide you a Connection to that server. If the Server is not available, the call will block until it is created. To fail if the server does not exist, use <code>try_connect()</code> instead of <code>connect()</code>.</p>
<h2><a class="header" href="#connection-limitations" id="connection-limitations">Connection Limitations</a></h2>
<p>Connections are limited on a per-process basis. Each process may only establish a connection to at most 32 servers. When this number is exceeded, <code>xous::connect()</code> will return <code>Error::OutOfMemory</code>.</p>
<p>If you call <code>xous::connect()</code> twice with the same <code>Server ID</code>, then you will get the same <code>connection_id</code>.</p>
<h2><a class="header" href="#disconnecting" id="disconnecting">Disconnecting</a></h2>
<p>To disconnect from a server, call <code>unsafe { xous::disconnect(connection_id)};</code>. This function is <code>unsafe</code> because you can copy connection IDs, so it is up to you to ensure that they are no longer in use when disconnecting.</p>
<p>For example, if you <code>connect()</code> to a Server and spawn a thread with that connection ID, you should only call <code>disconnect()</code> once that thread has finished with the connection. Similarly, if you <code>Copy</code> the connection ID to the thread, you must make sure that <strong>both</strong> uses of the Connection ID are destroyed prior to disposing of the connection.</p>
<p>Because of this, it is recommended that you use an <code>ARC&lt;CID&gt;</code> in order to ensure that the connection is only closed when it is no longer in use.</p>
<p>Furthermore, recall that subsequent calls to <code>connect()</code> with the same argument will reuse the <code>connection_id</code>. Because of this, it is vital that you only call <code>disconnect()</code> when you are certain that all instances are finished with the connection.</p>
<h2><a class="header" href="#message-overview" id="message-overview">Message Overview</a></h2>
<p>Messages come in five kinds: Scalar, BlockingScalar, Borrow, MutableBorrow, and Send. <code>Scalar</code> and <code>Send</code> messages are nonblocking and return immediately, while the others wait for the Server to respond.</p>
<p><code>Borrow</code>, <code>MutableBorrow</code>, and <code>Send</code> all detach memory from the client and send it to the server.</p>
<h2><a class="header" href="#scalar-and-blockingscalar-messages" id="scalar-and-blockingscalar-messages">Scalar and BlockingScalar Messages</a></h2>
<p>These messages allow for sending four <code>usize</code>s of data plus one <code>usize</code> of command. This can be used to send short updates to the Server. <code>Scalar</code> messages return to the client immediately, meaning the Server will receive the message after a short delay.</p>
<p><code>BlockingScalar</code> messages will pause the current thread and switch to the Server immediately. If the message is handled quickly, the Server can respond to the message and switch back to the Client before its quantum expires.</p>
<p><code>BlockingScalar</code> messages can return one or two <code>usize</code>s worth of data by returning <code>Result::Scalar1(usize)</code> or <code>Result::Scalar2(usize, usize)</code>.</p>
<p>As an example of what can be done, the ticktimer server uses <code>BlockingScalar</code> messages to implement <code>msleep()</code> by delaying the response until a timer expires.</p>
<h2><a class="header" href="#borrow-mutableborrow-and-send-messages" id="borrow-mutableborrow-and-send-messages">Borrow, MutableBorrow, and Send Messages</a></h2>
<p>These messages allow for sending memory from one process to another. Memory must be page-sized and aligned, but may be any memory available to a process. For example, a hardware process may want to reserve all MMIO peripherals in the system and then share them with processes as desired.</p>
<p>The memory message types allow for one <code>usize</code> worth of tag data which can be used to describe what the message is used for.</p>
<p>Furthermore, messages may also contain two advisory fields: <code>offset</code> and <code>valid</code>. These fields may be used to define an offset with the memory block where interesting data occurs. Similarly, the <code>valid</code> field could be used to define how large the data is.</p>
<p>When memory is passed via <code>MutableBorrow</code> then the memory is mapped into the Server's address space as writable. Additionally, the <code>offset</code> and <code>valid</code> fields become writable and may be updated in the server. As an example, if a Server implemented <code>bzero()</code> to clear a memory range to zero, then it might clear the contents of the buffer, then set both <code>offset</code> and <code>valid</code> to 0.</p>
<p>Internally, the <code>MutableBorrow</code> is updated by passing the new fields to <code>ReturnMemory()</code> where it gets updated in the client.</p>
<h1><a class="header" href="#xous-names" id="xous-names">Xous Names</a></h1>
<p>Servers are identified by a 128-bit ID number in Xous. Anyone with knowledge of the 128-bit ID number can make requests to that server.</p>
<p>Some servers have &quot;well-known names&quot;. These servers are designed to accept any number of connections and all of its APIs are considered safe for public use.</p>
<p>Other servers may have sensitive API calls. Their 128-bit IDs are treated as a secret.</p>
<p>In order to discover their ID, these servers register their ID in <code>xous-names</code>, along with a 64-byte <code>server name</code> which is a unique plaintext description of the server, and a <code>MaxConnections</code> which is the maximum number of processes allowed to connect to the registered server.</p>
<p><img src="images/xous-names.png" alt="overview of Xous names" /></p>
<h2><a class="header" href="#well-known-names" id="well-known-names">Well-Known Names</a></h2>
<p>A few servers have well-known names:</p>
<ul>
<li>log server: needed to debug name resolution issues</li>
<li>ticktimer: in case you want to delay before connecting to a server</li>
<li>Xous Names: the name server itself has a well known name</li>
<li>Some <code>std</code> library servers, which should not be connected to directly by user processes but instead through <code>libstd</code> calls.</li>
</ul>
<p>Well-known servers have a name like <code>b&quot;xous-name-server&quot;</code>, which reads like ASCII text but fits in exactly 128 bits: you just have to know the magic string, and you can connect to them.</p>
<p>Application programers will never need to know this name, because it is encapsulated within the objects that access the servers. For example, <code>XousNames::new()</code> &quot;just knows&quot; the name, so to access <code>xous-names</code> one simply needs to create a new <code>XousNames</code> object.</p>
<h2><a class="header" href="#discovered-names" id="discovered-names">Discovered Names</a></h2>
<p>All other servers have their names registered as a 64-byte free-from <code>u8</code> array, which by convention maps to ASCII text (nothing prevents you from doing weird things that don't map to unicode, but, please don't). The resulting server ID is a cryptographically random 128-bit ID, which makes it effectively unguessable. Note that no checks are done for collisions with the &quot;well known&quot; names, because the chance that the TRNG would output the string <code>b&quot;xous-name-server&quot;</code> by chance is vanishingly small.</p>
<p>When registering a server, one might invoke a call like this:</p>
<pre><code class="language-rust noplayground ignore">    let xns = xous_names::XousNames::new().unwrap();
    let net_sid = xns
        .register_name(api::SERVER_NAME_NET, None)
        .expect(&quot;can't register server&quot;);
</code></pre>
<p>or this:</p>
<pre><code class="language-rust noplayground ignore">    let xns = xous_names::XousNames::new().unwrap();
    let keys_sid = xns
        .register_name(api::SERVER_NAME_KEYS, Some(3))
        .expect(&quot;can't register server&quot;);
</code></pre>
<p>Generally, the server name is defined as a string within the <code>api.rs</code> section, so that other crates can refer to it via the API. In the case of the <code>net</code> crate, the maximum connection limit is <code>None</code>, which means that any processes may connect to the <code>net</code> crate. In the case of the <code>root keys</code> crate, the number of connections to it is limited to 3 by the <code>Some(3)</code> argument.</p>
<p>In this case, the first three processes that attempt to connect to the <code>root keys</code> crate are handed out it's 128-bit server ID. Later processes that attempt to connect will be denied. This is a &quot;trust on first use&quot; model similar to how SSH maps host public keys to IP addresses.</p>
<p>Generally, sensitive servers like <code>root keys</code> are encapsulated by other processes that act as firewalls to it. So, if there were a hypothetical need to dole out derived keys from the <code>root keys</code> set, a second <code>derived keys</code> server might be created which can accept any number of connections, and one more connection would be added to the <code>root keys</code> connection count for the <code>derived keys</code> server. The <code>derived keys</code> server would thus act as a firewall to the <code>root keys</code> server.</p>
<p>Furthermore, as a rule, the number of processes created by a system must be static and known on boot in order for this system to work. This is because the most secure operations will not be allowed to be conducted until all of the servers that have specified a connection limit have their connection tables fully occuppied. Therefore it is not allowed to, for example for the hypothetical <code>derived keys</code> to connect to the <code>root keys</code> server at some point during runtime, and then de-allocate its connection when it no longer needs it. Instead, <code>dervied keys</code> should eagerly connect to the <code>root keys</code> on boot so that it can reserve and permanently hold its slot in the connection table.</p>
<p>The goal of this is to disallow a rogue or unexpected process from connecting to sensitive servers through the Xous Names discovery mechanism.</p>
<h1><a class="header" href="#caller-idioms" id="caller-idioms">Caller Idioms</a></h1>
<p>There are two flavors of messages in Xous: <code>scalar</code> or <code>memory</code> messages. <code>scalar</code> messages are pass-by-register and have a limited size, but are very fast. <code>memory</code> messages are pass-by-memory, and can be large, but are slower.</p>
<p>There are (so far) four common types of caller patterns used in Xous:</p>
<ol>
<li>Non-synchronizing: these are &quot;fire and forget&quot; messages that don't block(*) and have no synchronization guarantee.</li>
<li>Synchronous: these block and wait for a response from the callee. The caller can do nothing else until this message is handled.</li>
<li>Asynchronous: these don't block, and expect a response at some time later via a &quot;push notification&quot;.</li>
<li>Deferred-response: these block the caller, but the callee is not allowed to block.</li>
</ol>
<p>Type (1) is implemented using <code>send</code> on <code>memory</code> messages, or vanilla <code>scalar</code> messages on <code>scalar</code> types.</p>
<p>The remaining types will involve a <code>lend</code> or <code>lend_mut</code> on <code>memory</code> messages, or <code>blocking_scalar</code> on <code>scalar</code> types.</p>
<p>Before diving in, it is helpful to review the <a href="ch07-00-messages.html">messaging architecture</a> of Xous:</p>
<p><img src="images/messaging-arch.png" alt="overview of message flow" /></p>
<p>Each server consists at its core of an event loop. While event loops are allowed to be non-blocking, this is an edge case and in general all event loops are blocking: when an event loop blocks, it is de-scheduled and consumes zero CPU resources, allowing us to stop the CPU clock and save power.</p>
<p>An incoming message will wake up the process, at which point the process shall decode and process the message. From here, the process may issue messages to other servers. Memory <code>send</code> and Scalar <code>scalar</code> messages will not stop the execution flow; the outgoing messages are simply placed in the destination queue and life goes on. However, blocking message types <code>lend</code>, <code>lend_mut</code>, and <code>blocking_scalar</code> will cause the message to be placed in the destination queue, and the current thread yields the remainder of its quanta to the destination thread. The blocked thread will remain stopped at that point of execution until the blocking message types are &quot;returned&quot;. At this point the blocked thread is re-queued for execution. Execution will resume either on a time-based pre-emption boundary, or possibly earlier if the returning process completes its task before its quanta is up and enters a blocking state (that is, waiting on a new incoming message, or a response to a new outgoing blocking message).</p>
<p>⚡ Key Concept ⚡</p>
<p>Memory messages implicitly return to callers on <code>Drop</code>. Thus, there is no explicit &quot;return&quot; call in Xous for memory messages. Thus, one must use Rust's borrow checker to schedule the return. Specifically:</p>
<ul>
<li>Synchronous messages return as soon as the current message goes out of scope, e.g., at the bottom of the event loop.</li>
<li>Deferred-response is implemented by binding the current message to an <code>Option&lt;MessageEnvelope&gt;</code> type that is external to the main event loop.
<ul>
<li>By sticking the message into a <code>Some()</code>, the message is not allowed to go out of scope, the <code>Drop</code> is never called, and thus the caller blocks.</li>
<li>However, the callee is free to continue on with its processing.</li>
<li>A return is triggered by calling <code>take()</code> on the enclosing <code>Option</code>. This moves the message out of the <code>Option</code> and into the current scope, where the message can now be modified with a return value. Once that operation ends, the message goes out of scope, <code>Drop</code> is called, and likewise, data is returned to the caller</li>
</ul>
</li>
</ul>
<p>⚠️ IPC Interoperability ⚠️</p>
<p>In many places Xous offers <code>usize</code> as arguments for IPC calls. This has a platform-dependent size, and in fact, the size can be different between caller and callee if you're passing messages between disparate hosts (which is actually a thing that is allowed on Xous).</p>
<p>For maximum compatibility, the recommendation is to restrict all IPC implementations to a <code>u32</code>-in-<code>usize</code>, unless you never intend to run on a 32-bit platform. <strong>Note</strong>: the target Precursor hardware is a 32-bit platform.</p>
<h2><a class="header" href="#basic-template" id="basic-template">Basic Template</a></h2>
<p>With this overview, we can now give an example of each of the four types of messages. In general, we assume that services are organized into at least three files:</p>
<ul>
<li><code>lib.rs</code> -- the caller-side API that formats native Rust data into IPC messages</li>
<li><code>main.rs</code> the server-side API that unpacks IPC messages and acts on them</li>
<li><code>api.rs</code> -- data structures &amp; definitions shared between caller and callee</li>
</ul>
<p>Note that none of these are mandatory -- for example, a pure client-side library like our AES implementation has only a <code>lib.rs</code>; and, an application that offers no services and has only a main function would have only a <code>main.rs</code>.</p>
<p>Below is an example of what these files might look like in a very minimal server implementation.</p>
<pre><code class="language-rust noplayground ignore">// inside lib.rs
pub mod api;
pub use api::*;
use xous::{CID, send_message};
use num_traits::*;
use core::sync::atomic::{AtomicU32, Ordering};
static REFCOUNT: AtomicU32 = AtomicU32::new(0);

pub struct MyService {
    conn: CID,
}
impl MyService {
    pub fn new() -&gt; Self {
        let xns = xous_names::XousNames::new().expect(&quot;couldn't connect to XousNames&quot;);
        REFCOUNT.fetch_add(1, Ordering::Relaxed);
        let conn = xns.request_connection_blocking(api::SERVER_NAME_MYSERVICE).expect(&quot;Can't connect to MyService&quot;);
        MyService {
            conn
        }
    }
    // ------ library methods to be discussed in detail below ------
}
/// Automatic disconnect on dropping the final instance of this connection
impl Drop for MyService {
    fn drop(&amp;mut self) {
        if REFCOUNT.fetch_sub(1, Ordering::Relaxed) == 1 {
            unsafe{xous::disconnect(self.conn).unwrap();}
        }
    }
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// inside api.rs
pub(crate) const SERVER_NAME_MYSERVICE: &amp;str     = &quot;_Any descriptive and unique name under 64 chars_&quot;;

#[derive(num_derive::FromPrimitive, num_derive::ToPrimitive, Debug)]
pub(crate) enum Opcode {
    /// Define various operations here
    DoNonSync,
    // ------ API opcodes to be discussed in detail below ------
    /// Exits the server
    Quit,
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// inside main.rs
#![cfg_attr(target_os = &quot;none&quot;, no_main)]

mod api;
use api::*;
use num_traits::*;

#[xous::xous_main]
fn xmain() -&gt; ! {
    log_server::init_wait().unwrap();
    log::set_max_level(log::LevelFilter::Info);
    log::info!(&quot;my PID is {}&quot;, xous::process::id());

    let xns = xous_names::XousNames::new().unwrap();
    let sid = xns.register_name(api::SERVER_NAME_MYSERVER, None).expect(&quot;can't register server&quot;);
    loop {
        let msg = xous::receive_message(sid).unwrap();
        match FromPrimitive::from_usize(msg.body.id()) {
            Some(Opcode::DoNonSync) =&gt; xous::msg_scalar_unpack!(msg, _, _, _, _, {
                // do stuff here
            }),
            // ------ options to be discussed in detail below ------
            Some(Opcode::Quit) =&gt; {
                xous::return_scalar(msg.sender, 1).expect(&quot;couldn't ack quit&quot;);
                break;
            },
            None =&gt; log::error!(&quot;couldn't convert opcode: {:?}&quot;, msg),
        }
    }
    // clean up our program
    xns.unregister_server(sid).unwrap();
    xous::destroy_server(sid).unwrap();
    xous::terminate_process(0)
}

</code></pre>
<p>With the above template in mind, click on the following for examples of each of the four patterns, broken down into each of <code>Scalar</code> and <code>Memory</code> types when applicable.</p>
<ul>
<li><a href="ch07-03-nonsynchronizing.html">Non-synchronizing</a></li>
<li><a href="ch07-04-synchronizing.html">Synchronous</a>. Includes an example of how to use raw messages (instead of <code>rkyv</code>) for serializing data.</li>
<li><a href="ch07-05-asynchronous.html">Asynchronous</a> or &quot;push notifications&quot;</li>
<li><a href="ch07-06-deferred.html">Deferred response</a></li>
<li><a href="ch07-07-forwarding.html">Forwarding messages</a></li>
</ul>
<h1><a class="header" href="#non-synchronizing-idioms" id="non-synchronizing-idioms">Non-Synchronizing Idioms</a></h1>
<h2><a class="header" href="#scalar-pattern" id="scalar-pattern">Scalar Pattern</a></h2>
<p>A scalar non-synchronizing call has the following characterisics:</p>
<ul>
<li>Up to 4 <code>u32</code>-sized arguments</li>
<li>Caller does not block</li>
<li>Callee does not return any result</li>
<li>No guarantee of synchronization between caller and callee
<ul>
<li>Side effects may happen at an arbitrary time later</li>
<li>Messages are guaranteed to arrive in order</li>
</ul>
</li>
</ul>
<pre><code class="language-rust noplayground">// api.rs
pub(crate) enum Opcode {
    Lights,
    // ... and other ops
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// lib.rs:
impl MyService {
    // ... new(), etc.

    /// Tell the main loop to set the state of lights. When this call exits, all we know is
    /// a message is &quot;en route&quot; to the main loop, but we can't guarantee anything has happened.
    pub fn set_lights(&amp;self, state: bool) -&gt; Result&lt;(), xous::Error&gt; {
        send_message(self.conn,
            Message::new_scalar(Opcode::Lights.to_usize().unwrap()),
                if state {1} else {0},
                0,
                0,
                0
            )
        ).map(|_|())
    }
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// main.rs:
fn xmain() -&gt; ! {
    // ... preamble
    loop {
        let msg = xous::receive_message(sid).unwrap();
        match FromPrimitive::from_usize(msg.body.id()) {
            /// This will get processed whenever the server gets scheduled, which has no strict
            /// relationship to the caller's state. However, messages are guaranteed
            /// to be processed in-order.
            Some(Opcode::Lights) =&gt; xous::msg_scalar_unpack!(msg, state, _, _, _, {
                if state == 1 {
                    turn_lights_on();
                } else {
                    turn_lights_off();
                }
            }),
            // .. other match statements
        }
    }
    // ... postamble
}
</code></pre>
<h2><a class="header" href="#memory-pattern" id="memory-pattern">Memory Pattern</a></h2>
<p>A memory non-synchronizing call has the following characterisics:</p>
<ul>
<li>Messages are sent in blocks rounded up to the nearest 4096-byte page size</li>
<li>Caller does not block</li>
<li>Callee does not return any result</li>
<li>No guarantee of synchronization between caller and callee
<ul>
<li>Side effects may happen at an arbitrary time later</li>
<li>Messages are guaranteed to arrive in order</li>
</ul>
</li>
</ul>
<pre><code class="language-rust noplayground ignore">// api.rs
pub(crate) enum Opcode {
    // use `rkyv` to serialize a memory message and send
    PushDataRkyv,
    // example of explicit serialization
    PushDataExplicit,
    // ... and other ops
}
/// `rkyv` can be used as a convenience method to serialize data in complex structures.
/// Almost any type can be contained in the structure (enums, other structures), but the
/// type must also `derive` the `rkyv` Archive, Serialize, and Deserialize traits.
/// Thus one cannot simply seralize a `std::string::String`; it must be transcribed into
/// a `xous_ipc::String::&lt;N&gt;` type which has a defined allocation size of `N`.
#[derive(rkyv::Archive, rkyv::Serialize, rkyv::Deserialize)]
pub struct CompoundData {
    pub data: [u8; 1000],
    pub len: u16,
    pub description: xous_ipc::String::&lt;128&gt;,
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// lib.rs:
impl MyService {
    // ... new(), etc.

    /// Send some `data` to the server. It'll get there when it gets there.
    /// This example uses `rkyv` to serialize data into a compound structure.
    pub fn push_data_rkyv(&amp;self, data: &amp;[u8], desc: &amp;str) -&gt; Result&lt;(), xous::Error&gt; {
        let mut rec = CompoundData {
            data: [0u8; 1000],
            len: 0,
            description: xous_ipc::String::new(),
        };
        if data.len() &gt; rec.data.len() {
            return Err(xous::Error::OutOfMemory);
        }
        for (&amp;s, d) in data.iter().zip(rec.data.iter_mut()) {
            *d = s;
        }
        data.len = data.len() as u16;
        rec.description.append(desc).ok(); // overflows are silently truncated

        // now consume `rec` and turn it into a Xous::Buffer, which can then be mapped into the
        // callee's memory space by `send`
        let buf = Buffer::into_buf(rec).or(Err(xous::Error::InternalError))?;
        buf.send(self.conn, Opcode::PushDataRkyv.to_u32().unwrap()).map(|_| ())
    }
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// main.rs:
fn xmain() -&gt; ! {
    // ... preamble
    let mut storage = Vec::&lt;CompoundData&gt;::new();
    let mut raw_data = [0u8; 32];
    loop {
        let msg = xous::receive_message(sid).unwrap();
        match FromPrimitive::from_usize(msg.body.id()) {
            /// This will get processed whenever the server gets scheduled, which has no strict
            /// relationship to the caller's state. However, messages are guaranteed
            /// to be processed in-order.
            Some(Opcode::PushDataRkyv) =&gt; {
                let buffer = unsafe { Buffer::from_memory_message(msg.body.memory_message().unwrap()) };
                // `.to_original()` automatically makes a copy of the data into my process space.
                //    This adds overhead and time, but your original types are restored.
                // `.as_flat()` will use the data directly out of the messages' memory space without copying it,
                //    but it introduces some type complexity. We don't give an example here, but you may find
                //    one in the TRNG's `FillTrng` implementation, where we avoid making two copies of the
                //    data for a more performant implementation.
                let data = buffer.to_original::&lt;PushDataRkyv, _&gt;().unwrap();
                storage.push(data);
            }
            // .. other match statements
        }
    }
    // ... postamble
}
</code></pre>
<h1><a class="header" href="#synchronizing" id="synchronizing">Synchronizing</a></h1>
<h2><a class="header" href="#scalar-pattern-1" id="scalar-pattern-1">Scalar Pattern</a></h2>
<p>A scalar synchronizing call has the following characterisics:</p>
<ul>
<li>Up to 4 <code>u32</code>-sized arguments</li>
<li>Caller blocks until the callee returns</li>
<li>Callee may return up to 2 <code>u32</code>-sized values</li>
</ul>
<pre><code class="language-rust noplayground">// api.rs
pub(crate) enum Opcode {
    LightsSync,
    // ... and other ops
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// lib.rs:
impl MyService {
    // ... new(), etc.

    /// Tell the main loop to set the state of lights. This blocks until we get a confirmation code,
    /// which in this case was the last state of the lights.
    pub fn set_lights_sync(&amp;self, state: bool) -&gt; Result&lt;bool, xous::Error&gt; {
        match send_message(self.conn,
            Message::new_blocking_scalar(Opcode::LightsSync.to_usize().unwrap()),
                if state {1} else {0},
                0,
                0,
                0
            )
        ) {
            // match to `xous::Result::Scalar2(val1, val2)` for the case of two values returned
            Ok(xous::Result::Scalar1(last_state)) =&gt; {
                if last_state == 1 {
                    Ok(true)
                } else {
                    Ok(false)
                }
            }
            _ =&gt; {
                Err(xous::Error::InternalError)
            }
        }
    }
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// main.rs:
fn xmain() -&gt; ! {
    // ... preamble
    loop {
        let msg = xous::receive_message(sid).unwrap();
        match FromPrimitive::from_usize(msg.body.id()) {
            Some(Opcode::LightsSync) =&gt; xous::msg_blocking_scalar_unpack!(msg, state, _, _, _, {
                let last_state = lights_current_state();
                if state == 1 {
                    turn_lights_on();
                } else {
                    turn_lights_off();
                }
                if last_state {
                    // alternative form is `xous::return_scalar2(msg.sender, val1, val2)`
                    xous::return_scalar(msg.sender, 1).expect(&quot;couldn't return last state&quot;);
                } else {
                    xous::return_scalar(msg.sender, 0).expect(&quot;couldn't return last state&quot;);
                }
            }),
            // .. other match statements
        }
    }
    // ... postamble
}
</code></pre>
<h2><a class="header" href="#memory-pattern-1" id="memory-pattern-1">Memory Pattern</a></h2>
<p>A memory synchronizing call has the following characterisics:</p>
<ul>
<li>Messages are sent in blocks rounded up to the nearest 4096-byte page size</li>
<li>Caller blocks until the data is returned</li>
<li>Callee returns data by overwriting the same page(s) of memory that were sent</li>
</ul>
<p>This example also shows how to do a memory message without <code>rkyv</code>. This is useful
for situations that can't have an <code>rkyv</code> dependency, or if you just prefer to do
things in a low-level fashion.</p>
<pre><code class="language-rust noplayground ignore">// api.rs
pub(crate) enum Opcode {
    // use `rkyv` to serialize a memory message and send
    PushDataRkyv,
    // example of explicit serialization
    PushDataExplicit,
    // ... and other ops
}
#[derive(rkyv::Archive, rkyv::Serialize, rkyv::Deserialize)]
pub struct CompoundData {
    pub data: [u8; 1000],
    pub len: u16,
    pub description: xous_ipc::String::&lt;128&gt;,
}
/// For a memory structure to be remapped between processes, it must be page-aligned,
/// and the mapped region will always round up to the neareest page boundary.
///
/// Therefore, the minimum size serialized is always one page (4096 bytes). Even if
/// we made this smaller, a full 4096 bytes are always allocated and cleared.
/// The `rkyv`+Buffer method hides the details of page alignment.
///
/// When serializing data manually, you need to guarantee the page alignment property.
/// One way to do this is to request a memory page using `xous::syscall::map_memory()`.
/// This is an explicit way to create a page of memory, and you must also unmap it
/// once you are done. Another way to do it is to allocate it on the stack, but, in
/// order to guarantee mapability, the structure has to be decorated with
/// `#[repr(C, align(4096))]`. This example uses stack allocation, and thus we create
/// a page-sized, page-aligned RawData structure as below.
#[repr(C, align(4096))]
pub struct RawData {
    raw: [u8; 4096],
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// lib.rs:
impl MyService {
    // ... new(), etc.

    /// Send some `data` to the server. It'll get there when it gets there.
    /// This example uses `rkyv` to serialize data into a compound structure.
    pub fn push_and_get_data_rkyv(&amp;self, data: &amp;mut [u8], desc: &amp;str) -&gt; Result&lt;(), xous::Error&gt; {
        let mut rec = CompoundData {
            data: [0u8; 1000],
            len: 0,
            description: xous_ipc::String::new(),
        };
        if data.len() &gt; rec.data.len() {
            return Err(xous::Error::OutOfMemory);
        }
        for (&amp;s, d) in data.iter().zip(rec.data.iter_mut()) {
            *d = s;
        }
        rec.len = data.len() as u16;
        rec.description.append(desc).ok(); // overflows are silently truncated

        // now convert it into a Xous::Buffer, which can then be lent to the server
        let mut buf = Buffer::into_buf(rec).or(Err(xous::Error::InternalError))?;
        buf.lend_mut(self.conn, Opcode::PushDataRkyv.to_u32().unwrap()).map(|_| ())?;

        let response = buf.as_flat::&lt;CompoundData, _&gt;().unwrap();
        if response.data.len() &gt; data.len() || response.data.len() &gt; response.data.len() {
            Err(xous::Error::OutOfMemory)
        } else {
            // copy the data back
            for (&amp;s, d) in response.data[..response.len as usize].iter().zip(data.iter_mut()) {
                *d = s;
            }
            Ok(())
        }
    }

    /// Send 32 bytes of `data` to a server. This example uses explicit serialization into a raw buffer.
    pub fn push_data_manual(&amp;self, data: &amp;mut [u8; 32]) -&gt; Result&lt;(), xous::Error&gt; {
        // RawData can be sized smaller, but all IPC memory messages are rounded up to the nearest page
        // The sizing here reflects that explicitly. Using `rkyv` does not change this, it just hides it.
        let mut request = RawData { raw: [0u8; 4096] };
        for (&amp;s, d) in data.iter().zip(request.raw.iter_mut()) {
            *d = s;
        }
	// we need to guarantee that RawData is a page-aligned, page-sized stack allocation.
	// See comment on the data structure for more information.
        let buf = unsafe {
            xous::MemoryRange::new(
                &amp;mut request as *mut RawData as usize,
                core::mem::size_of::&lt;RawData&gt;(),
            )
            .unwrap()
        };
        let response = xous::send_message(
            self.conn,
            xous::Message::new_lend_mut(
                Opcode::PushDataExplicit.to_usize().unwrap(),
                buf,
                None, // valid and offset are not used in explicit implementations
                None, // and are thus free to bind to other applications
            ),
        );
        match response {
            Ok(xous::Result::MemoryReturned(_offset, _valid)) =&gt; {
                // contrived example just copies whatever comes back from the server
                let response = buf.as_slice::&lt;u8&gt;();
                for (&amp;s, d) in response.iter().zip(data.iter_mut()) {
                    *d = s;
                }
                Ok(())
            }
            Ok(_) =&gt; Err(xous::Error::InternalError), // wrong return type
            Err(e) =&gt; Err(e)
        }
    }
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// main.rs:
fn xmain() -&gt; ! {
    // ... preamble
    let mut storage = Vec::&lt;CompoundData&gt;::new();
    let mut raw_data = [0u8; 32];
    loop {
        let mut msg = xous::receive_message(sid).unwrap();
        match FromPrimitive::from_usize(msg.body.id()) {
            /// This will get processed whenever the server gets scheduled, which has no strict
            /// relationship to the caller's state. However, messages are guaranteed
            /// to be processed in-order.
            Some(Opcode::PushDataRkyv) =&gt; {
                let mut buffer = unsafe {
                    Buffer::from_memory_message_mut(msg.body.memory_message_mut().unwrap())
                };
                let mut data = buffer.to_original::&lt;PushDataRkyv, _&gt;().unwrap();
                storage.push(data);
                // A contrived return value.
                data.len = 1;
                data.data[0] = 42;
                // Note that you can stick *any* `rkyv`-derived struct
                // into the buffer as a return &quot;value&quot;. We just happen to re-use
                // the same structure defintion here for expedience
                // However, it's up to the recipient to know the returned type,
                // and to deserialize it correctly. Nothing prevents type mismatches
                // across IPC boundaries!
                buffer.replace(data).expect(&quot;couldn't serialize return&quot;);
                // `msg` goes out of scope at this point, triggering `Drop` and thus unblocking the caller
            },
            Some(Opcode::PushDataExplicit) =&gt; {
                let body = msg.body.memory_message_mut().expect(&quot;incorrect message type received&quot;);
                let mut data = body.buf.as_slice_mut::&lt;u8&gt;();
                for (&amp;s, d) in data.iter().zip(raw_data.iter_mut()) {
                    *d = s;
                }
                // Very contrived example of &quot;returning&quot; data. Just poke something into the first byte.
                data[0] = 42;
                // there is no `replace()` because `data` is the original message memory: this is
                // unlike the previous example where `to_original()` creates a copy of the data.

                // `msg` goes out of scope at this point, triggering `Drop` and thus unblocking the caller
            }
            // .. other match statements
        }
    }
    // ... postamble
}
</code></pre>
<h1><a class="header" href="#asynchronous-idioms-or-push-notifications" id="asynchronous-idioms-or-push-notifications">Asynchronous Idioms or &quot;Push Notifications&quot;</a></h1>
<p>Push notifications are used when we want to be alerted of a truly unpredictable, asynchronous event that can happen at any time.</p>
<p>One of the main challenges of push notifications is not disclosing your <code>SID</code> to the notifying server. Remember, anyone with your <code>SID</code> can invoke any method on your server, including more sensitive ones.</p>
<p>The idiom here is to create and reveal a &quot;single-purpose&quot; server, whose sole job is to receive the push notification from the notifier, and forward this message back to the main server. The single purpose server exists on the <code>lib</code> side, and is thus the caller controls it and its construction. It runs in its own dedicated thread; thus, the single-purpose server spends most of its life blocked and not consuming CPU resources, and only springs to action once a notification arrives.</p>
<p>This pattern has the following properties:</p>
<ul>
<li>No disclosure of the main loop <code>SID</code></li>
<li>An extra &quot;bounce&quot; required for asynchronous notifications</li>
</ul>
<p>The example below is taken from the <code>NetManager</code>'s wifi state change subscription service, and trimmed down to the core bits.</p>
<pre><code class="language-rust noplayground ignore">// inside api.rs
// used for managing susbscriptions
#[derive(Debug, Archive, Serialize, Deserialize, Copy, Clone)]
pub(crate) struct WifiStateSubscription {
    // this is the &quot;single-purpose&quot; SID
    pub sid: [u32; 4],
    // this is the opcode dispatch number to use on the recipient side. Everyone
    // can have a different opcode table, so we must remember this with each SID.
    pub opcode: u32,
}

// all of the below sub-structures are `rkyv` serializeable
#[derive(Debug, Copy, Clone, rkyv::Archive, rkyv::Serialize, rkyv::Deserialize)]
pub struct WlanStatusIpc {
    pub ssid: Option&lt;SsidRecord&gt;,
    pub link_state: u16,
    pub ipv4: [u16; com_rs_ref::ComState::WLAN_GET_IPV4_CONF.r_words as usize],
}
// the `from_status()` method is a convenience trait that can take data from a native
// representation to an IPC-compatible version
impl WlanStatusIpc {
    pub fn from_status(status: WlanStatus) -&gt; Self {
        WlanStatusIpc {
            ssid: status.ssid,
            link_state: status.link_state as u16,
            ipv4: status.ipv4.encode_u16(),
        }
    }
}

#[derive(num_derive::FromPrimitive, num_derive::ToPrimitive, Debug)]
pub(crate) enum Opcode {
    // add a subscriber to our push notifications
    SubscribeWifiStats,
    // remove a subscriber
    UnsubWifiStats,
    // this triggers a push notification; it's contrived for simplicity in this pared-down example
    StateChangeEvent,
    // ------ API opcodes to be discussed in detail below ------
    /// Exits the server
    Quit,
}

</code></pre>
<pre><code class="language-rust noplayground ignore">// inside lib.rs
pub struct NetManager {
    netconn: NetConn,
    wifi_state_cid: Option&lt;CID&gt;,
    wifi_state_sid: Option&lt;xous::SID&gt;,
}
impl NetManager {
    pub fn new() -&gt; NetManager {
        NetManager {
            netconn: NetConn::new(&amp;xous_names::XousNames::new().unwrap()).expect(&quot;can't connect to Net Server&quot;),
            wifi_state_cid: None,
            wifi_state_sid: None,
        }
    }
    pub fn wifi_state_subscribe(&amp;mut self, return_cid: CID, opcode: u32) -&gt; Result&lt;(), xous::Error&gt; {
        if self.wifi_state_cid.is_none() {
            let onetime_sid = xous::create_server().unwrap();
            let sub = WifiStateSubscription {
                sid: onetime_sid.to_array(),
                opcode
            };
            let buf = Buffer::into_buf(sub).or(Err(xous::Error::InternalError))?;
            buf.send(self.netconn.conn(), Opcode::SubscribeWifiStats.to_u32().unwrap()).or(Err(xous::Error::InternalError))?;

            // this thread is the &quot;bouncer&quot; that takes the status data and sends it on
            // to our local private server. Note that it only has two opcodes, which limits
            // the attack surface exposed to a ptoentially untrusted subscriber.
            self.wifi_state_cid = Some(xous::connect(onetime_sid).unwrap());
            self.wifi_state_sid = Some(onetime_sid);
            let _ = std::thread::spawn({
                let onetime_sid = onetime_sid.clone();
                let opcode = opcode.clone();
                move || {
                    loop {
                        let msg = xous::receive_message(onetime_sid).unwrap();
                        match FromPrimitive::from_usize(msg.body.id()) {
                            Some(WifiStateCallback::Update) =&gt; {
                                let buffer = unsafe {
                                    Buffer::from_memory_message(msg.body.memory_message().unwrap())
                                };
                                // have to transform it through the local memory space because you can't re-lend pages
                                let sub = buffer.to_original::&lt;WlanStatusIpc, _&gt;().unwrap();
                                let buf = Buffer::into_buf(sub).expect(&quot;couldn't convert to memory message&quot;);
                                buf.lend(return_cid, opcode).expect(&quot;couldn't forward state update&quot;);
                            }
                            Some(WifiStateCallback::Drop) =&gt; {
                                xous::return_scalar(msg.sender, 1).unwrap();
                                break;
                            }
                            _ =&gt; {
                                log::error!(&quot;got unknown opcode: {:?}&quot;, msg);
                            }
                        }
                    }
                    xous::destroy_server(onetime_sid).unwrap();
                }
            });
            Ok(())
        } else {
            // you can only hook this once per object
            Err(xous::Error::ServerExists)
        }
    }
    /// If we're not already subscribed, returns without error.
    pub fn wifi_state_unsubscribe(&amp;mut self) -&gt; Result&lt;(), xous::Error&gt; {
        if let Some(handler) = self.wifi_state_cid.take() {
            if let Some(sid) = self.wifi_state_sid.take() {
                let s = sid.to_array();
                send_message(self.netconn.conn(),
                    Message::new_blocking_scalar(Opcode::UnsubWifiStats.to_usize().unwrap(),
                    s[0] as usize,
                    s[1] as usize,
                    s[2] as usize,
                    s[3] as usize,
                    )
                ).expect(&quot;couldn't unsubscribe&quot;);
            }
            send_message(handler, Message::new_blocking_scalar(WifiStateCallback::Drop.to_usize().unwrap(), 0, 0, 0, 0)).ok();
            unsafe{xous::disconnect(handler).ok()};
        }
        Ok(())
    }
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// main-side code
#[xous::xous_main]
fn xmain() -&gt; ! {
    // ... other stuff ...
    let mut wifi_stats_cache: WlanStatus = WlanStatus::from_ipc(WlanStatusIpc::default());
    let mut status_subscribers = HashMap::&lt;xous::CID, WifiStateSubscription&gt;::new();
    loop {
        let mut msg = xous::receive_message(sid).unwrap();
        // ... other opcodes ...
        Some(Opcode::SubscribeWifiStats) =&gt; {
            let buffer = unsafe {
                Buffer::from_memory_message(msg.body.memory_message().unwrap())
            };
            let sub = buffer.to_original::&lt;WifiStateSubscription, _&gt;().unwrap();
            let sub_cid = xous::connect(xous::SID::from_array(sub.sid)).expect(&quot;couldn't connect to wifi subscriber callback&quot;);
            status_subscribers.insert(sub_cid, sub);
        },
        Some(Opcode::UnsubWifiStats) =&gt; msg_blocking_scalar_unpack!(msg, s0, s1, s2, s3, {
            let sid = [s0 as u32, s1 as u32, s2 as u32, s3 as u32];
            let mut valid_sid: Option&lt;xous::CID&gt; = None;
            for (&amp;cid, &amp;sub) in status_subscribers.iter() {
                if sub.sid == sid {
                    valid_sid = Some(cid)
                }
            }
            xous::return_scalar(msg.sender, 1).expect(&quot;couldn't ack unsub&quot;);
            if let Some(cid) = valid_sid {
                status_subscribers.remove(&amp;cid);
                unsafe{xous::disconnect(cid).ok();}
            }
        }),
        // contrived state change event. Use the below idiom whenever you need to send a push notification.
        Some(Opcode::StateChangeEvent) =&gt; {
            // ... other code to handle the state change

            // iterate through all the subscribers and send the notification
            for &amp;sub in status_subscribers.keys() {
                let buf = Buffer::into_buf(WlanStatusIpc::from_status(wifi_stats_cache)).or(Err(xous::Error::InternalError)).unwrap();
                buf.send(sub, WifiStateCallback::Update.to_u32().unwrap()).or(Err(xous::Error::InternalError)).unwrap();
            }
        }
    }
}
</code></pre>
<h1><a class="header" href="#deferred-response" id="deferred-response">Deferred Response</a></h1>
<p>Deferred response is a variant of synchronous messaging. In this case, the caller blocks, but the callee is free to process new messages (typically to help compute results that eventually unblock the caller).</p>
<p>As of Xous 0.9.7, the trick to deferred response is different between <code>scalar</code> and <code>memory</code> messages.</p>
<ul>
<li>For <code>scalar</code> messages, one needs to store the <code>msg.sender</code> field (a <code>usize</code>) and delay the <code>xous::return_scalar(sender, value)</code> call until the appropriate time.</li>
<li>For <code>memory</code> messages, one needs to store the entire <code>MessageEnvelope</code>, so that it does not go out of scope. <code>memory</code> messages automatically call the appropriate syscall (<code>return_memory_offset_valid</code> for <code>lend</code> and <code>lend_mut</code>, <code>unmap_memory</code> for <code>send</code>) in their <code>Drop</code> trait implementation.</li>
</ul>
<p>Future versions of Xous may or may not implement a <code>Drop</code> method which automatically returns <code>scalar</code> messages when they go out of scope, this is a topic of active discussion. However, as is the case with all the other idioms, the pattern is different from <code>scalar</code> and <code>memory</code> types, so, regardless, they will be treated with separate examples.</p>
<h2><a class="header" href="#scalar-pattern-2" id="scalar-pattern-2">Scalar Pattern</a></h2>
<p>This is very close to the thing that's actually implemented for synchronizing all the servers during a suspend/resume event.</p>
<pre><code class="language-rust noplayground">// api.rs
pub(crate) enum Opcode {
    WaitUntilReady,
    TheBigEvent,
    // ... and other ops
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// lib.rs:
impl MyService {
    // ... new(), etc.

    /// This will wait until the main loop decides it's ready to unblock us.
    pub fn wait_until_ready(&amp;self) -&gt; Result&lt;(), xous::Error&gt; {
        send_message(self.conn,
            Message::new_blocking_scalar(Opcode::WaitUntilReady.to_usize().unwrap()),
                0, 0, 0, 0
            )
        ).map(|_| ())
    }
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// main.rs:
fn xmain() -&gt; ! {
    // ... preamble
    let mut waiting = Vec::&lt;MessageSender&gt;::new();
    loop {
        let msg = xous::receive_message(sid).unwrap();
        match FromPrimitive::from_usize(msg.body.id()) {
            Some(Opcode::WaitUntilReady) =&gt; xous::msg_blocking_scalar_unpack!(msg, _, _, _, _, {
                // store the message sender;
                // the sender continues to block because `xous::return_scalar()` has not been called
                waiting.push(msg.sender);
                // execution continues on here
            }),
            // .. this loop is still available to do things, even though the callers are blocked ..
            // stuff happens until something triggers TheBigEvent:
            Some(Opcode::TheBigEvent) =&gt; {
                for sender in waiting.drain(..) {
                    // the argument is arbitrary. `return_scalar2` can also be used.
                    xous::return_scalar(sender, 1).expect(&quot;couldn't unblock sender&quot;);
                }
                // All the waiting processes are now unblocked.
            }
            // .. other match statements
        }
    }
    // ... postamble
}
</code></pre>
<h2><a class="header" href="#memory-pattern-2" id="memory-pattern-2">Memory Pattern</a></h2>
<pre><code class="language-rust noplayground ignore">// api.rs
pub(crate) enum Opcode {
    GetDeferredData,
    Event,
    // ... and other ops
}
#[derive(rkyv::Archive, rkyv::Serialize, rkyv::Deserialize)]
pub struct DeferredData {
    pub spec: u32,
    pub description: xous_ipc::String::&lt;128&gt;,
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// lib.rs:
impl MyService {
    // ... new(), etc.

    pub fn get_data_blocking(&amp;self, spec: u32) -&gt; Result&lt;String, xous::Error&gt; {
        let mut rec = DeferredData {
            spec,
            description: xous_ipc::String::new(),
        };

        let mut buf = Buffer::into_buf(rec).or(Err(xous::Error::InternalError))?;
        buf.lend_mut(self.conn, Opcode::GetDeferredData.to_u32().unwrap()).map(|_| ())?;

        let response = buf.as_flat::&lt;DeferredData, _&gt;().unwrap();
        Ok(String::new(response.description.as_str().unwrap_or(&quot;UTF-8 error&quot;)))
    }
}
</code></pre>
<pre><code class="language-rust noplayground ignore">// main.rs:
fn xmain() -&gt; ! {
    // ... preamble
    // if you are sure there will never be multiple deferred messages, you can just use an
    // Option&lt;MessageEnvelope&gt; and .take() to remove it from scope, instead of Vec and .drain()
    let mut storage = Vec::&lt;xous::MessageEnvelope&gt;::new();
    let mut spec: u32 = 0;
    loop {
        let mut msg = xous::receive_message(sid).unwrap();
        match FromPrimitive::from_usize(msg.body.id()) {
            /// This will get processed whenever the server gets scheduled, which has no strict
            /// relationship to the caller's state. However, messages are guaranteed
            /// to be processed in-order.
            Some(Opcode::GetDeferredData) =&gt; {
                spec += {
                    // any incoming arguments are processed in a block like this to ensure
                    // that the `msg` has no ownership interference with `spec`.
                    let buffer = unsafe {
                        Buffer::from_memory_message(msg.body.memory_message().unwrap())
                    };
                    let data = buffer.to_original::&lt;DeferredData, _&gt;().unwrap();
                    data.spec
                };
                storage.push(msg);
                // `msg` is now pushed into the scope of `storage`, which prevents `Drop`
                // from being called, thus continuing to block the caller.
            },
            // ... other processing happens, perhaps guided by the value in `spec`
            Some(Opcode::Event) =&gt; {
                let result = DeferredData {
                    spec: 0,
                    description: xous_ipc::String::from_str(&quot;something happened!&quot;),
                };
                // `drain()` takes `msg` back out of the scope of `storage`, and
                // unless it is bound to another variable outside of this scope,
                // it will Drop and unblock the caller at the end of this block.
                for mut sender in storage.drain(..) {
                    let mut response = unsafe {
                        Buffer::from_memory_message_mut(sender.body.memory_message_mut().unwrap())
                    };
                    response.replace(result).unwrap();
                }
            }
            // .. other match statements
        }
    }
    // ... postamble
}
</code></pre>
<h1><a class="header" href="#forwarding-messages" id="forwarding-messages">Forwarding Messages</a></h1>
<p>Because server IDs are used to protect APIs, there arises occasions where
servers need to be firewalled: a private server within a crate may implement
a range of powerful and dangerous APIs, of which only a small portion should
be revealed to external callers.</p>
<p>The general idiom in this case is to:</p>
<ol>
<li>Create a process-private server that contains all the APIs. The server is not registered with <code>xous-names</code>; it is entirely a secret within the crate.</li>
<li>Create a process-public server that contains only the public APIs. This server is registered with <code>xous-names</code> and it may have a connection limit of <code>None</code>, e.g., anyone and everyone may connect to it.</li>
<li>Certain messages are forwarded from the process-public server to the process-private server.</li>
</ol>
<p>In order to support this idiom, messages have a <code>.forward()</code> call. Usage is straightfoward:</p>
<pre><code class="language-rust noplayground ignore">    // A private server that can do many powerful things
    let cm_sid = xous::create_server().expect(&quot;couldn't create connection manager server&quot;);
    let cm_cid = xous::connect(cm_sid).unwrap();
    thread::spawn({
        move || {
            connection_manager::connection_manager(cm_sid);
        }
    });

    loop {
        let mut msg = xous::receive_message(net_sid).unwrap();
        // .. other code

        // These messages are forwarded on to the private server
        // This one is a `lend` of a memory message
        Some(Opcode::SubscribeWifiStats) =&gt; {
            msg.forward(
                cm_cid,
                ConnectionManagerOpcode::SubscribeWifiStats as _)
            .expect(&quot;couldn't forward subscription request&quot;);
        }
        // This one is a `blocking_scalar` scalar message type
        Some(Opcode::UnsubWifiStats) =&gt; {
            msg.forward(
                cm_cid,
                connection_manager::ConnectionManagerOpcode::UnsubWifiStats as _)
            .expect(&quot;couldn't forward unsub request&quot;);
        },
    }
</code></pre>
<p>Other usage notes:</p>
<ul>
<li>Message types cannot be transformed across the forwarding boundary.</li>
<li>You are allowed to inspect a Memory <code>msg</code> by unpacking it into a <code>Buffer</code>, but you must make sure the <code>Buffer</code> goes out of scope before calling <code>.forward()</code> (perhaps by putting the inspection operation within its own block, e.g. a pair of curly braces).</li>
</ul>
<h1><a class="header" href="#messaging-performance" id="messaging-performance">Messaging Performance</a></h1>
<p>On a 100MHz VexRiscv RV32-IMAC, 4k/4way I/D L1 writethrough cache + unified 128k L2 writethrough cache, and cycle-accurate models for external SRAM (70ns access times) and SPINOR FLASH (200 MT/s):</p>
<ul>
<li>A round-trip call with a scalar message takes 174 microseconds</li>
<li>A round-trip call with a memory message typically takes 771 microseconds, but can be optimized down to 302 microseconds</li>
</ul>
<p>The waveforms presented in this section are derived from a cycle-accurate verilog simulation of something fairly close to a Precursor device.</p>
<h2><a class="header" href="#scalar-message-performance" id="scalar-message-performance">Scalar Message Performance</a></h2>
<p>Scalar messages can move up to 5 32-bit words (20 bytes) in a single call, using the <code>scalar5</code> message type available in the <code>reply_and_receive_next()</code>, introduced in release 0.9.11. Prior to that, up to 2 32-bit words could be moved. It takes the same amount of time whether you move 0 words, or 5 words either way.</p>
<p>The following is a graphical breakdown of the overhead of sending a scalar message.</p>
<p><img src="images/scalar_messaging.png" alt="scalar5 message breakdown" /></p>
<p>Notes:</p>
<ul>
<li>The <code>report[31:0]</code> field helps track client code location.</li>
<li><code>execute_PC</code> is plotted twice; once showing the range of userland code, once showing the range of kernel code</li>
<li><code>MmmuPlugin_satp_asid</code> is the active process ID. <code>5</code> is the client loop; <code>4</code> is the ticktimer server; <code>1</code> is the kernel</li>
</ul>
<p>The simulation was run using Xous 0.9.12, with the following code running:</p>
<p>Client code:</p>
<pre><code class="language-rust noplayground ignore">    // Code in the client main loop
    core_csr.wfo(utra::main::REPORT_REPORT, 0x1111_0000 + iter);
    let now = tt.elapsed_ms();
    core_csr.wfo(utra::main::REPORT_REPORT, 0x2222_0000 + iter);

    // Code in the library call
    pub fn elapsed_ms(&amp;self) -&gt; u64 {
        let response = send_message(
            self.conn,
            xous::Message::new_blocking_scalar(
                api::Opcode::ElapsedMs.to_usize().unwrap(),
                0,
                0,
                0,
                0,
            ),
        )
        .expect(&quot;Ticktimer: failure to send message to Ticktimer&quot;);
        if let xous::Result::Scalar2(upper, lower) = response {
            upper as u64 | ((lower as u64) &lt;&lt; 32)
        } else {
            panic!(
                &quot;Ticktimer elapsed_ms(): unexpected return value.&quot;
            );
        }
    }
</code></pre>
<p>Server code:</p>
<pre><code class="language-rust noplayground ignore">    // Code on the server main loop
    api::Opcode::ElapsedMs =&gt; {
        if let Some(scalar) = msg.body.scalar_message_mut() {
            let time = ticktimer.elapsed_ms() as i64;
            scalar.arg1 = (time &amp; 0xFFFF_FFFFi64) as usize;
            scalar.arg2 = ((time &gt;&gt; 32) &amp; 0xFFF_FFFFi64) as usize;
            scalar.id = 0;

            // API calls expect a `Scalar2` value in response
            return_type = 2;
        }
    }
    // Hardware abstraction code, down to the register read/writes
    pub fn elapsed_ms(&amp;self) -&gt; u64 {
        self.raw_ticktime() / TICKS_PER_MS
    }
    pub fn raw_ticktime(&amp;self) -&gt; u64 {
        let mut time: u64 = self.csr.r(utra::ticktimer::TIME0) as u64;
        time |= (self.csr.r(utra::ticktimer::TIME1) as u64) &lt;&lt; 32;
        time
    }

</code></pre>
<h2><a class="header" href="#memory-message-performance" id="memory-message-performance">Memory Message Performance</a></h2>
<p>Memory messages can move up to the available free memory in a single call. However, the minimum amount of memory that can be moved in any case is one page (4096 bytes).</p>
<p><img src="images/memory_messaging.png" alt="memory message breakdown" /></p>
<p>Notes:</p>
<ul>
<li>The <code>report[31:0]</code> field helps track client code location.</li>
<li><code>execute_PC</code> is plotted twice; once showing the range of userland code, once showing the range of kernel code</li>
<li><code>MmmuPlugin_satp_asid</code> is the active process ID. <code>5</code> is the client loop; <code>4</code> is the ticktimer server; <code>1</code> is the kernel</li>
</ul>
<p>The simulation was run using Xous 0.9.12, with the following code running:</p>
<pre><code class="language-rust noplayground ignore">    // Client main loop code
    core_csr.wfo(utra::main::REPORT_REPORT, 0x3333_0000 + iter);
    let version = tt.get_version();
    core_csr.wfo(utra::main::REPORT_REPORT, 0x4444_0000 + iter);

    // Client library code
    pub fn get_version(&amp;self) -&gt; String {
        let alloc = api::VersionString {
            version: xous_ipc::String::new(),
        };
        let mut buf = xous_ipc::Buffer::into_buf(alloc).expect(&quot;couldn't convert version request&quot;);
        buf.lend_mut(self.conn, api::Opcode::GetVersion.to_u32().unwrap())
            .expect(&quot;couldn't get version&quot;);
        let v = buf
            .to_original::&lt;api::VersionString, _&gt;()
            .expect(&quot;couldn't revert buffer&quot;);
        String::from(v.version.as_str().unwrap())
    }
</code></pre>
<p>Server code:</p>
<pre><code class="language-rust noplayground ignore">    // Main loop code
    api::Opcode::GetVersion =&gt; {
        let mut buf = unsafe {
            xous_ipc::Buffer::from_memory_message_mut(
                msg.body.memory_message_mut().unwrap(),
            )
        };
        buf.replace(version::get_version()).unwrap();
    }
    // Library to retrieve the version number
    pub(crate) fn get_version() -&gt; crate::api::VersionString {
        let mut v = crate::api::VersionString {
            version: xous_ipc::String::new()
        };
        v.version.append(SEMVER).ok();
        v.version.append(&quot;\n&quot;).ok();
        v.version.append(TIMESTAMP).ok();
        v
    }
    pub const TIMESTAMP: &amp;'static str = &quot;Wed, 18 Jan 2023 19:19:24 +0800&quot;;
    pub const SEMVER: &amp;'static str = &quot;v0.9.11-152-g277d014f&quot;;
</code></pre>
<p>A couple things are remarkable about this call:</p>
<ul>
<li>A large amount of time is spent clearing the 4096-byte page of memory to 0, even though only about 53 bytes are transferred. On this implementation, the zero-clearing time is bottlenecked by the write speed to main memory, and by the write-through caching scheme. Faster main memory and/or a write-back cache would reduce the zeroization time.</li>
<li>A large amount of time is spent in <code>dlmalloc()</code> to heap-allocate the return string.</li>
</ul>
<p>Thus, while the code is ergonomic, there is a price for the abstractions.</p>
<h2><a class="header" href="#optimizing-memory-message-performance" id="optimizing-memory-message-performance">Optimizing Memory Message Performance</a></h2>
<p>One can speed up memory messaging with a few techniques:</p>
<ul>
<li>Use stack-allocated, explicitly managed and <code>unsafe</code> regions of memory (warning: by not zeroizing the whole page every time, one runs the risk of leaking previously sent data to third parties. It is not recommended to do this unless you are very careful!)</li>
<li>Avoid heap allocations at all costs</li>
</ul>
<p>Below is the same run of code, but with these optimizations. The round-trip call time drops from 771us to 302us.</p>
<p><img src="images/memory_messaging_opt.png" alt="memory message, with optimizations" /></p>
<p>However, the code turns into this:</p>
<pre><code class="language-rust noplayground ignore">    // Client main loop code
    core_csr.wfo(utra::main::REPORT_REPORT, 0x3333_0000 + iter);
    let version = tt.get_version();
    core_csr.wfo(utra::main::REPORT_REPORT, 0x4444_0000 + iter);

    // Client library code
    // Define a struct that's 4096 bytes of `u8` and ensure it's page-aligned
    #[derive(Debug)]
    #[repr(C, align(4096))]
    struct StringRequest([u8; 4096]);

    #[derive(Debug)]
    pub struct Ticktimer {
        // ...
        request: UnsafeCell::&lt;StringRequest&gt;,
    }
    pub fn new() -&gt; Result&lt;Self, Error&gt; {
        // ...
        Ok(Ticktimer {
            // ...
            request: UnsafeCell::new(StringRequest([0u8; 4096])),
        })
    }

    pub fn get_version(&amp;self) -&gt; String {
        // Send the message mutably, indicating that there are 4096 bytes available. The
        // Server will overwrite some number of bytes and return the value in the `.valid`
        // field.
        let request = self.request.get();
        let memory_range = unsafe {
            xous::MemoryRange::new(
                request as usize,
                core::mem::size_of::&lt;StringRequest&gt;(),
            )
            .unwrap()
        };
        let result = send_message(
            self.conn,
            xous::Message::new_lend_mut(
                api::Opcode::GetVersion as _,
                memory_range,
                None, xous::MemorySize::new(4096))).unwrap();

        // Extract the `offset` and `valid` fields
        let valid = match result {
            xous::Result::MemoryReturned(_offset, valid) =&gt; valid.unwrap(),
            _ =&gt; panic!(&quot;Invalid return value&quot;),
        };

        // Convert the stack array into a heap-allocated Vec&lt;u8&gt;
        let data = unsafe{(&amp;*request).0[0..valid.get()].to_owned()};

        // Reassign the heap-allocated Vec&lt;u8&gt; to the String, and return it.
        // If there is a UTF-8 error, this will panic.
        String::from_utf8(data).unwrap()
    }
</code></pre>
<p>In this case, the <code>Ticktimer</code> object statically allocates, and keeps for the lifetime of an object,
a page-aligned &quot;hole&quot; in the stack that is tracked by the <code>StringRequest</code> structure. The <code>UnsafeCell</code>
wrapper is necessary to do runtime borrow checking, so that the API call for <code>get_version()</code> is not
<code>mut</code>.</p>
<p><code>StringRequest</code> is initialized to <code>0</code> once on <code>new()</code>, and future calls simply re-use and overwrite the memory region
(in fact, since the version data is static, the page could even be pre-populated with the version
return data, but this example dynamically populates it to give a more realistic example of how to
use this optimization in practice).</p>
<p>Note that this causes the object to &quot;eat&quot; at least 4096 but more typically closer to 8192 bytes
(whereas previously it was a single <code>u32</code> plus some Rust book-keeping); so, it is inefficient in
RAM, less safe, but completely avoids the problem of allocating a page and zeroizing it.</p>
<p>Server code:</p>
<pre><code class="language-rust noplayground ignore">    // Main loop code
    api::Opcode::GetVersion =&gt; {
        let mut raw_msg = msg.body.memory_message_mut().unwrap();
        raw_msg.valid = core::num::NonZeroUsize::new(
            crate::version::SEMVER.len() + 1 + crate::version::TIMESTAMP.len());
        let mut buffer = raw_msg.buf.as_slice_mut();
        for (dest, src) in buffer.iter_mut()
                .zip(crate::version::SEMVER.as_bytes().iter()
                .chain([b'\n'].iter())
                .chain(crate::version::TIMESTAMP.as_bytes().iter())) {
            *dest = *src;
        }
    }

    api::Opcode::GetVersion =&gt; {
        let raw_msg = msg.body.memory_message_mut().unwrap();
        let mut v = String::new();
        v.push_str(crate::version::SEMVER);
        v.push_str(&quot;\n&quot;);
        v.push_str(crate::version::TIMESTAMP);
        let len = v.as_bytes().len();
        raw_msg.buf.as_slice_mut()[..len].copy_from_slice(v.as_bytes());
        raw_msg.valid = Some(core::num::NonZeroUsize::new(len).unwrap());
    }    // Library to retrieve the version number
    pub const TIMESTAMP: &amp;'static str = &quot;Wed, 18 Jan 2023 19:19:24 +0800&quot;;
    pub const SEMVER: &amp;'static str = &quot;v0.9.11-152-g277d014f&quot;;
</code></pre>
<p>In this case, the server is directly accessing the page of memory lent from
the client, and copying the return data into the underlying <code>[u8]</code> of the memory
message. It uses one of the advisory fields (in this case, <code>valid</code>) to note
how long the return data is (recall that <code>valid</code> and <code>size</code> have no fixed
meaning are are available to the API writer to annotate the contents of the
re-mapped memory page).</p>
<p>Fortunately for this example, we're just returning a <code>String</code>, which deserializes
natively with <code>as_bytes()</code>; but more complex datatypes will require some sort
of serdes implementation. The <code>Buffer</code> abstraction uses <code>rkyv</code> as the <code>serdes</code>
layer, but by going straight to the underlying slice data, a user can use
their own preferred serdes format, or if their data happens to be already in
a slice-u8 format, they can completely bypass the serdes abstraction layer entirely.</p>
<p>Thus, one can optimize memory messages to be about 2x faster by stripping off
much of the ergonomics that surround memory messages, but it is trickier to guarantee
correctness, there is a very real risk of leaking data between processes (through
unused data in borrowed pages not being zero-ized), and at a higher static memory
cost.</p>
<p>Finally, one can see that because the return type of the API call is <code>String</code>,
there is still a fairly substantial <code>dlmalloc()</code> penalty in the loop, where
a chunk of heap memory is conjured to meet the requirements of the <code>get_version()</code>
API. Returning an <code>&amp;str</code> would remove that step, but then you have lifetime and
ownership ergonomics to contend with for that reference on the return.</p>
<h1><a class="header" href="#graphics-toolkit" id="graphics-toolkit">Graphics Toolkit</a></h1>
<p>The Xous UX stack consists of three levels:</p>
<ol>
<li><code>Modals</code> and <code>Menu</code>s</li>
<li>The <code>GAM</code> (Graphical Abstraction Manager)</li>
<li>The <code>graphics-server</code></li>
</ol>
<h1><a class="header" href="#overview" id="overview">Overview</a></h1>
<h2><a class="header" href="#modals-and-menus" id="modals-and-menus">Modals and Menus</a></h2>
<p>The <code>Modals</code> and <code>Menu</code> objects are pre-defined primitives that simplify the creation of Notifications, Checkboxes, Radioboxes, Text Entry boxes, Progress Bars, and Menus. They are as close as you get to a graphics toolkit in Xous.</p>
<h2><a class="header" href="#gam" id="gam">GAM</a></h2>
<p>Xous has a security-aware UX infrastructure that aims to make it difficult for rogue processes to pop up dialog boxes that could visually mimic system messages and password boxes.</p>
<p>The <code>GAM</code> is a layer that intermediates between the graphics toolkit and the hardware drivers, and enforces these security policies. It does this through the <code>Canvas</code> and <code>Layout</code> primitives.</p>
<p>The <code>Canvas</code> enforces a particular trust level associated with a region of the screen. White text on a black background is reserved for secure, trusted messages, and the <code>GAM</code> in combination with the trust level encoded in a <code>Canvas</code> is responsible for enforcing that rule. This is also where the <code>deface</code> operation occurs, the series of random lines that appear on items in the background.</p>
<p><code>Layout</code>s contain one or more <code>Canvas</code> objects and are used to define, at a coarse level, regions of the screen, such as where the status bar belongs, the IME, and so forth.</p>
<h2><a class="header" href="#graphics-server" id="graphics-server">Graphics Server</a></h2>
<p>The <code>graphics-server</code> is responsible for rendering primitives such as circles, lines, and glyphs to the frame buffer. It places no restrictions on where pixels may be placed.</p>
<p>The <code>graphics-server</code> uses the <code>xous-names</code> registry mechanism to restrict its access. No user processes can talk directly to it as a result.</p>
<h1><a class="header" href="#modals" id="modals">Modals</a></h1>
<p>You can use the <code>Modals</code> server to pop up the following objects:</p>
<ul>
<li>Notifications
<ul>
<li>Static: shows a message plus an &quot;Okay&quot; button</li>
<li>Dynamic: can sequence through multiple messages</li>
</ul>
</li>
<li>Checkboxes (multi-select list)</li>
<li>Radioboxes (single-select list)</li>
<li>Text Entry with validator</li>
<li>Progress bars</li>
</ul>
<p>To use <code>Modals</code> in your code, you will need to add <code>modals</code> to your <code>Cargo.toml</code> file. From an application in the <code>apps</code> directory:</p>
<pre><code class="language-toml">modals = {path = &quot;../../services/modals&quot;}
</code></pre>
<p>In all of the examples, you will need this pre-amble to create the <code>modals</code> object. The object can be re-used as many times as you like.</p>
<pre><code class="language-rust noplayground ignore">// connect to the modals object through the name resolver
let xns = XousNames::new().unwrap();
let modals = modals::Modals::new(&amp;xns).unwrap();
</code></pre>
<h2><a class="header" href="#static-notification" id="static-notification">Static Notification</a></h2>
<pre><code class="language-rust noplayground ignore">modals.show_notification(&quot;This is a test!&quot;).expect(&quot;notification failed&quot;);
</code></pre>
<p>This will pop up a notification that says &quot;This is a test!&quot;. Execution blocks at this line until the user pressses any key to acknowledge the notification.</p>
<h2><a class="header" href="#progress-bar" id="progress-bar">Progress bar</a></h2>
<p>One can create a progress bar using the <code>start_progress()</code> method, with the following parameters:</p>
<ul>
<li><code>name</code>: A <code>&amp;str</code> that is the title of the progress bar</li>
<li><code>start</code>: A <code>u32</code> that is the starting ordinal</li>
<li><code>end</code>: A <code>u32</code> that is the ending ordinal</li>
<li><code>current</code>: A <code>u32</code> that is the initial point of the progress bar</li>
</ul>
<p><code>start</code> should be less than <code>end</code>, and <code>current</code> should be between <code>start</code> and <code>end</code>, inclusive.</p>
<p>Once the bar is created, you can update its progress using the <code>update_progress()</code> method. It takes a number that represents the current progress between the start and end ordinal.</p>
<p>The progress bar is closed by calling the <code>finish_progress()</code> method.</p>
<pre><code class="language-rust noplayground ignore">// the ticktimer is used just to introduce a delay in this example. Normally, you'd do something computationally useful instead of just waiting.
let tt = ticktimer_server::Ticktimer::new().unwrap();

let start = 1;
let end = 20;
modals.start_progress(&quot;Progress Quest&quot;, start, end, start).expect(&quot;couldn't raise progress bar&quot;);

for i in (start..end).step_by(2) {
    modals.update_progress(i).expect(&quot;couldn't update progress bar&quot;);
    tt.sleep_ms(100).unwrap();
}
modals.finish_progress().expect(&quot;couldn't dismiss progress bar&quot;);
</code></pre>
<h2><a class="header" href="#dynamic-notifications" id="dynamic-notifications">Dynamic Notifications</a></h2>
<p>Dynamic notifications are notifications which don't have an option for the user
to close them; instead, the calling program controls when the dialog can
be closed, and can also dynamically update the message. This is useful for
displaying, for example, multi-phase progress updates without stopping and
waiting for a user to hit &quot;OK&quot;.</p>
<p>The API is similar to that of the Progress Bar, in that there are start, update,
and close phases:</p>
<ul>
<li>To pop up the dynamic notification, use the <code>dynamic_notification(title: Option&lt;&amp;str&gt;, text: Option&lt;&amp;str&gt;)</code>
method. The both <code>title</code> and <code>text</code> are optional, but at least one is recommended, otherwise
you get an empty notification.</li>
<li>Updates to the notification are done using <code>dynamic_notification_update(title: Option&lt;&amp;str&gt;, text: Option&lt;&amp;str&gt;)</code>.
Arguments that are <code>None</code> do not update, and show the same text as before.</li>
<li>Once you are finished showing the set of notifications, you must close the
dialog with <code>dynamic_notification_close()</code>.</li>
</ul>
<h2><a class="header" href="#text-entry" id="text-entry">Text entry</a></h2>
<p>One can request text entry using the <code>get_text()</code> method. This takes the following parameters:</p>
<ul>
<li><code>prompt</code>: A <code>&amp;str</code> that is the prompt to the user</li>
<li><code>validator</code>: An <code>Option&lt;fn(TextEntryPayload, u32) -&gt; Option&lt;ValidatorErr&gt;&gt;</code>. This is an optional function that takes the text entry payload, along with a dispatch opcode. The dispatch opcode allows a single validator function to be re-used across multiple invocations of <code>get_text()</code>.</li>
<li><code>validator_op</code>: An <code>Option&lt;u32&gt;</code>. When <code>Some()</code>, the argument inside is passed to the validator to indicate which type of text is being validated.</li>
</ul>
<p>The idea behind the <code>validator_op</code> is that you could create an <code>Enum</code> type that specifies the type of text you're entering, and you would pass the <code>u32</code> version of that <code>Enum</code> to the <code>get_text()</code> call so that a single <code>validator</code> function can be used to check multiple types of text entry.</p>
<pre><code class="language-rust noplayground ignore">// you can also use the num_derive crate to have bi-directional transformation of the enum
enum ValidatorOp {
    Int2 = 0,
    Int = 1,
}
//
fn my_code() {
    // ... insert code to create modals object, etc.
    match modals.get_text(&quot;Input an integer greater than 2&quot;, Some(test_validator), Some(ValidatorOp::Int2 as u32)) {
        Ok(text) =&gt; {
            log::info!(&quot;Input: {}&quot;, text.0);
        }
        _ =&gt; {
            log::error!(&quot;get_text failed&quot;);
        }
    }
    match modals.get_text(&quot;Input any integer&quot;, Some(test_validator), Some(ValidatorOp::Int2 as u32)) {
        Ok(text) =&gt; {
            log::info!(&quot;Input: {}&quot;, text.0);
        }
        _ =&gt; {
            log::error!(&quot;get_text failed&quot;);
        }
    }
}

fn test_validator(input: TextEntryPayload, opcode: u32) -&gt; Option&lt;xous_ipc::String::&lt;256&gt;&gt; {
    let text_str = input.as_str();
    match text_str.parse::&lt;u32&gt;() {
        Ok(input_int) =&gt;
        if opcode == ValidatorOp::Int2 as u32 {
            if input_int &lt;= 2 {
                return Some(xous_ipc::String::&lt;256&gt;::from_str(&quot;input must be larger than 2&quot;))
            } else {
                return None
            }
        } else if opcode == ValidatorOp::Int as u32 {
            return None
        } else {
            panic!(&quot;unknown discriminant&quot;);
        }
        _ =&gt; return Some(xous_ipc::String::&lt;256&gt;::from_str(&quot;enter an integer value&quot;))
    }
}
</code></pre>
<h2><a class="header" href="#radio-box" id="radio-box">Radio Box</a></h2>
<p>A radio box is a mechanism to force a user to pick exactly one item from a list of options.</p>
<p>One can construct a radio box by first repeatedly calling <code>add_list_item()</code> with a <code>&amp;str</code>
description of the items to select, and then calling <code>get_radiobutton()</code> with a <code>&amp;str</code> of
the prompt. The returned value will be the <code>&amp;str</code> description of the selected item.</p>
<p>Note that upon completion of the radio box, the list of items is automatically cleared
in preparation for another invocation of <code>modals</code>.</p>
<pre><code class="language-rust noplayground ignore">const RADIO_TEST: [&amp;'static str; 4] = [
    &quot;zebra&quot;,
    &quot;cow&quot;,
    &quot;horse&quot;,
    &quot;cat&quot;,
];

for item in RADIO_TEST {
    modals.add_list_item(item).expect(&quot;couldn't build radio item list&quot;);
}
match modals.get_radiobutton(&quot;Pick an animal&quot;) {
    Ok(animal) =&gt; log::info!(&quot;{} was picked&quot;, animal),
    _ =&gt; log::error!(&quot;get_radiobutton failed&quot;),
}
</code></pre>
<h2><a class="header" href="#check-box" id="check-box">Check Box</a></h2>
<p>A check box is a mechanism to present a user with a list of several options, of which
they can select none, some, or all of them.</p>
<p>The usage is nearly identical to the Radio Box above, except that the return value
is a <code>Vec::&lt;String&gt;</code>. The <code>Vec</code> will be empty if no elements are selected.</p>
<pre><code class="language-rust noplayground ignore">const CHECKBOX_TEST: [&amp;'static str; 5] = [
    &quot;happy&quot;,
    &quot;😃&quot;,
    &quot;安&quot;,
    &quot;peaceful&quot;,
    &quot;...something else!&quot;,
];

for item in CHECKBOX_TEST {
    modals.add_list_item(item).expect(&quot;couldn't build checkbox list&quot;);
}
match modals.get_checkbox(&quot;You can have it all:&quot;) {
    Ok(things) =&gt; {
        log::info!(&quot;The user picked {} things:&quot;, things.len());
        for thing in things {
            log::info!(&quot;{}&quot;, thing);
        }
    },
    _ =&gt; log::error!(&quot;get_checkbox failed&quot;),
}
</code></pre>
<h1><a class="header" href="#menus" id="menus">Menus</a></h1>
<p>Menus are created with the help of the <code>menu_matic()</code> convenience call.</p>
<p>Conceptually, a Menu in Xous is a list of <code>MenuItem</code>. Graphically, the menus
are rendered in the order that the <code>MenuItem</code>s are added to the list. When a <code>MenuItem</code> is selected, it fires a message off to another server to effect the corresponding outcome desired of the logical menu description.</p>
<p>Thus, each <code>MenuItem</code> has the following fields:</p>
<ul>
<li>A <code>name</code> describing the menu item, limited to a 64-byte long unicode string</li>
<li>An <code>Option</code> for an <code>action connection</code>. This is a CID to a server to which a message will be sent upon selecting the item. If <code>None</code>, the menu item does nothing and just closes the menu.</li>
<li>An <code>action opcode</code>. This is a <code>u32</code> value that corresponds to the discriminant of the <code>enum</code> used to dispatch opcodes in your main loop (e.g., the parameter passed as <code>msg.body.id()</code>).</li>
<li>A <code>MenuPayload</code>, which is an <code>enum</code> that currently can only be a <code>Scalar</code> payload consisting of up to 4 <code>u32</code> values. There's a future provision for this to be extended to a small <code>Memory</code> message but it is not yet implemented (please <a href="https://github.com/betrusted-io/xous-core/issues">open an issue</a> if you need this feature, and helpfully remind the maintainers to also update the Xous Book docs once this is done).</li>
<li><code>close on select</code> - when set to true, the menu will automatically close when the item is selected.</li>
</ul>
<p>So, when a <code>MenuItem</code> is selected by the user, the menu implementation will fire off a <code>Scalar</code> message to the server identified by <code>action_conn</code> with the opcode specified by <code>action opcode</code> and a payload of <code>MenuPayload</code>. The receiving server can asynchronously receive this message in its main loop and act upon the menu selection.</p>
<p>The general idiom is to create a <code>Vec</code> of <code>MenuItem</code>s, and then pass them into <code>MenuMatic</code>, as seen below:</p>
<pre><code class="language-rust noplayground ignore">pub fn create_kbd_menu(status_conn: xous::CID, kbd_mgr: xous::SID) -&gt; MenuMatic {
    let mut menu_items = Vec::&lt;MenuItem&gt;::new();

    let code: usize = KeyMap::Qwerty.into();
    menu_items.push(MenuItem {
        name: xous_ipc::String::from_str(&quot;QWERTY&quot;),
        action_conn: Some(status_conn),
        action_opcode: StatusOpcode::SetKeyboard.to_u32().unwrap(),
        action_payload: MenuPayload::Scalar([code as u32, 0, 0, 0]),
        close_on_select: true,
    });
    let code: usize = KeyMap::Dvorak.into();
    menu_items.push(MenuItem {
        name: xous_ipc::String::from_str(&quot;Dvorak&quot;),
        action_conn: Some(status_conn),
        action_opcode: StatusOpcode::SetKeyboard.to_u32().unwrap(),
        action_payload: MenuPayload::Scalar([code as u32, 0, 0, 0]),
        close_on_select: true,
    });
    menu_items.push(MenuItem {
        name: xous_ipc::String::from_str(&quot;Close Menu&quot;),
        action_conn: None,
        action_opcode: 0,
        action_payload: MenuPayload::Scalar([code as u32, 0, 0, 0]),
        close_on_select: true,
    });

    menu_matic(menu_items, gam::KBD_MENU_NAME, Some(kbd_mgr)).expect(&quot;couldn't create MenuMatic manager&quot;)
}

</code></pre>
<p>This will create a menu with three items, &quot;QWERTY&quot;, &quot;Dvorak&quot;, and &quot;Close Menu&quot;. When, for example, the &quot;QWERTY&quot; item is selected, it will send a message to the server pointed to be <code>status_conn</code>, with the argument of <code>StatusOpcode::SetKeyboard</code> as a<code>u32</code>, and an argument consisting of <code>[code, 0, 0, 0,]</code>. In this case, only <code>code</code> has meaning, and the other three are just placeholders.</p>
<p>The third menu item has <code>None</code> for the connection, so when it is selected, no messages are sent and the menu is simply closed.</p>
<h2><a class="header" href="#raising-the-menu" id="raising-the-menu">Raising the Menu</a></h2>
<p>Once you have created your menu, you can cause the menu to pop up with the following <code>gam</code> call:</p>
<pre><code class="language-rust noplayground ignore">gam.raise_menu(gam::KBD_MENU_NAME).expect(&quot;couldn't raise keyboard layout submenu&quot;);
</code></pre>
<p>The menu will automatically close if <code>close_on_select</code> is <code>true</code>.</p>
<h2><a class="header" href="#permission-to-create-menus" id="permission-to-create-menus">Permission to Create Menus</a></h2>
<p>What's the <code>gam::KBD_MENU_NAME</code> field all about?</p>
<p>In order to prevent rogue processes from creating menus willy-nilly that resemble, for example, the main menu but firing off forged messages to undesired processes, there is an access control list for menus.</p>
<p>The access control list is kept in the <code>gam</code>, and can be found in <code>services/gam/src/lib.rs</code>. You must add a <code>const str</code> that gives your menu a unique name, and insert it into the <code>EXPECTED_BOOT_CONTEXTS</code> structure, otherwise, the <code>gam</code> will deny the creation of your menu item. The access list is &quot;trust on first use&quot;, and secure operations such as accessing the root keys will not be allowed to proceed until all contexts have been allocated. Therefore, if you are creating a menu, you need to call <code>menu_matic()</code> early in the boot process, or else you will be unable to unlock the PDDB.</p>
<p>Permissions Checklist:</p>
<ol>
<li>Give your menu a name in <code>services/gam/src/lib.rs</code></li>
<li>Add the name to <code>EXPECTED_BOOT_CONTEXTS</code></li>
<li>Claim your name with <code>menu_matic()</code> early in the boot process</li>
</ol>
<h2><a class="header" href="#modifying-the-menu" id="modifying-the-menu">Modifying the Menu</a></h2>
<p><code>menu_matic()</code> has a third argument, which is an <code>Option&lt;xous::SID&gt;</code>. If you never plan to modify your menu, you can leave it as <code>None</code>. However, if you want to do things such as dynamically create and remove menu items, or pre-select an index in the menu list, you will need to specify an SID. This is used to create the <code>MenuMatic</code> object, which is returned to the caller.</p>
<p>The SID is created as follows:</p>
<pre><code class="language-rust noplayground ignore">let kbd_mgr = xous::create_server().unwrap();
</code></pre>
<p><code>MenuMatic</code> has the following methods available on it:</p>
<ul>
<li><code>add_item(MenuItem)</code> - adds the <code>MenuItem</code> specified to the end of the menu list, returning <code>true</code> to indicate success.</li>
<li><code>delete_item(&amp;str)</code> - deletes an item with a <code>name</code> specified as the argument. Returns <code>true</code> to indicate success.</li>
<li><code>set_index(usize)</code> - sets the index pointer of the menu to the specified offset. Typically ued to create a &quot;default&quot; position for the menu before it is raised.</li>
<li><code>quit()</code> - exit and destory the <code>MenuMatic</code> server</li>
</ul>
<p>If you don't need the above functionality, it's recommended that you do not create the server, as it consumes memory and eats up connection and server name space.</p>
<h1><a class="header" href="#the-plausibly-deniable-database-pddb-overview" id="the-plausibly-deniable-database-pddb-overview">The Plausibly Deniable DataBase (PDDB) Overview</a></h1>
<p>The Plausibly Deniable DataBase (<a href="https://www.bunniestudios.com/blog/?p=6307">PDDB</a>) is Xous' filesystem abstraction. It plays the role that a filesystem like <code>FAT</code> or <code>ext4</code> might play in other OSes, combined with full disk encryption like <code>LUKS</code> or <code>VeraCrypt</code>. It also features &quot;plausible deniability&quot;, which aims to make it difficult to prove &quot;beyond a reasonable doubt&quot; that additional secrets exist on the disk, even in the face of forensic evidence.</p>
<p>The PDDB can be accessed through a native API, or through Rust's <code>std::fs::File</code> layer. <code>std::fs::File</code> enables applications and libraries that are &quot;naive&quot; to deniability to run. Applications are free to mix-and-match between native and <code>std::fs::File</code> calls, and in most cases will deliver a less confusing and safer user experience if they are written with deniability built into the user work flow.</p>
<p><img src="images/betrusted-pddb-architecture.png" alt="dictionary to key mapping example" /></p>
<p>The PDDB is structured as a <code>key:value</code> store divided into <code>dictionaries</code> that features multiple overlay views. Each overlay view is called a <code>Basis</code> (plural Bases). A Basis has the following properties:</p>
<ul>
<li>The current view is the union of all open Bases</li>
<li>In case of namespace conflicts (two keys with the same name in a dictionary):
<ul>
<li>For reads, the value in the most recently unlocked Basis is returned</li>
<li>For writes, the value updates an existing key (if one exists) in the most recently unlocked Basis; otherwise, a new key is created in the most recently unlocked Basis.</li>
<li>In all cases, the API supports specifically naming a target Basis. This overrides the defaults specified above</li>
</ul>
</li>
<li>The default Basis is named <code>.System</code>, and it is created when the PDDB is formatted. The PDDB is considered mounted if the <code>.System</code> Basis can be found.</li>
<li>When a Basis is locked, its data is indistinguishable from free space and hence plausibly deniable.</li>
<li>A Basis is unlocked by a name and password combo. If either are lost or forgotten, the Basis is equivalent to having been deleted.</li>
</ul>
<p>One may also see the use of the term &quot;enumerated&quot; instead of &quot;unlocked&quot; in reference to a Basis. &quot;Enumeration&quot; refers to when the used space of a Basis is disclosed, but none of the core data structures are mounted. Typically the encryption keys are zeroized after enumeration. &quot;Unlocking&quot; refers to when the Basis is fully mounted, and its decryption keys and dictionary root records are cached in memory until the Basis is locked.</p>
<p>The PDDB documentation is structured into several chapters.</p>
<ul>
<li><a href="ch09-01-basis.html">Basis Internal Structure</a> does a deep-dive into the internal mechanics of the PDDB</li>
<li><a href="ch09-02-rootkeys.html">Key Derivation</a> outlines how the keys that secure the PDDB are derived</li>
<li><a href="ch09-03-api-native.html">Native API</a> is targeted at application developers who want to use native API calls</li>
<li><a href="ch09-04-api-std.html">Std API</a> is targeted at application developers who want to use <code>std::fs::File</code> calls</li>
<li><a href="ch09-05-testing.html">Testing</a> is targeted at kernel developers tracking down bugs in the PDDB</li>
<li><a href="ch09-06-backups.html">Backups</a> touches on how to extract data from backups made using the backup tool</li>
<li><a href="ch09-07-discussion.html">Discussion</a> covers issues affecting the security and deniability of the PDDB</li>
</ul>
<h1><a class="header" href="#basis-internal-structure" id="basis-internal-structure">Basis Internal Structure</a></h1>
<h2><a class="header" href="#overview-1" id="overview-1">Overview</a></h2>
<p>From an external API standpoint, users see the PDDB as a set of dictionaries containing keys:</p>
<p><img src="images/betrusted-pddb-architecture.png" alt="dictionary to key mapping example" /></p>
<p>This chapter goes behind the scenes and explores the internal structure, and how the Bases are allocated to provide multiple overlay views into the simplified example above.</p>
<h2><a class="header" href="#a-short-example" id="a-short-example">A Short Example</a></h2>
<p>Below is a contrived example of a PDDB consisting of two dictionaries, <code>Contacts</code> and <code>Passwords</code>, and two Bases, <code>Basis A</code> and <code>Basis B</code>:</p>
<p><img src="images/pddb-example1.png" alt="example of the PDDB with two secret bases open" /></p>
<p>The &quot;User View&quot; of the PDDB is the union of the data contained in <code>Basis A</code> and <code>Basis B</code>.</p>
<p>If the user were to lock <code>Basis B</code>, the &quot;User View&quot; would now lack the data contained within <code>Basis B</code>:</p>
<p><img src="images/pddb-example2.png" alt="example of the PDDB with one secret basis locked" /></p>
<p>Furthermore, each Basis is implemented using ciphers that have a particular characteristic, namely, <a href="https://web.cs.ucdavis.edu/%7Erogaway/papers/ad.pdf">IND$-CPA</a>: the ciphertext is indistinguishable from random noise. AES-GCM-SIV has this property (and if I'm not mistaken, provably indistingishable, but ask a cryptographer for the latest research).</p>
<p><img src="images/pddb-basic-idea.png" alt="the role of provable indistinguishability" /></p>
<p>Thus, when a Basis is locked, its data pages look indistinguishable from other pages in the PDDB storage area that have previously initialized with &quot;noise&quot; (more specifically, the output of a ChaCha8 CSPRNG that conditions the joint output of two TRNGs, a ring oscillator and an avalanche generator).</p>
<p>This quality of indistinguishability from free space is the source of plausible deniability. Side channels such as free space and API-level leakage degrade the amount of plausible deniability. See the chapter on <a href="ch09-07-discussion.html">Security and Deniability</a> for an in-depth discussion on deniability attacks and mitigations.</p>
<h2><a class="header" href="#orthogonal-virtual-page-table-structure" id="orthogonal-virtual-page-table-structure">Orthogonal Virtual Page Table Structure</a></h2>
<h3><a class="header" href="#page-table-format" id="page-table-format">Page Table Format</a></h3>
<p>The simplified diagram above would require a user to scan every page of storage and trial-decrypt each page to discover the full extent of user data. It also lacks an index to track what data goes where.</p>
<p>These two problems are solved by using a classic &quot;page table&quot; mechanism to map Basis data onto the actual storage array. The virtual memory space of any given Basis is 64 bits, with pages that are 4064 bytes long (this is 4096 physical bytes less a per-page overhead for AEC-GCM-SIV + journaling)</p>
<p>The page table itself consists of entries that are 128-bits long (sized to match the length of an AES block), that are encrypted with AES-ECB.</p>
<p><img src="images/pddb-details.png" alt="details of the PDDB implementation" /></p>
<p>Each page table entry is encodes the following data:</p>
<ul>
<li>52-bit virtual page number of the physical page corresponding to the offset of the page table, stored as a 56-bit zero-padded field.</li>
<li>8 bits of flags</li>
<li>32-bit nonce (see <a href="ch09-07-discussion.html#page-table-collision-leakage">discussion</a> on collisions)</li>
<li>32 bit <code>murmur3</code> hash checksum</li>
</ul>
<p>AES-ECB is tricky to use. However, it is fast, and requires no dependency to adjacent blocks. A nonce is provided to frustrate known-plaintext attacks. There is a trade-off between nonce size, checksum length, and fitting everything within a single AES block. The 32-bit nonce does not provide perfect collision resistance, but the potential leakage is hypothesized to be much smaller than other known side channels in the architecture. The impact of a collision is also negligible: an attacker will know that they have discovered a ciphertext that corresponds to a valid page table entry, but they don't know to which Basis or to what address.</p>
<p>The page table entry is also protected with a 32-bit murmur3 hash checksum that is not meant to be a cryptographic check; it is instead a fast &quot;go/no-go&quot; check on the potential validity of a page table entry. A page table entry is only considered fully valid until the corresponding data section also decrypts to the data key. The data sections are protected with a proper cryptographic-strength MAC via AES-GCM-SIV, so it's not a problem if we get occassional false-positives on the page table. In practice, false-positives turn into pages that are allocated-to-nowhere, e.g. the space never gets used to store useful data.</p>
<p>Thus the page table entry has the following characteristics:</p>
<ul>
<li>Maps physical pages to virtual pages</li>
<li>Fits in an AES block</li>
<li>Is quick to check for definitely invalid entries, but has a low false-positive rate that can be verified with a fully cryptographic MAC.</li>
<li>Has some protection against known-plaintext attacks; some leakage of information is expected, but is of minor consequence</li>
</ul>
<h3><a class="header" href="#page-table-orthogonality" id="page-table-orthogonality">Page Table Orthogonality</a></h3>
<p>All Bases share storage for their page table entries in the same page table, and each Basis has an identical virtual address space. Collisions of Bases are avoided (that is, the Bases are orthogonal) because the 256-bit AES key used to encrypt each page table entry is different. Thus, even if the plaintext of a page table entry is identical between several Bases, each Basis has a different AES key, and thus no Basis can accidentally decrypt the page table entry of another Basis.</p>
<p>Thus, when a Basis is &quot;mounted&quot;, the first operation is to take the <code>page table key</code> and trial-decrypt every block in the page table region. Blocks whose checksum match (along with a few other consistency properties) are populated into a <code>HashMap</code> that forms a candidate page table mapping for a given Basis. For Precursor's 98MiB PDDB, this means every time a Basis is mounted, about 25,000 AES blocks corresponding to as many pages need to be decrypted and trialed. This is a reasonably fast operation, thanks to the hardware AES engine, taking a couple of seconds total.</p>
<h2><a class="header" href="#virtual-memory-layout" id="virtual-memory-layout">Virtual Memory Layout</a></h2>
<p>The virtual memory layout of every Basis is identical.</p>
<p>A <code>VPAGE</code> in Basis space is is 0xFE0 (4,064) bytes long, which is equal to a <code>PAGE</code> of 4096 minus 32 bytes of encryption + journal overhead.</p>
<p>4064 is nice because it has convenient factors: 1, 2, 4, 8, 16, 32, 127, 254, 508, 1016, 2032, 4064.</p>
<p>The BasisRoot is located at <code>VPAGE</code> #1 (<code>VPAGE</code> #0 is always invalid, to make <code>Option</code>s zero-cost).</p>
<p>It contains a count of the number of valid dictionaries in the Basis. Dictionaries are found at
fixed offsets starting at 0xFE_0000 and repeating every 0xFE_0000 intervals, with up to 16383 dictionaries
allowed. A naive linear search is used to scan for dictionaries, starting at the lowest address,
scanning every 0xFE_0000, until the correct number of dictionares have been discovered. A dictionary can be effectively deleted by marking its descriptor as invalid.</p>
<p>A stride of 0xFE_0000 means that dictionary descriptors can be up to 4096 VPAGEs long. A dictionary
descriptor consists of a <code>DictDescriptor</code> header, some bookkeeping data, plus a count of the number
of keys in the dictionary. Following the header is a list of key descriptors. Similar to the Descriptors,
the key descriptors are stored at a stride of 127 (or 32 per <code>VPAGE</code>); they can be deleted by being marked
as invalid, and a linear scan is used to identify all the entries. A KeyDescriptor contains the name
of the key, flags, its age, and pointers to the key data in virtual memory space + its length.
This leads to a name length restriction of roughly 115 characters for keys and dictionaries, which is
about half of what most filesystems allow, but accommodates roughly 99.99% of the use cases.</p>
<p>Thus adding a new dictionary always consumes at least one 4k page, but you can have up to 15 keys
in that dictionary with no extra bookkeeping cost, once the first dictionary is added.</p>
<p>Each <code>VPAGE</code> is encrypted with AES-GCM-SIV, takes &quot;Additional Authenticating Data&quot;, or AAD. The AAD associated with the BasisRoot consist of a bytewise concatenation of:</p>
<ul>
<li>Basis name</li>
<li>Version number (complicates downgrade attacks)</li>
<li>FPGA's silicon DNA number (makes a naive raw-copy of PDDB data to another device unusable;
but of course, the DNA ID can be forged)</li>
</ul>
<p>Here are some of the assumptions that went into designing the PDDB:</p>
<ul>
<li>Most mutability happens on the data keys themselves (keys are read/write/modify routinely).</li>
<li>Dictionary modifications (key addition or removal) are about 20x less frequent than key mods.</li>
<li>Basis modifications (creation/removal of dictionaries) is about 10x less frequent than dictionary .</li>
<li>According to https://www.pdl.cmu.edu/PDL-FTP/HECStorage/Yifan_Final.pdf, 0.01% of files (1 in 10,
require a name over 100 bytes long; 0.1% require longer than 64 bytes. There longest filename tified
was 143 bytes long. Study surveys ~14M files on the LANL network.</li>
<li>Same study says 99.9% of directories have under 1k files, 99.999% under 10k</li>
</ul>
<h3><a class="header" href="#basis-virtual-memory-layout" id="basis-virtual-memory-layout">Basis Virtual Memory Layout</a></h3>
<table><thead><tr><th align="right">Start Address</th><th>Description</th></tr></thead><tbody>
<tr><td align="right">0x0000_0000_0000_0000</td><td>Invalid -- <code>VPAGE</code> 0 reserved for <code>Option&lt;&gt;</code></td></tr>
<tr><td align="right">0x0000_0000_0000_0FE0</td><td>Basis root page</td></tr>
<tr><td align="right">0x0000_0000_00FE_0000</td><td>Dictionary[0]</td></tr>
<tr><td align="right">+0</td><td>… Dict header (127 bytes)</td></tr>
<tr><td align="right">+7F</td><td>…… Maybe key entry (127 bytes)</td></tr>
<tr><td align="right">+FE</td><td>…… Maybe key entry (127 bytes)</td></tr>
<tr><td align="right">+FD_FF02</td><td>…… Last key entry start (128k possible)</td></tr>
<tr><td align="right">0x0000_0000_01FC_0000</td><td>Dictionary[1]</td></tr>
<tr><td align="right">0x0000_003F_7F02_0000</td><td>Dictionary[16382]</td></tr>
<tr><td align="right">0x0000_003F_8000_0000</td><td>Small data pool start  (~256GiB)</td></tr>
<tr><td align="right"></td><td>… Dict[0] pool = 16MiB (4k vpages)</td></tr>
<tr><td align="right"></td><td>…… SmallPool[0]</td></tr>
<tr><td align="right">+FE0</td><td>…… SmallPool[1]</td></tr>
<tr><td align="right">0x0000_003F_80FE_0000</td><td>… Dict[1] pool = 16MiB</td></tr>
<tr><td align="right">0x0000_007E_FE04_0000</td><td>… Dict[16383] pool</td></tr>
<tr><td align="right">0x0000_007E_FF02_0000</td><td>Unused</td></tr>
<tr><td align="right">0x0000_007F_0000_0000</td><td>Medium data pool start</td></tr>
<tr><td align="right"></td><td>… TBD</td></tr>
<tr><td align="right">0x0000_FE00_0000_0000</td><td>Large data pool start  (~16mm TiB)</td></tr>
<tr><td align="right"></td><td>…… Demand-allocated, bump-pointer; currently no defrag</td></tr>
<tr><td align="right"></td><td></td></tr>
</tbody></table>
<h3><a class="header" href="#memory-pools" id="memory-pools">Memory Pools</a></h3>
<p>Key data is split into three categories of sizes: small, medium, and large; but the implementation
currently only handles small and large keys. The thresholds are subject to tuning, but
roughly speaking, small data are keys &lt;4k bytes; large keys are everything else.</p>
<p>Large keys are the simplest - each key starts at a <code>VPAGE</code>-aligned address, and allocates
up from there. Any unused amount is wasted, but with a ~32k threshold you'll have no worse
than 12.5% unused space, probably closer to ~7%-ish if all your data hovered around the threshold.
The allocation is a simple pointer that just keeps going up. De-allocated space is never defragmented,
and we just rely on the space being &quot;huge&quot; to save us.</p>
<p>Small keys are kept in <code>VPAGE</code>-sized pools of data, and compacted together in RAM. The initial, naive
implementation simply keeps all small keys in a <code>HashMap</code> in RAM, and when it comes time to sync them
to disk, they are sorted by update count, and written to disk in ascending order.</p>
<p>Medium keys have a TBD implementation, and are currently directed to the large pool for now.</p>
<h3><a class="header" href="#size-limits" id="size-limits">Size Limits</a></h3>
<p>The biggest key the PDDB can handle, at least in this version, 32GiB. No, this is not
web scale, but it's big enough to hold a typical blu-ray movie as a single key.</p>
<p>One can adjust this constant up or down, and the trade-off is, you get more or less total number of large keys allocated over the life of the filesystem. This is because we simply &quot;increment a pointer&quot; when a new large key is added to create the next virtual memory spot for the large file, meaning each key get allocated a full 32GiB of virtual memory space for it to grow into.</p>
<p>At 32GiB, you can create a lifetime total of about 200 million keys (this includes keys you've previously deleted, until we create a mechanism for sweeping through the memory space and tracking de-allocations).</p>
<p>Note that a &quot;large&quot; keys includes anything over 4kiB, so if you create a 5kiB file, it can potentially grow to 32 GiB without bumping into the next large file.</p>
<p>This is a very &quot;lazy&quot; way to deal with large files. Given that the PDDB is initially designed for a 32-bit device with only 128MiB of memory and a read/write lifetime of 100k cycles for the FLASH, 200 million file allocations is probably greater than the lifetime of the device itself. If the PDDB migrates to a larger handphone-style application, I think it'll probably still hold up OK with 200 million total large file allocations over the device lifetime and a limit of 32GiB. That's about 73k files created per day for 10 years, or about 50 files per minute -- roughly one new file per second for 10 years straight before the PDDB runs out of virtual memory space.</p>
<p>A web server creating a &gt;4k temporary log file for every client that hit and then deleting it
would probably crush this limit in months. So don't use the PDDB to back a high volume web server.
But it's probably OK for a consumer electronics device with a typical lifetime of less than 10 years.</p>
<p>If you really think you want larger files and also more write life, you'd need to implement an in-memory
&quot;free&quot; file allocator, but honestly, this is not something I think we need to burn resources on for
the initial target of the PDDB (that is, a 100MiB device with 100k read/write endurance lifetime).
Anyways, the code is written so one can just slide this constant up or down and change the behavior
of the system; it's recommended you reformat when you do that but I /think/ it should actually be OK
if you made a change &quot;on the fly&quot;, because the bump allocator only cares about the size of data it intends to allocate, and disregards everything in the past.</p>
<p>Also note that in practice, a file size is limited to 4GiB on a 32-bit Precursor device anyways
because the <code>usize</code> type isn't big enough. Recompiling for a 64-bit target, however, should give
you access to the full 32GiB file size limit.</p>
<h3><a class="header" href="#ram-pressure" id="ram-pressure">RAM Pressure</a></h3>
<p>The PDDB retains in RAM a page table for every Basis. There are about 25,000 potential pages on a Precursor device, and there are no duplicate pages between Bases; thus, it's estimated that the page table structure may take about 500kiB of space at its largest.</p>
<p>In addition to the page tables, the PDDB agressively caches all &quot;small&quot; keys. The current implementation assumes that any small key is always &quot;hot&quot; in cache, and the disk is just a write-through backing store in case power is lost. In practice, the heap size limit of the PDDB server is about 2MiB, so, the system should crash if one starts to push around a megabyte total of small key data. That's about 256 exactly 4k-sized keys, but typically small keys are very small, about 32 bytes, so the practical limit is probably closer to 10k-20k 32-byte keys.</p>
<p>Large keys consume about one 4k-page per key, regardless of the key size. Large keys only retrieve their data when requested, and will keep only the most recently accessed page in RAM, regardless of the size of the large key. Thus one could store a several-megabyte file in a large key, and not worry about blowing out the cache.</p>
<p>However, because the large key cache is so simple, it has performance problems, especially for situations where one plans to access large key data randomly, or in the worst case, they are accessing bytes that happen to cross a page boundary -- every time you cross the boundary, the old page is forgotten, and the new page is read in.</p>
<p>The caching mechanism can be improved down the road, but, at the moment for an application like <code>vault</code>, the current implementation should be more than adequate to handle hundreds of password records.</p>
<h3><a class="header" href="#the-make-before-break-mbbb-structure" id="the-make-before-break-mbbb-structure">The &quot;Make Before Break&quot; (MBBB) Structure</a></h3>
<p>In order to protect against data loss in case of an untimely power outage, several pages of FLASH is devoted to the &quot;make before break&quot; feature. The core problem is that a single erase page of the page table contains records for 256 page table entres. If there is a power outage while updating one of the entries, all of the other 255 entries are also lost.</p>
<p>Thus, the MBBB mechanism creates a shadow area where the page table page being updated can be copied, prior to erasing it.</p>
<p>Initially, the MBBB area is blank (all <code>FF</code>'s). When a page table entry needs to be updated, the whole page containing the entry is copied to a random sector in the MBBB (the randomness is for wear-levelling, not security) <em>with</em> the changes applied, and then the page containing the page table entry is erased.</p>
<p>When the next page table entry needs to be updated, the MBBB page table image is then written to the blank slot in the page table, and the process repeats.</p>
<p>There is no mechanism to record where the MBBB page is:</p>
<ul>
<li>The MBBB area is only consulted if a blank page is found in the page table</li>
<li>&quot;Blankness&quot; of an area is determined by only consulting the first 16 bytes and checking if they are 0xFF. If it is, the entire page is considered blank.</li>
<li>The MBBB area may only contain 0 or 1 backup pages. Thus, when it is consulted, the algorithm searches for the first non-blank page and uses that as the MBBB page.</li>
</ul>
<h2><a class="header" href="#free-space" id="free-space">Free Space</a></h2>
<p>Plausible deniability is all about reducing the number of side channels that can leak information about the existence or non-existence of secret data. The amount of free space in the PDDB is a potent side channel. If the true amount of free space could be known, an adversary can use that to deduce the existence or non-existence of additional secrets within the PDDB beyond the ones revealed to the adversary.</p>
<p>The PDDB's solution to this is to create a cache of free space that represents a defined fraction of the total true free space. The parameters are tunable, but in v0.9.9 the default parameters are to allocate up to 50% +/- 10% of the smaller of the true free space or the capacity of the FSCB toward the free space cache, known as the FSCB (&quot;Fast Space Cache Buffer&quot;). The +/-10% is a fudge factor that is determined by the TRNG. Note that most of the time, the capacity of the FSCB (about 2000 pages, or 7.5% of Precursor hardware capacity) is the limit of the trackable space, due to the capacity limit inherent in the FSCB.</p>
<p>Thus, the situation for free space in the PDDB looks a bit like the schematic shown below, where the pink areas are &quot;maybe noise? maybe data?&quot; and the gray areas are &quot;definitely free space&quot; (the actual situation is much more fragmented, this is just a cartoon).</p>
<p><img src="images/pddb-freespace.png" alt="schematic of free space handling in the PDDB" /></p>
<p>An adversary can thus query the FSCB and know that, for example, a device may currently have about 7% of the total capacity marked as free space. However, they cannot say for sure that this means that the device is 93% full -- it could be that the device is brand new and has nothing allocated, but the free space has just hit the limit of the FSCB capacity. Or it could be any number of intermediate states in between: it would be hard to prove beyond a reasonable doubt the exact state of disk usage.</p>
<p>In the case that the FSCB is exhausted, the user is greeted with a prompt that warns them that the FSCB has been exhausted, and in order to proceed without data loss, every secret Basis must be enumerated (that is, its name and password must be presented to unlock it; the distinction between enumeration and unlocking is that enumeration simply counts the pages used, without attempting to mount any filesystem structures). A user can bail out of enumeration, causing the operation that triggered the FSCB refill to fail with an out-of-memory error. Likewise, failure to present a secret Basis at this point could result in its data being pulled into the FSCB, and ultimately being deleted.</p>
<p>The FSCB refill proceeds to enumerate every page in every Basis into a single &quot;master&quot; record of disk usage. It then randomly selects pages out of the unused pages (the inverse of the disk usage record) until the FSCB is full. The system consumes entries out of the FSCB in random order. Thus the FSCB is also a wear-levelling mechanism, since free blocks are handed out in random order.</p>
<p>At the implementation level, each FSCB entry is a single <code>u32</code> that tracks the physical page number of a free page plus a few bits for flags to help with journaling (as described in the <code>SpaceUpdate</code> section below). There is a flag for 64-bit physical addresses too, so the FSCB can be upgraded to run on a 64-bit CPU. The entire FSCB is exactly 2 pages long on v0.9.9 (and adjustable with a <code>const</code>). The structure is padded with 0's to full length regardless of the amount of actual free space recorded in it; note that a 0-record is automatically ignored due due to the <code>valid</code> flag being 0. The fixed-length padded structure is encrypted with AES-GCM-SIV using the <code>.System</code> Basis' data key and written to the FSCB area at a random offset. The FSCB is later identified by querying the first 16 bytes of every page in the FSCB area and choosing the one that is not all <code>0xFF</code>.</p>
<h3><a class="header" href="#spaceupdate-records" id="spaceupdate-records">SpaceUpdate Records</a></h3>
<p>The FSCB itself becomes a hotspot for write activity that would rapidly wear out if every time a page was allocated the entire encrypted structure had to be erased and re-written. The good news is that most flash devices (including Precursor's) support incremental writing to a blank (<code>0xFF</code>) space without erasing it, e.g. you can take any byte that is currently <code>0xFF</code> and set it to any other number without having to first erase the whole sector. Most journaling flash filesystems take advantage of this, but it is more difficult to do in a plausibly deniable sense because all of the free data space in the PDDB has been pre-initialized with random noise.</p>
<p>The solution to this is to use blank sectors in the FSCB -- which <em>are</em> kept as <code>0xFF</code> -- for a journal. So, as pages are consumed from the FSCB, they are journaled to a blank area in the FSCB using incremental-writing techniques. Thus the total amount free space available is determined first by reading the master FSCB record, and then subtracting the impact of journal entries. These incremental updates are known as <code>SpaceUpdate</code> records. Each <code>SpaceUpdate</code> record is encrypted with AES-ECB, and thus its size is 16 bytes.</p>
<p>The three types of records (<code>0xFF</code> empty space, <code>FastSpace</code> and <code>SpaceUpdate</code>) are differentiated by examining the first 32 bytes of a page:</p>
<ul>
<li>If bytes 0-31 are <code>0xFF</code>, the entire page must be blank (empty space)</li>
<li>If any of bytes 0-15 are not 0xFF, the page must be the start of a <code>FastSpace</code> master record. The master record itself may span mulitple pages but it must be consecutive pages from its start.</li>
<li>If all bytes of 0-15 are 0xFF, <strong>and</strong> any bytes of 16-31 are not 0xFF, then the page marks the start of <code>SpaceUpdate</code> records. A <code>SpaceUpdate</code> record is similar to that of a page table entry, but with the flags set differently to indicate the life cycle of that space, and a larger <code>u64</code> nonce. From that page until the end of the <code>FastSpace</code> area, <code>SpaceUpdate</code> records may be written.</li>
</ul>
<p>The <code>SpaceUpdate</code> records are interpreted sequentially, from the lowest address to the highest address encountered. The latest record takes precedence. Thus, a single page could be allocated, de-allocated, and re-allocated in sequence, and the last re-allocation is the ultimate record that affects the net FSCB.</p>
<p>When the <code>SpaceUpdate</code> record fills up the FSCB area (or it bumps into the existing FSCB), the records are automatically compacted; the FSCB is reduced by any allocated space at that time, the <code>SpaceUpdate</code> area is cleared, and a new random location is picked for the FSCB to wear-level the FSCB area. This all happens without user intervention or awareness, except for the fact that the operation which triggered the flush might take a bit longer than usual (about an extra 0.3s).</p>
<p>Note that the <code>SpaceUpdate</code> journal by definition leaks information about the most recent few hundred block allocations, so in the event that the unlock PIN is compromised, it could represent a significant loss of deniability. In order to counter this, a user can manually run <code>pddb flush</code> at any time compact the <code>SpaceUpdate</code> records and effectively delete the journal. Note that this doesn't require enumerating any Bases, because this only clears a journal of operations on known free space, and it also does not attempt to allocate any new free space.</p>
<p>Note: the hotfix for v0.9.9 incorporates a call to flush the journal once every 24 hours of uptime automatically. The call should be safe to run asynchronously since the FSCB state is independent of filesystem state.</p>
<h2><a class="header" href="#physical-layout" id="physical-layout">Physical Layout</a></h2>
<p>The physical layout of the PDDB (as of v0.9.9) is as follows, from lowest to highest address:</p>
<ul>
<li>Page tables</li>
<li>Static crypto data (one page)</li>
<li>MBBB area (10 pages)</li>
<li>FSCB (16 pages)</li>
<li>Data pages (1:1 map to page table entries)</li>
</ul>
<p>In the case that you're looking at a backup image, a single page of memory is pre-pended to the PDDB area that contains the root key block plus some versioning data, encrypted with the BIP-39 backup key using AES-GCM-SIV with key commitment.</p>
<h1><a class="header" href="#deriving-the-pddbs-keys" id="deriving-the-pddbs-keys">Deriving The PDDB's Keys</a></h1>
<p>This chapter examines the cryptopraphic material used to encrypt the PDDB, and traces its origin all the way back to the hardware root of trust. It assumes you are familiar with the general structure of the PDDB.</p>
<h2><a class="header" href="#basis-keys" id="basis-keys">Basis Keys</a></h2>
<p>A Basis within the PDDB holds a virtual filesystem that is unionized with the other Bases. A Basis is protected with a <code>name</code> and <code>password</code> combination. Neither the <code>name</code> nor the <code>password</code>, nor a hash or salt for a password, is stored within the PDDB, as such records would be a sidechannel revealing the existence of a secret Basis. Thus the confidentiality of a Basis is derived entirely from the strength of the <code>password</code>, but there is a generic, per-device salt (perhaps more accurately called a &quot;pepper&quot;) that means brute force attackers must prepare hash tables unique to each device.</p>
<p>A Basis is defined by two keys:</p>
<ul>
<li>A 256-bit page table key, used to derive an AES cipher run in ECB</li>
<li>A 256-bit data key, used to derive an AES-GCM-SIV cipher</li>
</ul>
<p>The cryptographic matter pertaining specifically to the PDDB is stored in raw FLASH in a header with the following structure:</p>
<pre><code class="language-rust noplayground ignore">#[repr(C)]
pub(crate) struct StaticCryptoData {
    /// a version number for the block
    pub(crate) version: u32,
    /// aes-256 key of the system basis page table, encrypted with the User0 root key, and wrapped using NIST SP800-38F
    pub(crate) system_key_pt: [u8; WRAPPED_AES_KEYSIZE],
    /// aes-256 key of the system basis, encrypted with the User0 root key, and wrapped using NIST SP800-38F
    pub(crate) system_key: [u8; WRAPPED_AES_KEYSIZE],
    /// a pool of fixed data used for salting. The first 32 bytes are further subdivided for use in the HKDF.
    pub(crate) salt_base: [u8; 4096 - WRAPPED_AES_KEYSIZE * 2 - size_of::&lt;u32&gt;()],
}
</code></pre>
<p>The structure is sized to be exactly one page of memory, with the &quot;remaining&quot; data filled with TRNG-derived salt. The version number is considered a &quot;hint&quot;, as it is not signature protected and there are no anti-rollback measures.</p>
<p>The PDDB has a default Basis called <code>.System</code>, which has its page table and data keys stored as wrapped keys by the device's root enclave. It is the only Basis treated in this manner. All other Bases are derived from the <code>name</code> and <code>password</code> of the basis, as hashed by <code>salt_base</code>. Any Basis that is not the <code>.System</code> Basis is referred to as a &quot;secret Basis&quot;.</p>
<h3><a class="header" href="#secret-basis-key-derivation" id="secret-basis-key-derivation">Secret Basis Key Derivation</a></h3>
<p>A secret Basis key derivation is performed using the folowing algorithm, implemented in Rust but presented here in Python for clarity:</p>
<pre><code class="language-python">for name, pw in basis_credentials.items():
    # Basis names are limited to 64 bytes encoded as UTF-8.
    # Copy the Basis name into a 64-byte array that is initialized with all 0's
    bname_copy = [0]*64
    i = 0
    for c in list(name.encode('utf-8')):
        bname_copy[i] = c
        i += 1

    # Passwords are limited to 72 bytes encoded as UTF-8. They are
    # always null-terminated, so a 73-byte 0-array is prepared.
    plaintext_pw = [0]*73
    pw_len = 0
    for c in list(pw.encode('utf-8')):
        plaintext_pw[pw_len] = c
        pw_len += 1
    pw_len += 1 # For the null termination

    # Hash the 64-byte basis name, 73-byte password and the `salt_base` using SHA512/256.
    hasher = SHA512.new(truncate=&quot;256&quot;)
    hasher.update(salt_base[32:]) # from byte 32 until the end of the salt region (couple kiB)
    hasher.update(bytes(bname_copy))
    hasher.update(bytes(plaintext_pw))
    derived_salt = hasher.digest()

    # Use the first 16 bytes of the derived salt and the null-terminated plaintext password
    # to drive a standard `bcrypt` with a work factor of 7. We can only do 7 because the
    # target hardware is a single-issue, in-order 100MHz RV32-IMAC.
    bcrypter = bcrypt.BCrypt()
    hashed_pw = bcrypter.crypt_raw(plaintext_pw[:pw_len], derived_salt[:16], 7)

    # Derive a key for the page table, using HKDF/SHA256, plus the first 32 bytes of salt,
    # and an info word of &quot;pddb page table key&quot;
    hkdf = HKDF(algorithm=hashes.SHA256(), length=32, salt=pddb_salt[:32], info=b&quot;pddb page table key&quot;)
    pt_key = hkdf.derive(hashed_pw)

    # Derive a key for the data pages, using KHDF/SHA256, plus teh first 32 bytes of salt,
    # and an info word of &quot;pddb data key&quot;
    hkdf = HKDF(algorithm=hashes.SHA256(), length=32, salt=pddb_salt[:32], info=b&quot;pddb data key&quot;)
    data_key = hkdf.derive(hashed_pw)

    keys[name] = [pt_key, data_key]
</code></pre>
<h3><a class="header" href="#system-basis-key-derivation" id="system-basis-key-derivation">System Basis Key Derivation</a></h3>
<p>The System basis keys for the PDDB are wrapped by the Precursor's on-board <code>root-keys</code> block. They are wrapped using the <code>User0</code> key (also referred to as the <code>user root key</code>). Please see the Xous wiki for more information on the <a href="https://github.com/betrusted-io/betrusted-wiki/wiki/Secure-Boot-and-KEYROM-Layout#key-rom-format">layout of the root key block</a>.</p>
<pre><code class="language-python"># Pseudocode for accessing the root keys from the key block.
# The user key is at offset 40, 32 bytes long.
user_key_enc = get_key(40, keyrom, 32)
# The pepper is at offset 248, 16 bytes long.
pepper = get_key(248, keyrom, 16)
# The password type is XOR'd in to the pepper, to make it less convenient
# for pre-computed rainbow tables to re-use their work across various passwords.
pepper[0] = pepper[0] ^ 1 # encodes the &quot;boot&quot; password type into the pepper

# The unlock PIN is up to 72 bytes long, encoded as UTF-8. Prepare a null-terminated
# version of the password. Here the pseudocode refers to the &quot;unlock PIN&quot; as &quot;boot_pw&quot;
boot_pw_array = [0] * 73
pw_len = 0
for b in bytes(boot_pw.encode('utf-8')):
    boot_pw_array[pw_len] = b
    pw_len += 1
pw_len += 1 # null terminate, so even the null password is one character long

# Use bcrypt on the password + pepper to derive a key. See above for notes on
# the use of a work factor of 7.
bcrypter = bcrypt.BCrypt()
hashed_pw = bcrypter.crypt_raw(boot_pw_array[:pw_len], pepper, 7)

# Expand the derived 24-byte password to 32 bytes with SHA512/256.
hasher = SHA512.new(truncate=&quot;256&quot;)
hasher.update(hashed_pw)
user_pw = hasher.digest()

# XOR the derived key with the encrypted, stored user_key to get the plaintext user_key
user_key = []
for (a, b) in zip(user_key_enc, user_pw):
    user_key += [a ^ b]

# Derive an anti-rollback user state. This takes the user_key and hashes it
# repeatedly, a maximum of 255 times. Every time we need to version the system
# with anti-rollback, we increase a counter stored at offset 254 in the keyrom
# and subtract this from 255. This means newer versions can still access older
# versions by applying N extra hashes (where N is the number of versions older)
# that need to be accessed, while making it impossible for an application holding
# the current key to guess what the next key might be in the anti-rollback sequence.
rollback_limit = 255 - int.from_bytes(keyrom[254 * 4 : 254 * 4 + 4], 'little')
for i in range(rollback_limit):
    hasher = SHA512.new(truncate=&quot;256&quot;)
    hasher.update(bytes(user_key))
    user_key = hasher.digest()
# user_key now contains the actual key that is used to wrap the PDDB system keys.

# Access the wrapped system keys from the StaticCryptoData structure (as defined above)
wrapped_key_pt = static_crypto_data[4:4+40]
wrapped_key_data = static_crypto_data[4+40:4+40+40]

# Extract the .System key by unwrapping the system keys with AES-KWP, per NIST SP800-38F
# (or identically RFC 5649).
key_pt = aes_key_unwrap_with_padding(bytes(user_key), bytes(wrapped_key_pt))
key_data = aes_key_unwrap_with_padding(bytes(user_key), bytes(wrapped_key_data))

# The key unwrapping method will fail with very high probability if the provided
# user password is incorrect. Thus the results from the key unwrap must be checked
# and handled for the case of an incorrect boot password.
</code></pre>
<p>The application of the page table and data keys are discussed in the chapter on the <a href="ch09-01-basis.html">Basis Internal Structure</a>. Note that the AES-GCM-SIV for the data keys does require AAD, which includes the device-specific DNA as well as the version number of the PDDB.</p>
<h1><a class="header" href="#native-api" id="native-api">Native API</a></h1>
<p>The &quot;native&quot; API for the PDDB is a set of <code>xous</code>-specific calls that one can use to manage and access the PDDB.</p>
<p>All of the native API method signatures can be found in <a href="https://github.com/betrusted-io/xous-core/blob/main/services/pddb/src/lib.rs"><code>lib.rs</code></a> and the <a href="https://github.com/betrusted-io/xous-core/blob/main/services/pddb/src/frontend/pddbkey.rs">frontend</a> module. Proper Rustdoc for these is on the list of things to do. This chapter treats the native API at an abstract level, with a focus on code examples rather than 100% coverage of every feature.</p>
<h2><a class="header" href="#the-pddb-object" id="the-pddb-object">The <code>Pddb</code> Object</a></h2>
<p>Any native access to the PDDB goes through the <code>Pddb</code> object. You will need to add the <code>pddb</code> service to your <code>Cargo.toml</code> file, and then create a PDDB object like such:</p>
<pre><code class="language-rust noplayground ignore">let pddb = pddb::Pddb::new();
</code></pre>
<p>The method you'll use the most is the <code>.get()</code> method on the <code>Pddb</code> object. It has a signature like this:</p>
<pre><code class="language-rust noplayground ignore">pub fn get(
    &amp;self,
    dict_name: &amp;str,
    key_name: &amp;str,
    basis_name: Option&lt;&amp;str&gt;,
    create_dict: bool,
    create_key: bool,
    alloc_hint: Option&lt;usize&gt;,
    key_changed_cb: Option&lt;impl Fn() + 'static + Send&gt;
) -&gt; Result&lt;PddbKey&gt;
</code></pre>
<p><code>dict_name</code> and <code>key_name</code> are the names of the dictionary and key. They can be any valid UTF-8 string but you should avoid the <code>:</code> character as that is the path separator. Dictionary names can be up to 111 bytes long, and key names up to 95 bytes long.</p>
<p><code>basis_name</code> is an optional Basis name, that can be any valid UTF-8 string that avoids <code>:</code>. Basis names can be up to 64 bytes long. If <code>basis_name</code> is <code>None</code>, then the Basis to use will be computed as follows:</p>
<ul>
<li>If the key exists in any Basis, the most recently open Basis is accessed for that key.</li>
<li>If the key does not exist, then either it returns an error (depending on the flags), or it creates the key in the most recently opened Basis.</li>
</ul>
<p>The System basis (available at <code>pddb::PDDB_DEFAULT_SYSTEM_BASIS</code>) is the fall-back as it is always mounted. Administrative operations, especially ones that deal with non-sensitive settings, should generally specify the system basis explicitly so that options don't mysteriously reset or disappear when secret Bases are mounted or unmounted.</p>
<p><code>create_dict</code> specifies to create the dictionary, if it does not already exist.</p>
<p><code>create_key</code> specifies to create the key, if it does not already exist.</p>
<p><code>alloc_hint</code> is a hint to the system as to how much space it should allocate for the key. This parameter is only used when the key is created; later calls will ignore this. Generally, system performance will be much faster if you provide an <code>alloc_hint</code>, especially for small keys. Without the hint, the key size starts at 4 bytes, and every byte written deletes and re-allocates the key to grow to the next byte size. This is mitigated partially by buffering in the <code>Read</code> API, but if you have a sense of how big a key might be in advance, it's helpful to pass that on.</p>
<p><code>key_changed_cb</code> is a callback meant to notify the key accessor that the key's status has changed. Typically this would be the result of someone locking or unlocking a secret Basis. As a <code>static + Send</code> closure, generally one would place a call to <code>xous::send_message()</code> inside the call, that would send a message to another server to handle this situation, similar to this:</p>
<pre><code class="language-rust noplayground ignore">static SELF_CONN: AtomicU32 = AtomicU32::new(0); // 0 is never a valid CID

pub(crate) fn basis_change() {
    if SELF_CONN.load(Ordering::SeqCst) != 0 {
        xous::send_message(SELF_CONN.load(Ordering::SeqCst),
            Message::new_scalar(Opcode::BasisChange.to_usize().unwrap(), 0, 0, 0, 0)
        ).unwrap();
    }
}

// In the main loop, there would be some code similar to this:
fn main () {
    let xns = xous_names::XousNames::new().unwrap();
    let sid = xns.register_name(&quot;_My Server_&quot;, None).unwrap();
    let conn = xous::connect(sid).unwrap();
    SELF_CONN.store(conn, Ordering::SeqCst);
    // at this point SELF_CONN will be non-zero
}

// later on, a piece of code might refer to the function as follows:
fn myfunc() {
    let key = pddb.get(
        &amp;dictname,
        &amp;keyname,
        None,
        false, false, None,
        Some(crate::basis_change)
    ).unwrap();
    // if you want the callback to be None, you must specify the type of None as follows:
    let key2 = pddb.get(
        &amp;dictname,
        &amp;key2name,
        None,
        false, false, None,
        None::&lt;fn()&gt;
    ).unwrap();
}
</code></pre>
<h2><a class="header" href="#access-examples" id="access-examples">Access Examples</a></h2>
<p>The general flow for writing to the PDDB is as follows:</p>
<ol>
<li>Serialize your data into a <code>[u8]</code> slice</li>
<li>Fetch the key using the <code>pddb.get()</code> method</li>
<li>Use any <code>Write</code> trait from <code>std::io::Write</code> to write the data</li>
<li>Sync the PDDB (highly recommended, especially at this early stage)</li>
</ol>
<p>The general flow for reading data from the PDDB is as follows:</p>
<ol>
<li>Fetch the key using the <code>pddb.get()</code> method</li>
<li>Use any <code>Read</code> trait from <code>std::io::Read</code> to write the data</li>
<li>Deserialize the data into a <code>[u8]</code> slice</li>
</ol>
<p>Below is an example of writing a key.</p>
<pre><code class="language-rust noplayground ignore">use std::io::Write;

let pddb = pddb::Pddb::new();
let record = PasswordRecord {
    version: VAULT_PASSWORD_REC_VERSION,
    description,
    username,
    password,
    // ... other line items
};
let ser = serialize_password(&amp;record);
let guid = self.gen_guid();
log::debug!(&quot;storing into guid: {}&quot;, guid);
pddb.borrow().get(
    VAULT_PASSWORD_DICT,
    &amp;guid,
    None, true, true,
    Some(VAULT_ALLOC_HINT), Some(crate::basis_change)
)
.expect(&quot;error accessing the PDDB&quot;)
.write(&amp;ser)
.expect(&quot;couldn't write data&quot;);
log::debug!(&quot;syncing...&quot;);
pddb.borrow().sync().ok();
</code></pre>
<p>And below is an example of reading a key.</p>
<pre><code class="language-rust noplayground ignore">use std::io::Read;

let pddb = pddb::Pddb::new();
let mut record = pddb.borrow().get(
    VAULT_PASSWORD_DICT,
    &amp;key,
    None,
    false, false, None,
    Some(crate::basis_change)
).expect(&quot;couldn't find key&quot;);
let mut data = Vec::&lt;u8&gt;::new();
match record.read_to_end(&amp;mut data) {
    Ok(_len) =&gt; {
        if let Some(pw) = deserialize_password(data) {
            // pw now contains the deserialized data
        } else {
            // handle errors
        }
    }
    Err(e) =&gt; // handle errors
}
</code></pre>
<h2><a class="header" href="#management" id="management">Management</a></h2>
<p>The Pddb object also has methods to help manage the PDDB, including:</p>
<ul>
<li><a href="https://github.com/betrusted-io/xous-core/blob/ac1f7465667aabb7bc7fa3e3e9ced8e980ea4a0c/services/pddb/src/lib.rs#L163"><code>list_basis(..)</code></a></li>
<li><a href="https://github.com/betrusted-io/xous-core/blob/ac1f7465667aabb7bc7fa3e3e9ced8e980ea4a0c/services/pddb/src/lib.rs#L208"><code>create_basis(..)</code></a></li>
<li><a href="https://github.com/betrusted-io/xous-core/blob/main/services/pddb/src/lib.rs#L230"><code>unlock_basis(..)</code></a></li>
<li><a href="https://github.com/betrusted-io/xous-core/blob/main/services/pddb/src/lib.rs#L252"><code>lock_basis(..)</code></a></li>
<li><a href="https://github.com/betrusted-io/xous-core/blob/main/services/pddb/src/lib.rs#L274"><code>delete_basis(..)</code></a></li>
<li><a href="https://github.com/betrusted-io/xous-core/blob/main/services/pddb/src/lib.rs#L386"><code>delete_key(..)</code></a></li>
<li><a href="https://github.com/betrusted-io/xous-core/blob/main/services/pddb/src/lib.rs#L435"><code>delete_dict(..)</code></a></li>
<li><a href="https://github.com/betrusted-io/xous-core/blob/main/services/pddb/src/lib.rs#L498"><code>list_keys(..)</code></a></li>
<li><a href="https://github.com/betrusted-io/xous-core/blob/main/services/pddb/src/lib.rs#L560"><code>list_dict(..)</code></a></li>
<li><a href="https://github.com/betrusted-io/xous-core/blob/ac1f7465667aabb7bc7fa3e3e9ced8e980ea4a0c/services/pddb/src/lib.rs#L143"><code>is_mounted_blocking(..)</code></a> - blocks until the PDDB is mounted</li>
</ul>
<p>For non-blocking queries of PDDB mount status, there is an object called <code>PddbMountPoller</code> which has a method <a href="https://github.com/betrusted-io/xous-core/blob/ac1f7465667aabb7bc7fa3e3e9ced8e980ea4a0c/services/pddb/src/lib.rs#L44"><code>is_mounted_nonblocking()</code></a>.</p>
<h1><a class="header" href="#std-api" id="std-api"><code>std</code> API</a></h1>
<p>⚠ The <code>std</code> API is only accurate on real hardware and Renode emulation. <code>std</code> on hosted mode will use the <code>std</code> implementation of the host.</p>
<p>The PDDB is also accessible from <code>std::fs::File</code>, as <a href="https://xobs.io/experimental-rust-filesystem-and-path-support-for-xous/">described here</a>:</p>
<pre><code class="language-rust noplayground ignore">fn main() {
    // Create an example file under the `sys.rtc` key
    let mut file = std::fs::File::create(&quot;sys.rtc:test&quot;).unwrap();
    file.write_all(&amp;[1, 2, 3, 4]).unwrap();
    // Close the file.
    core::mem::drop(file);

    // Open the example file and ensure our data is present
    let mut file = std::fs::File::open(&quot;sys.rtc:test&quot;).unwrap();
    let mut v = vec![];
    file.read_to_end(&amp;mut v).unwrap();
    assert_eq!(&amp;v, &amp;[1, 2, 3, 4]);
    // Close the file.
    core::mem::drop(file);

    // Remove the test file
    std::fs::remove_file(&quot;sys.rtc:test&quot;).unwrap();
}
</code></pre>
<p>The example above shows the process of creating, reading from, and deleting a file.</p>
<p>The main difference from a Unix-like or Windows interface is that the path separator on Xous is <code>:</code>.</p>
<p>At this time, PDDB has no restrictions on dict or key names, meaning it's possible to create a key with a <code>:</code> in the name. The standard library functions won't be able to disambiguate these paths at this time, and so this character will likely be made illegal in key names. This is somewhat remeniscent of the Windows Registry where \ is a path separator that is illegal in path names yet is allowed in key names.</p>
<h2><a class="header" href="#path-conventions" id="path-conventions">Path Conventions</a></h2>
<p>A PDDB Path may be a dict, a dict + a key, a basis + dict, or a basis + dict + key.
In the following examples, the given Basis, Dict, and Key are as follows:</p>
<ul>
<li>Basis: <code>.System</code></li>
<li>Dict: <code>wlan.networks</code></li>
<li>Key: <code>Home Wifi</code></li>
</ul>
<p>A canonical path looks like:</p>
<p><img src="images/betrusted-pddb-path-format.png" alt="path format" /></p>
<h3><a class="header" href="#examples" id="examples">Examples</a></h3>
<ul>
<li><code>:Home Wifi</code> -- A basis named &quot;Home Wifi&quot;</li>
<li><code>:.System:</code> -- A basis named &quot;.System&quot;</li>
<li><code>wlan.networks</code> -- A dict named &quot;wlan.networks&quot; in the default basis</li>
<li><code>wlan.networks:recent</code> -- A dict named &quot;wlan.networks:recent&quot;, which may be considered a path, in the default basis. This also describes a key called &quot;recent&quot; in the dict &quot;wlan.networks&quot;, depending on whether</li>
<li><code>:.System:wlan.networks</code> -- A dict named &quot;wlan.networks&quot; in the basis &quot;.System&quot;</li>
<li><code>:.System:wlan.networks:recent</code> -- a fully-qualified path, describing a key &quot;recent&quot; in the dict &quot;wlan.networks&quot; in the basis &quot;.System&quot;. Also describes a dict &quot;wlan.networks:recent&quot; in the basis &quot;.System&quot; when</li>
<li><code>:</code> -- The root, which lists every basis. Files cannot be created here. &quot;Directories&quot; can be
created and destroyed, which corresponds to creating and destroying bases.</li>
<li><code>::</code> -- An empty basis is a synonym for all bases, so this corresponds to listing all dicts in the root of the default basis.</li>
<li>-- An empty string corresponds to listing all dicts in root the union basis.</li>
</ul>
<h3><a class="header" href="#corner-cases" id="corner-cases">Corner cases</a></h3>
<ul>
<li><code>: :</code> -- A basis named &quot; &quot;. Legal, but questionable</li>
<li><code> </code> -- A dict named &quot; &quot; in the default basis. Legal, but questionable.</li>
<li><code>: </code> -- Also a dict named &quot; &quot; in the default basis.</li>
<li><code>:</code> -- A key named &quot; &quot; in a dict called &quot; &quot;. Legal.</li>
<li><code>baz:</code> -- A dict named &quot;baz&quot; in the default basis with an extra &quot;:&quot; following. Legal.</li>
<li><code>baz:foo:</code> -- Currently illegal, but may become equal to <code>baz:foo</code> in the future.</li>
<li><code>:::</code> -- An key named &quot;:&quot; in an empty dict in the default basis. Illegal.</li>
<li><code>::::</code> -- An key named &quot;::&quot; in an empty dict in the default basis. Illegal.</li>
<li><code>::foo</code> -- A key &quot;foo&quot; in the default basis.</li>
<li><code>:lorem.ipsum:foo:baz</code> -- A key called &quot;foo:baz&quot; in the basis &quot;lorem.ipsum&quot;. May also describe a dict &quot;foo:baz&quot; in the basis &quot;lorem.ipsum&quot; if treated as a directory.</li>
<li><code>:bar:lorem.ipsum:foo:baz</code> -- A key called &quot;baz&quot; in the dict &quot;lorem.ipsum:foo&quot; in
the basis &quot;bar&quot;, or a dict called &quot;lorem.ipsum:foo:baz&quot;. Legal.</li>
</ul>
<p>Any reference to &quot;default basis&quot; depends on whether the operation is a &quot;read&quot; or a &quot;write&quot;:</p>
<ul>
<li>&quot;Read&quot; operations come from a union, with the most-recently-added basis taking precedence</li>
<li>&quot;Write&quot; operations go to the most-recently-added basis that contains the key. If the key does not exist and &quot;Create&quot; was specified, then the file is created in the most-recently-added basis.</li>
</ul>
<h2><a class="header" href="#api-status" id="api-status">API Status</a></h2>
<p>As of v0.9.9, there is basic support for <code>std::fs</code> and <code>std::path</code>. As an example, the following features work:</p>
<ul>
<li>Opening and closing files</li>
<li>Reading from and writing to files</li>
<li>Seeking within an open file</li>
<li>Creating new files</li>
<li>Deleting files</li>
<li>Listing directories</li>
<li>Creating directories</li>
<li>Deleting directories</li>
</ul>
<p>There are a lot of features that do not work, or do not currently make sense. We'll add these features if there is demand:</p>
<ul>
<li>Copying files</li>
<li>Truncating currently-open files</li>
<li>Duplicating file descriptors</li>
<li>Getting creation/access/modification times on files</li>
<li>Symlinks</li>
<li>Readonly files</li>
<li>Permissions</li>
<li>Renaming files</li>
</ul>
<p>Additionally, the PDDB native API supports callbacks to notify senders of various file events such as deletions and updates. The spec for the native callback API is still a work in progress.</p>
<h1><a class="header" href="#testing-and-ci" id="testing-and-ci">Testing and CI</a></h1>
<p>Developers using the PDDB will find that the PDDB native API is accurate and fully functional on all of the standard modes for Xous: running on real hardware, Renode emulation, and Hosted mode emulation.</p>
<p>In hosted mode, the PDDB will create a smaller version of itself (just 4MiB in length) by creating a file called <code>tools/pddb-images/hosted.bin</code>. In Renode, the PDDB creates a full-length PDDB (98MiB) at <code>tools/pddb-images/renode.bin</code>. The passwords in Renode are hard-wired to <code>a</code> for both the boot PIN and the update password, and the silicon DNA is 0x0.</p>
<p>The following features are available to assist with testing the PDDB in hosted mode:</p>
<ul>
<li><code>&quot;deterministic&quot;</code> -- forces a deterministic seed to the RNG in hosted mode</li>
<li><code>&quot;ci&quot;</code> -- adds auto-running self-tests to the build</li>
<li><code>&quot;pddbtest&quot;</code> -- adds <code>shellchat</code> test commands using the native API to the build; also works on hardware</li>
<li><code>&quot;autobasis&quot;</code> -- patches over Basis enumeration commands to automatically create a test set of Bases.</li>
<li><code>&quot;test-rekey&quot;</code> -- changes the DNA in hosted mode so re-key migrations can be tested</li>
</ul>
<p>By default, <code>&quot;pddbtest&quot;</code> is enabled in the <code>cargo xtask run</code> configuration, enabling some extra commands in the <code>shellchat</code> PDDB menu.</p>
<h2><a class="header" href="#the-ci-feature" id="the-ci-feature">The &quot;ci&quot; Feature</a></h2>
<p>The <code>&quot;ci&quot;</code> test automatically kicks off a set of scripted tests that run <em>inside</em> the PDDB itself; so this does not use the API calls, but instead it calls methods normally only accessible internally within the server. The test does a series of stress-tests, creating and deleting keys of random sizes, with a specified naming scheme and data contents so that they can be automatically analyzed for correctness. The analysis is enabled by calling <code>dbg_dump()</code> periodically through the test -- an API call that is only made available in hosted mode. This call creates a new file that is a snapshot of the PDDB, along with a dump of the system keys, so that an analysis script can decrypt and analyze the PDDB's structure.</p>
<p>The correctness analysis of <code>&quot;ci&quot;</code> runs is done by the <code>tools/ppdbdbg.py</code> script. This script takes the keys provided, and decrypts the PDDB binary image. It scans the page table, checks the make-before-break buffer, free space tables, dictionaries and keys for consistency. It expects to see a certain pre-defined pattern of data in the dictionaries -- if you run this on a dump not generated by <code>&quot;ci&quot;</code>, it will throw CI errors.</p>
<p>The <code>&quot;ci&quot;</code> script is not a &quot;true&quot; CI in the sense that it is not currently run automatically on every build. Part of the complication is that there isn't a good way in hosted mode to &quot;quit&quot; the emulation based on an internal trigger.</p>
<p>A set of true &quot;CI&quot; scripts are also being developed that will run for every build on the hardware-in-loop testing.</p>
<h2><a class="header" href="#the-autobasis-feature" id="the-autobasis-feature">The &quot;autobasis&quot; Feature</a></h2>
<p>This feature will automatically create and enumerate a couple dozen Bases in the PDDB, according to an algorithm to derive names and passwords. This is meant to accelerate stress testing of scenarios covering resource exhausting in the presence of secret Bases.</p>
<h1><a class="header" href="#backups" id="backups">Backups</a></h1>
<p>Users can make backups of the PDDB, and restore it to the same or new device, by following the <a href="https://github.com/betrusted-io/betrusted-wiki/wiki/Backups">instructions on the wiki</a>.</p>
<h2><a class="header" href="#analysis" id="analysis">Analysis</a></h2>
<p>Offline analysis of a PDDB backup image is now possible thanks to the <code>backalyzer.py</code> script, found in the <code>tools/</code> directory. This script can take a backup PDDB image, and along with the BIP-39 key, boot password, and any basis name/password combos, decrypt the entire PDDB image, and perform a consistency check of all the Basis structures, dictionaries and keys. It can also be instructed to dump all the data.</p>
<p>This tool could potentially be run in an &quot;air-gapped&quot; environment to securely access PDDB contents from a backup in case a Precursor device is not available or damaged. However, it is not recommended to run this script on a regular, untrusted computer since you will have to share with it all the relevant security credentials to perform an analysis.</p>
<h1><a class="header" href="#security-and-deniability" id="security-and-deniability">Security and Deniability</a></h1>
<p>This chapter discusses issues affecting the security and deniability of the PDDB.</p>
<h2><a class="header" href="#deniability" id="deniability">Deniability</a></h2>
<p>Here are some vectors that can reduce the deniability of the PDDB:</p>
<ul>
<li>Ciphertext comparison attacks by an attacker who can capture previous snapshots of the disk</li>
<li>API leakage by application programs</li>
<li>Free space cache leakage</li>
</ul>
<h3><a class="header" href="#ciphertext-comparison-attacks" id="ciphertext-comparison-attacks">Ciphertext Comparison Attacks</a></h3>
<p>An adversary may come across backup archives of the PDDB, or snapshots taken at events such as border crossings or other lawful or unlawful surveillance seizures. With more than one backup file, an adversary could compare the evolution of the ciphertext and noise, and map out which blocks are very likely to be unused, versus ones which have definitely been used. The more frequently snapshots taken, the less deniable things become, to an asymptotic limit of an adversary with a precise log of every write to disk, leading to zero deniability (but you have bigger problems if this has happened).</p>
<p>To counter this, a user may regularly <code>churn</code> their device after doing a backup. This is done by running the <code>pddb churn</code> command in the <code>shellchat</code> app. This will ask the user to unlock all known secret Bases, and then it will:</p>
<ol>
<li>Re-encrypt every used block by &quot;re-noncing&quot; the ciphers</li>
<li>Re-write every unused block with a fresh set of noise from the TRNG</li>
</ol>
<p>This process is not mandated, because it takes about 20-30 minutes to churn all 100MiB of the PDDB, and puts a tax on the write lifetime of the FLASH memory. Alternatively, users may opt to maintain only a single backup file, versus a history of backups.</p>
<h3><a class="header" href="#api-leakage" id="api-leakage">API Leakage</a></h3>
<p>A trivial way to defeat all deniability is for an application to do the equivalent of <code>ls -lr /</code> and store a copy of that in a non-secret Basis. There is no code or active countermeasure to prevent an application from doing this: Xous takes a minimalist approach and assumes you have only one app on a device, and there is no pushbutton facility to download and run new apps or remote code on the device.</p>
<p>The more likely issue is that deniability-naive apps may try to store a path to a secret file, such as a contact that should be kept secret. When the secret Basis containing the contact is locked (e.g. unmounted), that dangling path reference is a leakage event. An application that reports an error due to the now-missing contact betrays the existence of the contact.</p>
<p>This is a difficult problem that has <a href="https://www.schneier.com/wp-content/uploads/2016/02/paper-truecrypt-dfs.pdf">been noted previously</a>. The PDDB makes it easier for applications to be deniable, and has &quot;safe defaults&quot; which means naive applications will not throw hard errors in the face of common mistakes. However, it does require all application developers to exercise a modicum of restraint when it comes to implementing features such as &quot;Open Recent...&quot; or &quot;Favorites...&quot;.</p>
<p>The general rule of thumb is all applications should lean on the PDDB's internal filesystem cache and treat it as the authoritative lookup for things like lists of contacts and files. This requires programmers to &quot;unlearn&quot; the pattern of creating local copies of directory listings to accelerate filesystem operations; it does feel strange to re-query a list of keys every single time you regenerate a UX view. However, this is the right way to implement such code paths while using the PDDB.</p>
<h3><a class="header" href="#free-space-cache-fscb-leakage" id="free-space-cache-fscb-leakage">Free Space Cache (FSCB) Leakage</a></h3>
<p>In order to not annoy users and to accelerate allocations, a cache of &quot;definitely free space&quot; is allocated on the PDDB. By default, this cache is set at a maximum of 50% of the actual remaining free space ±10%, and is further limited to the capacity of the cache itself, which is about 7% of peak capacity. Thus, the default settings strongly favor user convenience over deniability. A more paranoid setting might set the cache to something like 10% of the actual remaining free space ±10%.</p>
<p>However, these settings work well for applications where the PDDB is only lightly used. In particular, this works well for password vault and pure crypto wallet applications, where relatively tiny amounts (a few megabytes in aggregate) of sensitive cryptographic matter are stored in the PDDB.</p>
<p>This model breaks down quickly in the case of a chat device that is heavily used, especially if rich media types like images are stored in the PDDB. From a chat perspective, the device is usable for pure text-based chats and interviews, where the logs may consist of some hundreds of kilobytes of text-only data. But users who require trading items such as numerous high-resolution photographs or videos in a deniable fashion would be strongly advised to exercise caution, as these rich media types rapidly overflow the PDDB and lead to a degredation of deniability.</p>
<p>Some may argue that's a feature, not a bug.</p>
<h3><a class="header" href="#page-table-collision-leakage" id="page-table-collision-leakage">Page Table Collision Leakage</a></h3>
<p>The page table nonce is cryptographically &quot;tiny&quot;: just 32 bits. Its goal is to mask identical page numbers and flags from being encrypted to the same ciphertext.</p>
<p>If two identical page table entries from different Bases were to randomly be assigned an identical nonce, and if somehow they had the same encryption key, they would yield the same ciphertext. This would betray the existence of at least one secret basis. However, because the encryption key is derived from a unique name-and-password combo, you would need both a key and a nonce that collides to generate the same ciphertext.</p>
<p>More practically, a Basis page table entry may be assigned the same nonce upon re-encryption after being updated to a new location in physical memory. This means there is a chance that an adversary who has historical snapshots of a PDDB could do a ciphertext analysis of the page table and have a practical chance of finding two entries that have the same ciphertext. This would allow them to deduce that this entry corresponds to a valid page table entry, but it would not allow them to say which page or Basis it belongs to.</p>
<p>The table below, derived from <a href="https://en.wikipedia.org/wiki/Birthday_problem">wikipedia</a>, indicates the scale of the problem.</p>
<p><img src="images/collision-chance.png" alt="collision probabilities" /></p>
<p>Assuming that about 10,000 independent but identically virtually-addressed page table entries are updated between each backup (e.g. half the PDDB is turned over but with perfect re-use of the address space), an adversary has about a 1% chance of finding a single colliding pair of ciphertexts between any two backups. However, all the adversary can note is that a particular ciphertext corresponds to some kind of page table entry, but they don't know which Basis, or what part of the Basis.</p>
<p>In the end, the information from differential ciphertext analysis of backup images on the data regions is an orders magnitude larger leakage of data allocation state, so the presumption is that this is a negligible vector. However, an alternative approach would be to use the nonce in a &quot;counter&quot; mode where it is incrementing. This would guarantee no collisions, until the counter rolled over at 4 billion re-allocation events, at which point, the ciphertext pattern would repeat. This is an improvement that will likely be rolled out in a later version of Xous.</p>
<h2><a class="header" href="#security" id="security">Security</a></h2>
<p>The PDDB has not been formally reviewed by a Cryptographer for security, and the author is not an expert at Cryptography. Use at your own risk.</p>
<h3><a class="header" href="#approach" id="approach">Approach</a></h3>
<p>As a matter of philosophy, there are no hand-rolled ciphers in the PDDB and we try to use, as much as practical, implementations directly from the <a href="https://cryptography.rs/">RustCrypto</a> community (the exceptions are the hardware-accelerated core primitives like AES, SHA and Curve25519, required for performance reasons). However, the PDDB itself is a novel construction and could very likely have issues.</p>
<h3><a class="header" href="#known-issues" id="known-issues">Known Issues</a></h3>
<p>The AES-GCM-SIV construction in particular was revealed to have a problem known as <a href="https://keymaterial.net/2020/09/07/invisible-salamanders-in-aes-gcm-siv/">Salamanders</a>. This has been worked around by requiring a key commitment in the root page of the cryptographic Bases. However, our implementation of a key commitment <em>is</em> hand-rolled, because there isn't a committee-blessed standard on how to do this (yet). We do follow the recommendations <a href="https://eprint.iacr.org/2020/1456.pdf">in this paper</a>.</p>
<p>Finally, <em>all</em> confidentiality of the PDDB stems solely from the secrecy of the backup password, the boot PIN, and any secret Bases name/password combos. If you don't perform a backup, then the backup password is ostensibly only known to the hardware itself, and it requires an adversary with direct access to the device and its JTAG port to pull off any practical attack to extract the key. See <a href="https://github.com/betrusted-io/betrusted-wiki/wiki/FAQ:-FPGA-AES-Encryption-Key-(eFuse-BBRAM)#can-the-fpga-encryption-key-foil-an-attacker-who-has-unlimited-physical-access-to-my-device">this FAQ</a> for limitations on using Precursor as a &quot;true HSM&quot;.</p>
<p><a href="https://en.wikipedia.org/wiki/Kerckhoffs%27s_principle">There is no other magic</a>, so protect those keys!</p>
<h1><a class="header" href="#encrypted-swap" id="encrypted-swap">Encrypted Swap</a></h1>
<p>Encrypted swap is a solution for small-footprint secure microcontrollers that must rely upon external RAM chips. The idea is to have the fast, on-chip RAM within the secure perimeter serve as the working set of data, but have this backed up with a &quot;swapfile&quot; consisting of slower, off-chip RAM that is also encrypted.</p>
<p>The swap implementation is modelled after the kind of swap space found in other operating systems like Linux. The kernel can over-commit pages of virtual memory, and data is only allocated when a program actually attempts to access the over-committed pages. When the on-chip memory gets full, the swapper will guess as to what pages are not being used and copy them to encrypted swap. The kernel is then free to mark those virtual memory pages as invalid, and re-allocate them to actively used data.</p>
<p>Terminology:</p>
<ul>
<li><code>wired</code> refers to pages that are resident in RAM and cannot be swapped out</li>
<li><code>resident</code> refers to a page in RAM</li>
<li><code>free RAM</code> refers unallocated internal RAM</li>
<li><code>swapped</code> refers to a page in swap</li>
<li><code>free swap</code> refers to unallocated pages in external swap memory</li>
<li><code>reserved</code> refers to memory that has been over-committed, i.e., exists in virtual memory space but has no physical allocation</li>
<li><code>allocated</code> refers to memory that has been allocated, but could be in either <code>resident</code> or <code>swapped</code> states</li>
</ul>
<h2><a class="header" href="#review-of-virtual-memory-implementation-without-swap" id="review-of-virtual-memory-implementation-without-swap">Review of Virtual Memory Implementation Without Swap</a></h2>
<p>In Xous, every process has a page table, including the kernel. The <code>satp</code> field of a process record stores the page address of the root of a process page table in <code>satp.PPN</code>. <code>satp.ASID</code> contains the PID.</p>
<p>The kernel is mapped into every process virtual memory space, in the top 16MiB of memory. Thus, the kernel is unique in that it is the only process that can access its physical pages alongside another process.</p>
<p>When each process is created, their page tables are populated with entries that hard-wire the program's code. The stack and heap are also fully allocated, but over-provisioned. Only the first page of each space is backed with physical memory; the rest is demand-paged. Thus, when a program starts, its maximum stack and heap extents are defined by the loader. These extents can be modified at runtime with a kernel syscall, but a program will OOM-fail even if there is physical memory available if its virtual stack and heap allocations are exhausted.</p>
<p>To review, each PTE has the following flags:</p>
<ul>
<li>V <code>valid</code>: page contents are valid</li>
<li>R <code>read</code>: page can be read</li>
<li>W <code>write</code>: page can be written</li>
<li>X <code>execute</code>: page is executable</li>
<li>U <code>user</code>: page is accessible in user mode</li>
<li>G <code>global</code>: page is in all address spaces</li>
<li>A <code>accessed</code>: page has been accessed (read, execute, or write) (Vex does not implement)</li>
<li>D <code>dirty</code>: page has been written since last time it was cleared (Vex does not implement)</li>
<li>S <code>shared</code>: (part of RWS set) shared page - used by Xous to track if a page has been lent to another process</li>
<li>P <code>previously writable</code>: (part of RWS set) previously writable (not used)</li>
</ul>
<p>From the standpoint of memory management, a page can only have the following states:</p>
<ul>
<li><a href="https://github.com/betrusted-io/xous-core/blob/f389b41ccf3f31d4565b6840403af522ffc16890/kernel/src/arch/riscv/mem.rs#L894-L896">Allocated</a>: <code>V</code> set</li>
<li><a href="https://github.com/betrusted-io/xous-core/blob/f389b41ccf3f31d4565b6840403af522ffc16890/kernel/src/arch/riscv/mem.rs#L901-L903">Fault</a>: No flags are set, or <code>S</code> is set and <code>V</code> is not set</li>
<li>Reserved: <code>V</code> is <em>not</em> set, and at least one other flag is set except for <code>S</code></li>
</ul>
<h2><a class="header" href="#encryption-method" id="encryption-method">Encryption Method</a></h2>
<p>Swap is encrypted with an AEAD that is either AES-GCM-SIV or ChachaPoly (the choice will be determined based on benchmarked performance, and can even be changed on the fly since the encrypted information is ephemeral on every boot). The swap encryption key is generated from a hardware TRNG on boot. It is critical that this TRNG function correctly and be truly random early at boot.</p>
<p>The 16-byte AEAD MAC codes for every page are stored in a global appendix in untrusted RAM; this is fine, as the MAC is considered to be ciphertext, as all security derives from the key, but the swap space is reduced by this overhead. Detaching the MAC is done purely as a convenience to simplify page offset mapping computations; the detachment is not meant to imply the MAC is somehow cryptographically separable from the ciphertext block, as would be the case in e.g. a detachable signature scheme.</p>
<p>The nonce for the AEAD is derived as follows:</p>
<p><code>nonce[96] = {swap_count[32]|pid[8]|p_page[24]|v_page[24]}</code></p>
<p>This gives the following security properties:</p>
<ul>
<li>In all cases, pages cannot be replayed between reboots, as the key is generated on each boot</li>
<li>Tampered pages in external memory are cryptographically likely to be detected (due to the 128-bit MAC code)</li>
<li>Identical plaintext between two processes will not map to the same ciphertext</li>
<li>Identical plaintext within a process will not map to the same ciphertext</li>
<li>Ciphertext between two processes cannot be swapped to do code injection with ciphertext</li>
<li>Ciphertext of one page within a process cannot be copied to a new page location in the same process and decrypt correctly</li>
<li>Identical plaintext located in the same physical location and virtual location for the same process with the same swap count will create interchangeable ciphertext</li>
</ul>
<p>The swap count of a page is a cryptographically small number (nominally 32 bits) that is used to track which page has been least-recently used (to manage evictions). The implementation will be coded to allow a larger number if necessary, but there is a trade-off between the size of this number and the amount of heap space needed to track every virtual page and its swap space; as the swap grows large, the overhead can start to overwhelm the amount of memory available in a small footprint microcontroller.</p>
<p>The last property means that, for example, it is possible to infer something about the heap or stack of a running process that has been swapped out. In particular, we can detect if a region of stack or heap memory has been modified &amp; swapped, and then restored to the original data &amp; swapped, once the swap count is saturated.</p>
<p>This can be used for the following malicious activities:</p>
<ul>
<li>Build a side channel to exfiltrate data via swap</li>
<li>Force a running process into a previous stack or heap configuration by recording and restoring pages after forcing the swap count to roll over</li>
</ul>
<p>Mitigation of this vulnerability relies upon these factors:</p>
<ul>
<li>It takes a long time to push the swap count to 32 bits. This is the equivalent of encrypting and decrypting about 17 terabytes of data using the embedded controller. This would take over 22 years if the microcontroller can run AES-GCM-SIV bidirectionally at a rate of 100MiB/s. An Apple M1 Pro <a href="https://engineering.linecorp.com/en/blog/AES-GCM-SIV-optimization">can achieve 590MiB/s</a> unidirectionally, so this is an optimistic estimate for an embedded controller running at a few hundred MHz. A similar analysis can be done for ChachaPoly.</li>
<li>Instead of saturating, the swap count must roll-over. This means that the LRU algorithm will suffer a performance degradation after a &quot;long time&quot; (see previous bullet for bounds on that), but by avoiding saturation it means an attacker has a single window of opportunity to re-use a page before having to roll over again (or they must keep a log of all the pages). This isn't a cryptographically strong defense, but it practically complicates any attack with little cost in implementation.</li>
<li>The swap count can be increased to up to 40 bits in size (any larger would overflow the nonce size considering the other data concatenated into the nonce), if further strength is desired, at a considerable price on 32-bit microcontrollers.</li>
</ul>
<h2><a class="header" href="#swap-implementation" id="swap-implementation">Swap Implementation</a></h2>
<p>Swap is a kernel feature that is enabled with the flag <code>swap</code>.</p>
<p>Swap is intended to be implemented using an off-chip SPI RAM device. While it is most performant if it is a memory mapped RAM, it does not need to be; the <code>swapper</code> shall be coded with a HAL that can also handle SPI devices that are accessible only through a register interface.</p>
<h3><a class="header" href="#image-creation" id="image-creation">Image Creation</a></h3>
<p><code>swap</code> configured builds cannot assume that all the static code can fit inside the secure FLASH within a microcontroller.
Thus, the image creator must take regions marked as <code>IniS</code> and locate them in a &quot;detached blob&quot; from the main <code>xous.img</code>.</p>
<p>The security properties of the two images are thus:</p>
<ul>
<li><code>xous.img</code> is assumed to be written into a secure on-chip FLASH region, and is unencrypted by default.</li>
<li><code>swap.img</code> is assumed to be written to an off-chip SPI FLASH memory, and is untrusted by default.</li>
</ul>
<p>A simple bulk signature check on <code>swap.img</code>, like that used on <code>xous.img</code>, is not going to cut it in an adversarial
environment, because of the TOCTOU inherent in doing a hash-and-check and then bulk-copy over a slow bus like SPI.
Thus, the following two-phase scheme is introduced for distributing <code>swap.img</code>.</p>
<p>The AEAD shall be either ChachaPoly or AES-256, depending upon which is more performant (to be updated). We use a &quot;detached-MAC&quot; scheme only because it makes mapping block offsets in the ciphertext stream to block offsets in the plaintext stream logically easier. There's no cryptographic meaning in detaching the MAC.</p>
<ol>
<li>In phase 1, <code>swap.img</code> is encrypted using an AEAD to a &quot;well-known-key&quot; of <code>0</code>, where each block in FLASH encrypts a page of data, and the MAC are stored in an appendix to the <code>swap.img</code>. The first page is an unprotected directory that defines the expected offset of all the MAC relative to the encrypted blocks in the image file, and contains the 64-bit nonce seed + AAD. The problem of whether to accept an update is outside the scope of this spec: it's assumed that if an update is delivered, it's updated with some signature tied to a certificate in a transparency log that is confirmed by the user at update time. This does mean there is a potential TOCTOU of the bulk update data versus signing at update time, but we assume that the update is done as an atomic operation by the user in a &quot;safe&quot; environment, and that an adversary cannot force an update of the <code>swap.img</code> that meets the requirements of phase 2 without user consent.</li>
<li>In phase 2, <code>swap.img</code> is re-encrypted to a locally generated key, which is based on a key stored only in the device and derived with the help of a user-supplied password. This prevents adversaries from forcing an update to <code>swap.img</code> without a user's explicit consent. NOTE: the key shall <em>not</em> be re-used between <code>swap.img</code> updates; it should be re-generated on every update. This does mean that the signature on the <code>xous.img</code> shall change on every update, but this is assumed to be happening already on an update.</li>
</ol>
<p>In order to support this scheme, the <code>Swap</code> kernel argument contains a <code>key</code> field. The image creator sets this to a 256-bit &quot;all zero&quot; key initially for distribution and initial device image creation. Once the device is provisioned with a root key, the provisioning routine shall also update the kernel arguments (which are stored inside the secure FLASH region) with the new key, and re-encrypt the <code>swap</code> detached blob in SPI FLASH to the unique device key before rebooting.</p>
<p>If followed correctly, a device is distributed &quot;naive&quot; and malleable, but once the keying ceremony is done, it should be hard to intercept and/or modify blocks inside <code>swap.img</code>, since the block-by-block read-in and authentication check provides a strong guarantee of consistency even in the face of an adversary that can freely MITM the SPI bus.</p>
<p>This is different from the detached-signature with unencrypted body taken for on-chip FLASH, which is a faster, easier method, but only works if the path to FLASH memory is assumed to be trusted.</p>
<p>The nonce for the <code>swap.img</code> AEAD is 96 bits, where the lower 32 bits track the block offset, and the upper 64 bits are the lower 64 bits of the git commit corresponding to the <code>swap.img</code>. This 64-bit git commit is stored as a nonce seed in the unprotected header page along with the offset of the MAC + AAD data. The incorporation of the git commit helps protect against bugs in the implementation of the locally generated key. The locally generated key should not be re-used between updates, but tying the nonce to the git commit should harden against chosen ciphertext attacks in the case that the generated key happens to be re-used.</p>
<p>The AAD shall be the ASCII string 'swap'. I don't think it's strictly necessary, but might as well have domain separation.</p>
<h3><a class="header" href="#boot-setup-loader" id="boot-setup-loader">Boot Setup: Loader</a></h3>
<p>The loader gets new responsibilities when <code>swap</code> is enabled:</p>
<ul>
<li>The loader needs to be aware of both the location and size of the trusted internal unencrypted RAM (resident memory), and the external encrypted RAM (swap memory).</li>
<li>The resident memory is tracked using the existing &quot;Runtime Page Tracker&quot; (RPT) mechanism.</li>
<li>Additional structures are created, located at virtual address <code>0xE000_0000</code> and mapped into PID2's memory space:
<ol>
<li>The &quot;Swap Page Tables&quot; (SPT), which is a slice of pointers to swap page table structures. Every process starts with a root page table page pre-allocated, even if it does not use swap. Any page table pages allocated are placed in the 0xE000_0000 memory range; however, at run-time any additional pages needed will be allocated using <code>MapMemory</code> calls to the kernel and thus placed in the swapper's heap region.</li>
<li>The &quot;Swap MAC Table&quot; (SMT), which tracks the 16-byte MAC codes for every page in swap. It does not degrade security to locate the SMT in swap. The size is fixed, and is proportional to the size of swap.</li>
<li>A copy of the RPT, except with <code>wired</code> memory marked with a PID of 0 (pages marked with the kernel's PID, 1, are free memory; the kernel code itself is marked 0 and <code>wired</code>). The size is fixed, and is proportional to the total size of internal (<code>resident</code>) RAM.</li>
</ol>
</li>
<li>All of these structures must be mapped into PID2's memory space by the loader</li>
<li>The &quot;Swap Count Tracker&quot; is not allocated by the loader. However, the swap count of pages in swap is guaranteed to be set to 0 by the loader.</li>
<li>The loader is responsible for querying the TRNG on every boot to generate the session key for encrypting off-chip RAM.</li>
<li>A new image tag type is created <code>inis</code>, to indicate data that should start in encrypted swap.</li>
<li>A kernel argument with tag <code>swap</code> is created. It contains the userspace address for PID2 (the swapper) of the SPT, SMT, and RPT structures.</li>
</ul>
<p>The SPT has the same structure as system page tables. However, SPT entries are only allocated on-demand for processes that have swap; it is not a full copy of every page in the system page table.</p>
<h4><a class="header" href="#inif-handling" id="inif-handling">INIF handling</a></h4>
<p>Regions marked as <code>xip</code> (i.e, marked as <code>inif</code> type) are assumed to FLASH that is contained within the secure perimeter of the microcontroller. These regions are mapped directly and unencrypted into the kernel memory space.</p>
<p>These boot-critical processes must be <code>xip</code>, and are never swapped out:</p>
<ul>
<li>kernel</li>
<li>swapper</li>
<li>ticktimer</li>
</ul>
<p>More regions can be marked as <code>xip</code>; this is preferable, because if the code is resident in on-chip FLASH, they aren't taking up working-set RAM and things will run faster.</p>
<p>The initial data set of <code>inif</code> processes are considered to be <code>wired</code>; however, their reserved memory regions can be swapped after allocation.</p>
<h4><a class="header" href="#inie-handling" id="inie-handling">INIE handling</a></h4>
<p>Regions marked as <code>inie</code> are copied to the working set RAM and executed out of RAM. It is assumed this tag is mostly unused in microcontrollers with a small internal working set, but the behavior is not modified because it is a valid and useful tag for devices with large, trusted RAMs.</p>
<h4><a class="header" href="#inis-handling" id="inis-handling">INIS handling</a></h4>
<p>Regions marked as <code>inis</code> are copied into encrypted swap on boot. The kernel page table state start out with the correct <code>R</code>/<code>W</code>/<code>X</code>/<code>U</code> values, but <code>V</code> is not set, and <code>P</code> is set. Entries are created in the SPT to inform the tracker where to find the pages.</p>
<p>An kernel argument of type <code>swap</code> is provided, which is a base and bounds to the SPT/SMT region. This is meant to passed to the <code>swapper</code> process when it registers to the kernel.</p>
<p>The image creation routine and kernel arguments need to be extended to support <code>inis</code> regions located in off-chip SPI FLASH. The off-chip data is not encrypted, but it is signature checked with a dedicated signature block. Note that the off-chip SPI FLASH does not need to be memory mapped: the loader may read the memory through a register interface.</p>
<h3><a class="header" href="#kernel-runtime" id="kernel-runtime">Kernel Runtime</a></h3>
<p>Systems with <code>swap</code> enabled must have a process located at <code>PID</code> 2 that is the <code>swapper</code>. The kernel will only recognize <code>swap</code> extension syscalls originating from <code>PID</code> 2.</p>
<p>The following kernel syscall extensions are recognized when the <code>swap</code> feature is activated:</p>
<ul>
<li><code>RegisterSwapper</code></li>
<li><code>EvictPage</code></li>
</ul>
<p>The kernel page fault handler must also be extended to handle swapped pages by invoking the swapper to recover the contents.</p>
<p>The userspace <code>swapper</code> handles two classes of events. The first are blocking events, handled in an interrupt-like context where all IRQs are disabled. These are &quot;atomic&quot; swap operations, and cannot invoke any syscalls that could block, or wait on any events. The second are non-blocking events and are queued into the <code>swapper</code> like any other message.</p>
<p>Thus, preemption requests are ignored during a blocking swap event, because external IRQs are disabled.</p>
<p>Finally, the swapper shall not allow any shared-state locks on data structures required to satisfy a swap request. Such a lock will lead to a system hang with no error message, since what happens is the <code>swapper</code> will busy-wait eternally because preemption has been disabled.</p>
<h4><a class="header" href="#blocking-events" id="blocking-events">Blocking Events</a></h4>
<p>Blocking events are called with a list of 8 arguments in an interrupt-like context. Not all arguments are valid for all calls; the 8 arguments are an upper bound and must all be set to something due to the strictness of Rust function call prototypes.</p>
<p>Here are the types of blocking events that the swapper must handle:</p>
<ul>
<li><code>WriteToSwap</code>: Copy &amp; encrypts a physical page to swap. Arguments include the original processes' PID and virtual address.</li>
<li><code>ReadFromSwap</code>: Retrieve &amp; decrypts a page from swap, and copies it to a designated physical page. Arguments include the target process PID and virtual address for the page to retrive.</li>
<li><code>AllocateAdvisory</code>: Informs the swapper that a page in free RAM was allocated to a given PID and virtual address. Only reports on pages that are allocated out of free RAM, and it includes a flag to indicate if the allocation was <code>wired</code> or not. Recall that <code>wired</code> memory cannot be swapped. <code>AllocateAdvisory</code> may be coded to &quot;bulk up&quot; a couple of allocate requests for better efficiency.</li>
<li><code>Free</code>: Informs the swapper that a page was de-allocated by a process.</li>
</ul>
<p>These are processed with interrupts disabled, and have the same rules as interrupt handlers in terms of safe calls that can be performed.</p>
<p>The blocking responder inside the <code>swapper</code> must be atomic: in other words, every kernel request that comes in must be fully handled without any dependencies or stalls on other processes, and upon satisfaction the <code>swapper</code> must be immediately ready for another blocking request. In particular: you can't use the <code>log</code> crate for debugging.</p>
<h4><a class="header" href="#non-blocking-events" id="non-blocking-events">Non-Blocking Events</a></h4>
<ul>
<li><code>Trim</code>: (<strong>this might be a bad idea</strong>) a request from the kernel to free up N pages. Normally the kernel would not call this, as the swapper should be pre-emptively clearing space, but it is provided as a last-ditch method in case of an OOM.</li>
<li><code>ProcessAdvisory</code>: This is a scalar message generated by a blocking <code>AllocateAdvisory</code> message via the <code>try_send_message</code> method that tells the swapper to decide if an <code>EvictPage</code> call is needed. <code>ProcessAdvisory</code> can be safely missed if the message queue overflows.</li>
</ul>
<p>Non-blocking events happen in the normal userspace server thread.</p>
<h4><a class="header" href="#flags-and-states" id="flags-and-states">Flags and States</a></h4>
<p>When <code>swap</code> is enabled, the flags have the following meaning:</p>
<ul>
<li>V <code>valid</code>: page contents are valid</li>
<li>R <code>read</code>: page can be read</li>
<li>W <code>write</code>: page can be written</li>
<li>X <code>execute</code>: page is executable</li>
<li>U <code>user</code>: page is accessible in user mode</li>
<li>G <code>global</code>: page is in all address spaces</li>
<li>A <code>accessed</code>: page has been accessed (read, execute, or write) (Vex does not implement)</li>
<li>D <code>dirty</code>: page has been written since last time it was cleared (Vex does not implement)</li>
<li>S <code>shared</code>: (part of RWS set) shared page - used by Xous to track if a page has been lent to another process</li>
<li>P <code>swapped</code>: (part of RWS set) page is in swap</li>
</ul>
<p>From the standpoint of memory management, a page can only have the following states:</p>
<ul>
<li><code>Allocated</code>: <code>V</code> set, <code>P</code> may not be set</li>
<li><code>Fault</code>: No flags are set, or <code>S</code> is set and <code>V</code> is not set</li>
<li><code>Swapped</code>: <code>P</code> is set. <code>V</code> is <em>not</em> set. <code>S</code> may also not be set. Upon access to this page, the kernel allocates a resident page and calls <code>ReadFromSwap</code> to fill it. The page will move to the <code>Allocated</code> state on conclusion.</li>
<li><code>Reserved</code>: <code>V</code> is <em>not</em> set, <code>P</code> is <em>not</em> set, and at least one other flag is set except for <code>S</code>. A kernel allocates a resident page and zeros it. The page will move to the <code>Allocated</code> state on conclusion.</li>
</ul>
<p>Pages go from <code>Allocated</code> to <code>Swapped</code> based on the <code>swapper</code> observing that the kernel is low on memory, and calling a series of <code>EvictPage</code> calls to free up memory. It is always assumed that the kernel can allocate memory when necessary; as a last ditch the kernel can attempt to call <code>Trim</code> on the swapper, but this should only happen in extreme cases of memory pressure.</p>
<p>Pages go from <code>Allocated</code> to <code>Reserved</code> when a process unmaps memory.</p>
<p>When the <code>swapper</code> runs out of space, <code>WriteToSwap</code> panics with an OOM.</p>
<h4><a class="header" href="#registerswapper-syscall" id="registerswapper-syscall">RegisterSwapper Syscall</a></h4>
<p>The <code>swapper</code> registers with the kernel on a TOFU basis. The kernel reserves a single 128-bit <code>sid</code> with the target of the <code>swapper</code>, and it will trust the first process to use the <code>RegisterSwapper</code> syscall with its 128-bit random ID.</p>
<p>After registration, the kernel sends a message to the <code>swapper</code> with the location of the SPT/SMT regions as created by the bootloader, as well as the base and bounds of the free memory pool. The free memory pool is the region remaining after boot, after the loader has marked all the necessary RAM pages as <code>wired</code>.</p>
<h4><a class="header" href="#evictpage-syscall" id="evictpage-syscall">EvictPage Syscall</a></h4>
<p><code>EvictPage</code> is a syscall that only the <code>swapper</code> is allowed to call. It is a scalar <code>send</code> message, which contains the PID and address of the page to evict. Upon receipt, the kernel will:</p>
<ul>
<li>Change into the requested PID's address space</li>
<li>Lookup the physical address of the evicted page</li>
<li>Clear the <code>V</code> bit and set the <code>P</code> bit of the evicted page's PTE</li>
<li>Mark the RPT entry as free</li>
<li>Change into the swapper's address space</li>
<li>Mutably lend the evicted physical page to the swapper with a <code>WriteToSwap</code> message</li>
<li>Schedule the swapper to run</li>
</ul>
<h3><a class="header" href="#swapper-responsibilities" id="swapper-responsibilities">Swapper Responsibilities</a></h3>
<p>It is the swapper's responsibility to maintain a structure that keeps track of every page in the <code>free RAM</code> pool. It builds this using the <code>AllocateAdvisory</code> messages.</p>
<p>When the amount of free RAM falls below a certain threshold, the swapper will initiate a <code>Trim</code> operation. A kernel can also initiate a <code>Trim</code> as a last-ditch in case the <code>swapper</code> was starved of time and was unable to initiate a <code>Trim</code>, but this meant to be avoided.</p>
<p>In a <code>Trim</code> operation, the swapper picks the pages it thinks will have the least performance impact and calls <code>EvictPage</code> to remove them. Initially, the swapper will have no way to know what pages are most important; it must use a heuristic to guess the first pages to evict. However, since it must track how frequently a page has been swapped with the <code>swap_count</code> field (necessary for encryption), it can rely upon this to build an eventual map of which pages to avoid.</p>
<p>The swapper is also responsible for responding to <code>WriteToSwap</code> and <code>ReadFromSwap</code> calls.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
